{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c7b71c",
   "metadata": {},
   "source": [
    "## The purpose of this notebook is to attempt to build a graph with no neighbors while still cooperating with the PyG framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "091afe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/\"\n",
    "        \"non_response_blank_removed.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\", encoding=\"utf8\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(155)) - set(self.features))\n",
    "\n",
    "        data_list = self.construct_graphs(n_neighbors, train, log_transform)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[[12, 13, 14, 15, 16, 144]] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish.csv\", \"merfish.hdf5\"]\n",
    "\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.csv\")\n",
    "\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(self, data, anid, breg, n_neighbors, log_transform):\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "# LINES THAT WERE CHANGED\n",
    "###############################################################################################        \n",
    "        if n_neighbors == 0:\n",
    "            edges = np.concatenate(\n",
    "                [np.c_[np.array([i]), np.array([i])] for i in range(locations_for_this_slice.shape[0])],\n",
    "                axis=0\n",
    "            )\n",
    "            print(edges)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            nbrs = neighbors.NearestNeighbors(\n",
    "                n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "            )\n",
    "            nbrs.fit(locations_for_this_slice)\n",
    "            _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "            edges = np.concatenate(\n",
    "                [np.c_[kneighbors[:, 0], kneighbors[:, i + 1]] for i in range(n_neighbors)],\n",
    "                axis=0,\n",
    "            )\n",
    "        \n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "############################################################################################### \n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "            bregma=breg,\n",
    "        )\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list\n",
    "\n",
    "\n",
    "class FilteredMerfishDataset(MerfishDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/\"\n",
    "        \"non_response_blank_removed.txt\",\n",
    "        sexes=None,\n",
    "        behaviors=None,\n",
    "        test_animal=None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.sexes = sexes\n",
    "        self.behaviors = behaviors\n",
    "        self.test_animal = test_animal\n",
    "        original_csv_file = super().merfish_csv\n",
    "        new_df = pd.read_csv(original_csv_file)\n",
    "        print(f\"Original Data {new_df.shape}\")\n",
    "        if self.sexes is not None:\n",
    "            new_df = new_df[new_df[\"Animal_sex\"].isin(self.sexes)]\n",
    "        if self.behaviors is not None:\n",
    "            new_df = new_df[new_df[\"Behavior\"].isin(self.behaviors)]\n",
    "        if new_df.shape[0] == 0:\n",
    "            raise ValueError(\"Dataframe has no rows. Cannot build graph.\")\n",
    "        new_df.to_csv(self.root + \"/raw/merfish_messi.csv\", index=False)\n",
    "        print(f\"Filtered Data {new_df.shape}\")\n",
    "        # print(\"Filtered csv file created!\")\n",
    "        MerfishDataset.download(self)\n",
    "        super().__init__(\n",
    "            root,\n",
    "            n_neighbors=n_neighbors,\n",
    "            train=train,\n",
    "            log_transform=log_transform,\n",
    "            non_response_genes_file=non_response_genes_file,\n",
    "        )\n",
    "        # print(\"Filtered hdf5 file created!\")\n",
    "\n",
    "    #     @property\n",
    "    #     def raw_file_names(self):\n",
    "    #         return [\"merfish_messi.csv\", \"merfish_messi.hdf5\"]\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.csv\")\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.hdf5\")\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        print(self.merfish_hdf5)\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        anid_to_bregma_count = {\n",
    "            1: 12,\n",
    "            2: 12,\n",
    "            3: 6,\n",
    "            4: 5,\n",
    "            5: 6,\n",
    "            6: 6,\n",
    "            7: 12,\n",
    "            8: 6,\n",
    "            9: 6,\n",
    "            10: 6,\n",
    "            11: 6,\n",
    "            12: 4,\n",
    "            13: 4,\n",
    "            14: 4,\n",
    "            15: 4,\n",
    "            16: 4,\n",
    "            17: 4,\n",
    "            18: 4,\n",
    "            19: 4,\n",
    "            20: 4,\n",
    "            21: 4,\n",
    "            22: 4,\n",
    "            23: 4,\n",
    "            24: 4,\n",
    "            25: 4,\n",
    "            26: 4,\n",
    "            27: 2,\n",
    "            28: 4,\n",
    "            29: 4,\n",
    "            30: 4,\n",
    "        }\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "\n",
    "        # if we want a specific animals\n",
    "        if self.test_animal is not None:\n",
    "            # we need to find which of the slices\n",
    "            sorted_anids = np.sort(np.unique(data.anids))\n",
    "            slices_before_test_anid = 0\n",
    "            for anid in sorted_anids:\n",
    "                if anid != self.test_animal:\n",
    "                    slices_before_test_anid += anid_to_bregma_count[anid]\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            mask_train = np.ones(unique_slices.shape[0], dtype=bool)\n",
    "            mask_train[\n",
    "                slices_before_test_anid : (\n",
    "                    slices_before_test_anid + anid_to_bregma_count[self.test_animal]\n",
    "                )\n",
    "            ] = 0\n",
    "            unique_slices = (\n",
    "                unique_slices[(1 - mask_train).astype(\"bool\")]\n",
    "                if not train\n",
    "                else unique_slices[mask_train]\n",
    "            )\n",
    "        else:\n",
    "            min_animal = anid_to_bregma_count[np.min(data.anids)]\n",
    "            unique_slices = (\n",
    "                unique_slices[min_animal:] if train else unique_slices[:min_animal]\n",
    "            )\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a95ad1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "../data/raw/merfish_messi.hdf5\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6088 6088]\n",
      " [6089 6089]\n",
      " [6090 6090]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6260 6260]\n",
      " [6261 6261]\n",
      " [6262 6262]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6325 6325]\n",
      " [6326 6326]\n",
      " [6327 6327]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6132 6132]\n",
      " [6133 6133]\n",
      " [6134 6134]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5816 5816]\n",
      " [5817 5817]\n",
      " [5818 5818]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5690 5690]\n",
      " [5691 5691]\n",
      " [5692 5692]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5674 5674]\n",
      " [5675 5675]\n",
      " [5676 5676]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5378 5378]\n",
      " [5379 5379]\n",
      " [5380 5380]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5724 5724]\n",
      " [5725 5725]\n",
      " [5726 5726]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5281 5281]\n",
      " [5282 5282]\n",
      " [5283 5283]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5358 5358]\n",
      " [5359 5359]\n",
      " [5360 5360]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5277 5277]\n",
      " [5278 5278]\n",
      " [5279 5279]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5821 5821]\n",
      " [5822 5822]\n",
      " [5823 5823]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6055 6055]\n",
      " [6056 6056]\n",
      " [6057 6057]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5886 5886]\n",
      " [5887 5887]\n",
      " [5888 5888]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5733 5733]\n",
      " [5734 5734]\n",
      " [5735 5735]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5448 5448]\n",
      " [5449 5449]\n",
      " [5450 5450]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5328 5328]\n",
      " [5329 5329]\n",
      " [5330 5330]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6233 6233]\n",
      " [6234 6234]\n",
      " [6235 6235]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5691 5691]\n",
      " [5692 5692]\n",
      " [5693 5693]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6033 6033]\n",
      " [6034 6034]\n",
      " [6035 6035]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [4686 4686]\n",
      " [4687 4687]\n",
      " [4688 4688]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5707 5707]\n",
      " [5708 5708]\n",
      " [5709 5709]]\n"
     ]
    }
   ],
   "source": [
    "test_trial = FilteredMerfishDataset(\"../data\", n_neighbors=0, sexes=[\"Female\"], behaviors=[\"Naive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70ff8216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 6088, 6089, 6090],\n",
       "        [   0,    1,    2,  ..., 6088, 6089, 6090]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trial[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7afdcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6088 6088]\n",
      " [6089 6089]\n",
      " [6090 6090]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6260 6260]\n",
      " [6261 6261]\n",
      " [6262 6262]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6325 6325]\n",
      " [6326 6326]\n",
      " [6327 6327]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6132 6132]\n",
      " [6133 6133]\n",
      " [6134 6134]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5816 5816]\n",
      " [5817 5817]\n",
      " [5818 5818]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5690 5690]\n",
      " [5691 5691]\n",
      " [5692 5692]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5674 5674]\n",
      " [5675 5675]\n",
      " [5676 5676]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5378 5378]\n",
      " [5379 5379]\n",
      " [5380 5380]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5724 5724]\n",
      " [5725 5725]\n",
      " [5726 5726]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5281 5281]\n",
      " [5282 5282]\n",
      " [5283 5283]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5358 5358]\n",
      " [5359 5359]\n",
      " [5360 5360]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5277 5277]\n",
      " [5278 5278]\n",
      " [5279 5279]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5821 5821]\n",
      " [5822 5822]\n",
      " [5823 5823]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6055 6055]\n",
      " [6056 6056]\n",
      " [6057 6057]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5886 5886]\n",
      " [5887 5887]\n",
      " [5888 5888]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5733 5733]\n",
      " [5734 5734]\n",
      " [5735 5735]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5448 5448]\n",
      " [5449 5449]\n",
      " [5450 5450]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5328 5328]\n",
      " [5329 5329]\n",
      " [5330 5330]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6233 6233]\n",
      " [6234 6234]\n",
      " [6235 6235]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5691 5691]\n",
      " [5692 5692]\n",
      " [5693 5693]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6033 6033]\n",
      " [6034 6034]\n",
      " [6035 6035]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [4686 4686]\n",
      " [4687 4687]\n",
      " [4688 4688]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5707 5707]\n",
      " [5708 5708]\n",
      " [5709 5709]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 5. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571cc9b3ac3d4b1aa0c65dddeae7a189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 209: val_loss reached 0.43063 (best 0.43063), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 419: val_loss reached 0.35653 (best 0.35653), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 629: val_loss reached 0.32034 (best 0.32034), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 839: val_loss reached 0.29829 (best 0.29829), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1049: val_loss reached 0.27206 (best 0.27206), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 1259: val_loss reached 0.25861 (best 0.25861), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1469: val_loss reached 0.24626 (best 0.24626), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1679: val_loss reached 0.23887 (best 0.23887), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1889: val_loss reached 0.23275 (best 0.23275), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 2099: val_loss reached 0.22632 (best 0.22632), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 2309: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 2519: val_loss reached 0.22269 (best 0.22269), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 2729: val_loss reached 0.22115 (best 0.22115), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2939: val_loss reached 0.22018 (best 0.22018), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 3149: val_loss reached 0.21664 (best 0.21664), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 3359: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 3569: val_loss reached 0.21327 (best 0.21327), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 3779: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 3989: val_loss reached 0.21189 (best 0.21189), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 4199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 4409: val_loss reached 0.21189 (best 0.21189), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 4619: val_loss reached 0.21156 (best 0.21156), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 4829: val_loss reached 0.21082 (best 0.21082), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 5039: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 5249: val_loss reached 0.21003 (best 0.21003), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 5459: val_loss reached 0.20874 (best 0.20874), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 5669: val_loss reached 0.20815 (best 0.20815), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 5879: val_loss reached 0.20744 (best 0.20744), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 6089: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 6299: val_loss reached 0.20720 (best 0.20720), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 6509: val_loss reached 0.20583 (best 0.20583), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 6719: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 6929: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 7139: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 7349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 7559: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 7769: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 7979: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 8189: val_loss reached 0.20569 (best 0.20569), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 8399: val_loss reached 0.20537 (best 0.20537), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 8609: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 8819: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 9029: val_loss reached 0.20501 (best 0.20501), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 9239: val_loss reached 0.20474 (best 0.20474), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 9449: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 9659: val_loss reached 0.20474 (best 0.20474), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 9869: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 10079: val_loss reached 0.20408 (best 0.20408), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 10289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 10499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 10709: val_loss reached 0.20328 (best 0.20328), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__0__['Female']__['Naive']__0.001__25__grid_search_filtered-v1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 10919: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 11129: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 11339: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 11549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 11759: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 11969: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 12179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 12389: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 12599: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1045.2         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.7339         \t|600            \t|  1040.3         \t|  99.53          \t|\n",
      "run_training_batch                 \t|  0.052638       \t|12600          \t|  663.24         \t|  63.454         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.034276       \t|12600          \t|  431.88         \t|  41.319         \t|\n",
      "training_step_and_backward         \t|  0.029738       \t|12600          \t|  374.69         \t|  35.848         \t|\n",
      "model_forward                      \t|  0.019806       \t|12600          \t|  249.56         \t|  23.876         \t|\n",
      "training_step                      \t|  0.019578       \t|12600          \t|  246.68         \t|  23.601         \t|\n",
      "get_train_batch                    \t|  0.013113       \t|13200          \t|  173.1          \t|  16.561         \t|\n",
      "fetch_next_train_batch             \t|  0.013088       \t|13200          \t|  172.76         \t|  16.528         \t|\n",
      "backward                           \t|  0.0093212      \t|12600          \t|  117.45         \t|  11.236         \t|\n",
      "training_batch_to_device           \t|  0.0026351      \t|12600          \t|  33.203         \t|  3.1766         \t|\n",
      "on_train_batch_end                 \t|  0.0024176      \t|12600          \t|  30.462         \t|  2.9144         \t|\n",
      "get_validate_batch                 \t|  0.078197       \t|180            \t|  14.076         \t|  1.3466         \t|\n",
      "fetch_next_validate_batch          \t|  0.078146       \t|180            \t|  14.066         \t|  1.3458         \t|\n",
      "on_validation_end                  \t|  0.12881        \t|61             \t|  7.8573         \t|  0.75173        \t|\n",
      "zero_grad                          \t|  0.00057949     \t|12600          \t|  7.3015         \t|  0.69856        \t|\n",
      "evaluation_step_and_end            \t|  0.028222       \t|122            \t|  3.4431         \t|  0.32941        \t|\n",
      "validation_step                    \t|  0.028065       \t|122            \t|  3.4239         \t|  0.32758        \t|\n",
      "on_train_batch_start               \t|  0.00022146     \t|12600          \t|  2.7904         \t|  0.26697        \t|\n",
      "on_validation_start                \t|  0.024433       \t|61             \t|  1.4904         \t|  0.14259        \t|\n",
      "on_train_epoch_start               \t|  0.0017373      \t|600            \t|  1.0424         \t|  0.099726       \t|\n",
      "training_step_end                  \t|  5.8884e-05     \t|12600          \t|  0.74194        \t|  0.070983       \t|\n",
      "on_batch_start                     \t|  4.4227e-05     \t|12600          \t|  0.55726        \t|  0.053314       \t|\n",
      "on_train_epoch_end                 \t|  0.00087442     \t|600            \t|  0.52465        \t|  0.050195       \t|\n",
      "evaluation_batch_to_device         \t|  0.0036567      \t|122            \t|  0.44612        \t|  0.042681       \t|\n",
      "on_after_backward                  \t|  3.3018e-05     \t|12600          \t|  0.41603        \t|  0.039803       \t|\n",
      "on_batch_end                       \t|  3.2228e-05     \t|12600          \t|  0.40607        \t|  0.03885        \t|\n",
      "on_before_zero_grad                \t|  3.1909e-05     \t|12600          \t|  0.40205        \t|  0.038465       \t|\n",
      "on_before_backward                 \t|  2.8102e-05     \t|12600          \t|  0.35409        \t|  0.033877       \t|\n",
      "on_before_optimizer_step           \t|  2.7151e-05     \t|12600          \t|  0.3421         \t|  0.03273        \t|\n",
      "on_validation_batch_end            \t|  0.0021362      \t|122            \t|  0.26061        \t|  0.024933       \t|\n",
      "get_sanity_check_batch             \t|  0.056288       \t|3              \t|  0.16886        \t|  0.016156       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.056227       \t|3              \t|  0.16868        \t|  0.016138       \t|\n",
      "on_train_start                     \t|  0.027681       \t|1              \t|  0.027681       \t|  0.0026483      \t|\n",
      "on_sanity_check_start              \t|  0.022556       \t|1              \t|  0.022556       \t|  0.002158       \t|\n",
      "on_epoch_start                     \t|  2.8465e-05     \t|661            \t|  0.018815       \t|  0.0018001      \t|\n",
      "on_epoch_end                       \t|  2.7675e-05     \t|661            \t|  0.018293       \t|  0.0017501      \t|\n",
      "on_validation_batch_start          \t|  8.6484e-05     \t|122            \t|  0.010551       \t|  0.0010095      \t|\n",
      "validation_step_end                \t|  7.3793e-05     \t|122            \t|  0.0090027      \t|  0.00086131     \t|\n",
      "on_validation_model_eval           \t|  0.00014036     \t|61             \t|  0.0085617      \t|  0.00081912     \t|\n",
      "on_pretrain_routine_start          \t|  0.004979       \t|1              \t|  0.004979       \t|  0.00047636     \t|\n",
      "on_validation_epoch_end            \t|  3.8144e-05     \t|61             \t|  0.0023268      \t|  0.00022261     \t|\n",
      "on_validation_epoch_start          \t|  2.5475e-05     \t|61             \t|  0.0015539      \t|  0.00014867     \t|\n",
      "on_train_end                       \t|  0.00067036     \t|1              \t|  0.00067036     \t|  6.4135e-05     \t|\n",
      "configure_optimizers               \t|  0.00026288     \t|1              \t|  0.00026288     \t|  2.515e-05      \t|\n",
      "on_fit_start                       \t|  7.5621e-05     \t|1              \t|  7.5621e-05     \t|  7.2348e-06     \t|\n",
      "on_fit_end                         \t|  4.5479e-05     \t|1              \t|  4.5479e-05     \t|  4.3511e-06     \t|\n",
      "teardown                           \t|  3.7137e-05     \t|1              \t|  3.7137e-05     \t|  3.553e-06      \t|\n",
      "on_sanity_check_end                \t|  3.1915e-05     \t|1              \t|  3.1915e-05     \t|  3.0534e-06     \t|\n",
      "on_pretrain_routine_end            \t|  2.7838e-05     \t|1              \t|  2.7838e-05     \t|  2.6634e-06     \t|\n",
      "setup                              \t|  2.3633e-05     \t|1              \t|  2.3633e-05     \t|  2.261e-06      \t|\n",
      "on_configure_sharded_model         \t|  1.9859e-05     \t|1              \t|  1.9859e-05     \t|  1.9e-06        \t|\n",
      "on_before_accelerator_backend_setup\t|  1.424e-05      \t|1              \t|  1.424e-05      \t|  1.3624e-06     \t|\n",
      "on_val_dataloader                  \t|  8.9789e-06     \t|1              \t|  8.9789e-06     \t|  8.5903e-07     \t|\n",
      "configure_callbacks                \t|  7.1339e-06     \t|1              \t|  7.1339e-06     \t|  6.8252e-07     \t|\n",
      "configure_sharded_model            \t|  6.842e-06      \t|1              \t|  6.842e-06      \t|  6.5459e-07     \t|\n",
      "prepare_data                       \t|  5.289e-06      \t|1              \t|  5.289e-06      \t|  5.0601e-07     \t|\n",
      "on_train_dataloader                \t|  5.2312e-06     \t|1              \t|  5.2312e-06     \t|  5.0049e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6506 6506]\n",
      " [6507 6507]\n",
      " [6508 6508]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6409 6409]\n",
      " [6410 6410]\n",
      " [6411 6411]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6504 6504]\n",
      " [6505 6505]\n",
      " [6506 6506]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6602 6602]\n",
      " [6603 6603]\n",
      " [6604 6604]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6182 6182]\n",
      " [6183 6183]\n",
      " [6184 6184]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6151 6151]\n",
      " [6152 6152]\n",
      " [6153 6153]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6108 6108]\n",
      " [6109 6109]\n",
      " [6110 6110]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6141 6141]\n",
      " [6142 6142]\n",
      " [6143 6143]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5796 5796]\n",
      " [5797 5797]\n",
      " [5798 5798]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [6064 6064]\n",
      " [6065 6065]\n",
      " [6066 6066]]\n",
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5575 5575]\n",
      " [5576 5576]\n",
      " [5577 5577]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0]\n",
      " [   1    1]\n",
      " [   2    2]\n",
      " ...\n",
      " [5581 5581]\n",
      " [5582 5582]\n",
      " [5583 5583]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6a5db9d1f14fa9a3a22f4a351db777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  10.487         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  10.441         \t|1              \t|  10.441         \t|  99.56          \t|\n",
      "evaluation_step_and_end            \t|  0.70293        \t|12             \t|  8.4352         \t|  80.435         \t|\n",
      "test_step                          \t|  0.68798        \t|12             \t|  8.2557         \t|  78.724         \t|\n",
      "get_test_batch                     \t|  0.10407        \t|13             \t|  1.3529         \t|  12.901         \t|\n",
      "fetch_next_test_batch              \t|  0.10403        \t|13             \t|  1.3524         \t|  12.896         \t|\n",
      "on_test_batch_end                  \t|  0.018193       \t|12             \t|  0.21832        \t|  2.0818         \t|\n",
      "test_step_end                      \t|  0.01473        \t|12             \t|  0.17676        \t|  1.6856         \t|\n",
      "evaluation_batch_to_device         \t|  0.01017        \t|12             \t|  0.12204        \t|  1.1637         \t|\n",
      "on_test_start                      \t|  0.018092       \t|1              \t|  0.018092       \t|  0.17252        \t|\n",
      "on_test_end                        \t|  0.0012911      \t|1              \t|  0.0012911      \t|  0.012311       \t|\n",
      "on_test_batch_start                \t|  5.3971e-05     \t|12             \t|  0.00064765     \t|  0.0061757      \t|\n",
      "on_test_model_eval                 \t|  9.9598e-05     \t|1              \t|  9.9598e-05     \t|  0.00094973     \t|\n",
      "on_test_epoch_end                  \t|  5.6463e-05     \t|1              \t|  5.6463e-05     \t|  0.00053841     \t|\n",
      "teardown                           \t|  3.7308e-05     \t|1              \t|  3.7308e-05     \t|  0.00035576     \t|\n",
      "on_epoch_end                       \t|  2.5598e-05     \t|1              \t|  2.5598e-05     \t|  0.0002441      \t|\n",
      "on_epoch_start                     \t|  2.4725e-05     \t|1              \t|  2.4725e-05     \t|  0.00023577     \t|\n",
      "on_test_epoch_start                \t|  1.9096e-05     \t|1              \t|  1.9096e-05     \t|  0.0001821      \t|\n",
      "on_configure_sharded_model         \t|  1.3198e-05     \t|1              \t|  1.3198e-05     \t|  0.00012585     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.2941e-05     \t|1              \t|  1.2941e-05     \t|  0.0001234      \t|\n",
      "configure_callbacks                \t|  1.1873e-05     \t|1              \t|  1.1873e-05     \t|  0.00011322     \t|\n",
      "setup                              \t|  1.0641e-05     \t|1              \t|  1.0641e-05     \t|  0.00010147     \t|\n",
      "on_test_dataloader                 \t|  7.3882e-06     \t|1              \t|  7.3882e-06     \t|  7.0451e-05     \t|\n",
      "prepare_data                       \t|  6.3269e-06     \t|1              \t|  6.3269e-06     \t|  6.0332e-05     \t|\n",
      "configure_sharded_model            \t|  4.9411e-06     \t|1              \t|  4.9411e-06     \t|  4.7117e-05     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.20122438669204712,\n",
      " 'test_loss: mae_response': 0.32917433977127075,\n",
      " 'test_loss: mse': 0.20576705038547516}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# from spatial.merfish_dataset import FilteredMerfishDataset, MerfishDataset\n",
    "from spatial.models.monet_ae import MonetAutoencoder2D, TrivialAutoencoder\n",
    "from spatial.train import train\n",
    "from spatial.predict import test\n",
    "\n",
    "import torch\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "\n",
    "behaviors = [\"Naive\"]\n",
    "sexes = [\"Female\"]\n",
    "\n",
    "with open('animal_id.json') as json_file:\n",
    "    animals = json.load(json_file)\n",
    "\n",
    "loss_dict = {}\n",
    "time_dict = {}\n",
    "loss_excitatory_dict = {}\n",
    "loss_inhibitory_dict = {}\n",
    "\n",
    "for behavior in behaviors:\n",
    "    for sex in sexes:\n",
    "        try:\n",
    "            animal_list = animals[behavior][sex]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        behavior = [behavior]\n",
    "        sex = [sex]\n",
    "        # print(behavior, sex, animal_list)\n",
    "        start = time.time()\n",
    "        with initialize(config_path=\"../config\"):\n",
    "            cfg_from_terminal = compose(config_name=\"config\")\n",
    "            # update the behavior to get the model of interest\n",
    "            OmegaConf.update(cfg_from_terminal, \"datasets.dataset.behaviors\", behavior)\n",
    "            OmegaConf.update(cfg_from_terminal, \"datasets.dataset.sexes\", sex)\n",
    "            OmegaConf.update(cfg_from_terminal, \"datasets.dataset.test_animal\", 1)\n",
    "            OmegaConf.update(cfg_from_terminal, \"n_neighbors\", 0)\n",
    "            model = train(cfg_from_terminal)\n",
    "            output = test(cfg_from_terminal)\n",
    "            trainer, l1_losses, inputs, gene_expressions, celltypes, test_results = output\n",
    "            MAE = test_results[0]['test_loss: mae_response']\n",
    "            excitatory_cells = (celltypes == 6).nonzero(as_tuple=True)[0]\n",
    "            MAE_excitatory = torch.abs(torch.index_select((gene_expressions-inputs)[excitatory_cells], 1, torch.tensor(model.responses))).mean().item()\n",
    "            inhibitory_cells = (celltypes == 7).nonzero(as_tuple=True)[0]\n",
    "            MAE_inhibitory = torch.abs(torch.index_select((gene_expressions-inputs)[inhibitory_cells], 1, torch.tensor(model.responses))).mean().item()\n",
    "        end = time.time()\n",
    "#             time_dict[f\"{sex}_{behavior}_{animal}\"] = end-start\n",
    "#             loss_dict[f\"{sex}_{behavior}_{animal}\"] = MAE\n",
    "#             loss_excitatory_dict[f\"{sex}_{behavior}_{animal}\"] = MAE_excitatory\n",
    "#             loss_inhibitory_dict[f\"{sex}_{behavior}_{animal}\"] = MAE_inhibitory\n",
    "\n",
    "#             with open(\"deepST_MAE.json\", \"w\") as outfile:\n",
    "#                 json.dump(loss_dict, outfile, indent=4)\n",
    "\n",
    "#             with open(\"deepST_time.json\", \"w\") as outfile:\n",
    "#                 json.dump(time_dict, outfile, indent=4)\n",
    "\n",
    "#             with open(\"deepST_MAE_excitatory.json\", \"w\") as outfile:\n",
    "#                 json.dump(loss_excitatory_dict, outfile, indent=4)\n",
    "\n",
    "#             with open(\"deepST_MAE_inhibitory.json\", \"w\") as outfile:\n",
    "#                 json.dump(loss_inhibitory_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612c14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
