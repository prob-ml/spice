{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77a296b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "import json\n",
    "import itertools as it\n",
    "import pathlib\n",
    "import copy\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        neighbor_celltypes=False,\n",
    "        radius=None,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/\"\n",
    "        \"non_response_blank_removed.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\", encoding=\"utf8\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(155)) - set(self.features))\n",
    "\n",
    "        data_list = self.construct_graphs(\n",
    "            n_neighbors, train, log_transform, neighbor_celltypes, radius\n",
    "        )\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[[12, 13, 14, 15, 16, 144]] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish.csv\", \"merfish.hdf5\"]\n",
    "\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.csv\")\n",
    "\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(\n",
    "        self, data, anid, breg, n_neighbors, log_transform, neighbor_celltypes, radius\n",
    "    ):\n",
    "        def get_neighbors(edges, x_shape):\n",
    "            return [edges[:, edges[0] == i][1] for i in range(x_shape)]\n",
    "\n",
    "        def get_celltype_simplex(cell_behavior_tensor, neighbors_tensor):\n",
    "            num_classes = cell_behavior_tensor.max() + 1\n",
    "            return torch.cat(\n",
    "                [\n",
    "                    (\n",
    "                        torch.mean(\n",
    "                            1.0\n",
    "                            * F.one_hot(\n",
    "                                cell_behavior_tensor.index_select(0, neighbors),\n",
    "                                num_classes=num_classes,\n",
    "                            ),\n",
    "                            dim=0,\n",
    "                        )\n",
    "                    ).unsqueeze(0)\n",
    "                    for neighbors in neighbors_tensor\n",
    "                ],\n",
    "                dim=0,\n",
    "            )\n",
    "\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "\n",
    "        # only include self edges if n_neighbors is 0\n",
    "        if n_neighbors == 0:\n",
    "            edges = np.concatenate(\n",
    "                [\n",
    "                    np.c_[np.array([i]), np.array([i])]\n",
    "                    for i in range(locations_for_this_slice.shape[0])\n",
    "                ],\n",
    "                axis=0,\n",
    "            )\n",
    "            print(edges)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if radius is None:\n",
    "                nbrs = neighbors.NearestNeighbors(\n",
    "                    n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "                )\n",
    "                nbrs.fit(locations_for_this_slice)\n",
    "                _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "                edges = np.concatenate(\n",
    "                    [\n",
    "                        np.c_[kneighbors[:, 0], kneighbors[:, i + 1]]\n",
    "                        for i in range(n_neighbors)\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "\n",
    "                tree = cKDTree(locations_for_this_slice)\n",
    "                kneighbors = tree.query_ball_point(\n",
    "                    locations_for_this_slice, r=32, return_sorted=False\n",
    "                )\n",
    "                edges = np.concatenate(\n",
    "                    [\n",
    "                        np.c_[\n",
    "                            np.repeat(i, len(kneighbors[i]) - 1),\n",
    "                            [x for x in kneighbors[i] if x != i],\n",
    "                        ]\n",
    "                        for i in range(len(kneighbors))\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if neighbor_celltypes:\n",
    "            test_simplex = get_celltype_simplex(\n",
    "                torch.tensor(labelinfo[:, 1]),\n",
    "                get_neighbors(edges, predictors_x.shape[0]),\n",
    "            )\n",
    "            predictors_x = torch.cat((predictors_x, test_simplex), dim=1)\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "            bregma=breg,\n",
    "        )\n",
    "\n",
    "    def construct_graphs(\n",
    "        self,\n",
    "        n_neighbors,\n",
    "        train,\n",
    "        log_transform=True,\n",
    "        neighbor_celltypes=False,\n",
    "        radius=None,\n",
    "    ):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            \n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "            \n",
    "            num_graphs = int(np.ceil(n_neighbors/3))\n",
    "            \n",
    "            # print(num_graphs)\n",
    "            \n",
    "            data_graphs = []\n",
    "            \n",
    "            # for each new graph\n",
    "            for i in range(1, num_graphs+1):\n",
    "                \n",
    "                # subset 1/num_graphs of the data based on quantiles\n",
    "                graph_filter = np.where(\n",
    "                    (data.locations[:,0]<=np.quantile(data.locations[:,0], i/num_graphs)) & \n",
    "                    (data.locations[:,0]>=np.quantile(data.locations[:,0], (i-1)/num_graphs))\n",
    "                )[0]\n",
    "\n",
    "                data = types.SimpleNamespace(\n",
    "                    anids=h5f[\"Animal_ID\"][graph_filter],\n",
    "                    bregs=h5f[\"Bregma\"][graph_filter],\n",
    "                    expression=h5f[\"expression\"][graph_filter, :],\n",
    "                    locations=np.c_[h5f[\"Centroid_X\"][graph_filter], h5f[\"Centroid_Y\"][graph_filter]],\n",
    "                    behavior=h5f[\"Behavior\"][graph_filter].astype(\"U\"),\n",
    "                    celltypes=h5f[\"Cell_class\"][graph_filter].astype(\"U\"),\n",
    "                )\n",
    "                \n",
    "                data_graphs.append(data)\n",
    "        \n",
    "        # see if you can update data locations AFTER data was created\n",
    "        # create a deepcopy and then split the locations\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        # print(len(data_graphs))\n",
    "        for data in data_graphs:\n",
    "            \n",
    "            # get the (animal_id,bregma) pairs that define a unique slice\n",
    "            unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "            # are we looking at train or test sets?\n",
    "            unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "        \n",
    "            # print(len(unique_slices))\n",
    "            \n",
    "            for anid, breg in unique_slices:\n",
    "                data_list.append(\n",
    "                    self.construct_graph(\n",
    "                        data,\n",
    "                        anid,\n",
    "                        breg,\n",
    "                        n_neighbors,\n",
    "                        log_transform,\n",
    "                        neighbor_celltypes,\n",
    "                        radius,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f62af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MerfishDataset(\"../data\", n_neighbors=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8d64919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4bda8bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(bregma=[1], edge_index=[2, 17615], pos=[1355, 2], x=[1355, 155], y=[1355, 2])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a4132b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 48\n",
      "1 48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [165]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_neighbors \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m13\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     test \u001b[38;5;241m=\u001b[39m \u001b[43mMerfishDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(n_neighbors, sys\u001b[38;5;241m.\u001b[39mgetsizeof(test))\n",
      "Input \u001b[0;32mIn [161]\u001b[0m, in \u001b[0;36mMerfishDataset.__init__\u001b[0;34m(self, root, n_neighbors, train, log_transform, neighbor_celltypes, radius, non_response_genes_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# response genes (columns in MERFISH)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m155\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures))\n\u001b[0;32m---> 41\u001b[0m data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_graphs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_celltypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerfish_hdf5, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m h5f:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgene_names \u001b[38;5;241m=\u001b[39m h5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene_names\u001b[39m\u001b[38;5;124m\"\u001b[39m][:][\u001b[38;5;241m~\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbad_genes]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [161]\u001b[0m, in \u001b[0;36mMerfishDataset.construct_graphs\u001b[0;34m(self, n_neighbors, train, log_transform, neighbor_celltypes, radius)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_graphs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    258\u001b[0m         \n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# subset 1/num_graphs of the data based on quantiles\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         graph_filter \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m    261\u001b[0m             (data\u001b[38;5;241m.\u001b[39mlocations[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mquantile(data\u001b[38;5;241m.\u001b[39mlocations[:,\u001b[38;5;241m0\u001b[39m], i\u001b[38;5;241m/\u001b[39mnum_graphs)) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m    262\u001b[0m             (data\u001b[38;5;241m.\u001b[39mlocations[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mquantile(data\u001b[38;5;241m.\u001b[39mlocations[:,\u001b[38;5;241m0\u001b[39m], (i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39mnum_graphs))\n\u001b[1;32m    263\u001b[0m         )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    265\u001b[0m         data \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mSimpleNamespace(\n\u001b[1;32m    266\u001b[0m             anids\u001b[38;5;241m=\u001b[39mh5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnimal_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m][graph_filter],\n\u001b[1;32m    267\u001b[0m             bregs\u001b[38;5;241m=\u001b[39mh5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBregma\u001b[39m\u001b[38;5;124m\"\u001b[39m][graph_filter],\n\u001b[1;32m    268\u001b[0m             expression\u001b[38;5;241m=\u001b[39mh5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m\"\u001b[39m][graph_filter, :],\n\u001b[0;32m--> 269\u001b[0m             locations\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mc_[\u001b[43mh5f\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCentroid_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgraph_filter\u001b[49m\u001b[43m]\u001b[49m, h5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentroid_Y\u001b[39m\u001b[38;5;124m\"\u001b[39m][graph_filter]],\n\u001b[1;32m    270\u001b[0m             behavior\u001b[38;5;241m=\u001b[39mh5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavior\u001b[39m\u001b[38;5;124m\"\u001b[39m][graph_filter]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    271\u001b[0m             celltypes\u001b[38;5;241m=\u001b[39mh5f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell_class\u001b[39m\u001b[38;5;124m\"\u001b[39m][graph_filter]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    274\u001b[0m         data_graphs\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# see if you can update data locations AFTER data was created\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# create a deepcopy and then split the locations\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# store all the slices in this list...\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/h5py/_hl/dataset.py:710\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for n_neighbors in [0,1,2,3,5,8,13]:\n",
    "    test = MerfishDataset(\"../data\", n_neighbors=13)\n",
    "    print(n_neighbors, sys.getsizeof(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8c3cf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatial.merfish_dataset import MerfishDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7409bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MerfishDataset(\"../data\", n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "030f105f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d1946c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(bregma=[1], edge_index=[2, 18273], pos=[6091, 2], x=[6091, 155], y=[6091, 2])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b06cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
