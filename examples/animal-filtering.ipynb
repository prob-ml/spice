{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cathedral-faculty",
   "metadata": {},
   "source": [
    "# Step 1: Recreating the data example in MESSI's home tutorial notebook. (Get Animals 16-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "brutal-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "animated-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish_df = pd.read_csv('../data/raw/merfish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "floppy-melissa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Female', 'Male'], dtype=object),\n",
       " array(['Naive', 'Parenting', 'Virgin Parenting', 'Aggression to pup',\n",
       "        'Aggression to adult', 'Mating'], dtype=object),\n",
       " array(['Astrocyte', 'Inhibitory', 'OD Mature 2', 'Endothelial 1',\n",
       "        'Ambiguous', 'Pericytes', 'Endothelial 2', 'OD Mature 1',\n",
       "        'OD Immature 1', 'Excitatory', 'Microglia', 'Endothelial 3',\n",
       "        'OD Mature 4', 'OD Immature 2', 'OD Mature 3', 'Ependymal'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexes = merfish_df[\"Animal_sex\"].unique()\n",
    "behaviors = merfish_df[\"Behavior\"].unique()\n",
    "celltypes = merfish_df[\"Cell_class\"].unique()\n",
    "(sexes, behaviors, celltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "domestic-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish_df.to_csv('justatest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sophisticated-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027848, 170)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = merfish_df[(merfish_df[\"Animal_sex\"].isin([\"Female\", \"Male\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wicked-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485657, 170)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[(merfish_df[\"Behavior\"].isin([\"Naive\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accurate-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457111, 170)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = merfish_df[(merfish_df[\"Animal_sex\"].isin([\"Female\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indian-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86902, 170)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[(new_df[\"Behavior\"].isin([\"Parenting\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "straight-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 12\n",
      "2 12\n",
      "3 6\n",
      "4 5\n",
      "5 6\n",
      "6 6\n",
      "7 12\n",
      "8 6\n",
      "9 6\n",
      "10 6\n",
      "11 6\n",
      "12 4\n",
      "13 4\n",
      "14 4\n",
      "15 4\n",
      "16 4\n",
      "17 4\n",
      "18 4\n",
      "19 4\n",
      "20 4\n",
      "21 4\n",
      "22 4\n",
      "23 4\n",
      "24 4\n",
      "25 4\n",
      "26 4\n",
      "27 2\n",
      "28 4\n",
      "29 4\n",
      "30 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 31):\n",
    "    merfish_df_subset = merfish_df[merfish_df['Animal_ID'] == i]\n",
    "    print(i, len(merfish_df_subset['Bregma'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elder-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example = merfish_df[(merfish_df['Animal_sex'] == \"Female\") & (merfish_df['Behavior'] == \"Parenting\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signed-cheat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_ID</th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Animal_sex</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Bregma</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Cell_class</th>\n",
       "      <th>Neuron_cluster_ID</th>\n",
       "      <th>Ace2</th>\n",
       "      <th>...</th>\n",
       "      <th>Penk</th>\n",
       "      <th>Scg2</th>\n",
       "      <th>Sln</th>\n",
       "      <th>Sst</th>\n",
       "      <th>Tac1</th>\n",
       "      <th>Tac2</th>\n",
       "      <th>Th</th>\n",
       "      <th>Trh</th>\n",
       "      <th>Ucn3</th>\n",
       "      <th>Vgf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485657</th>\n",
       "      <td>4e351e96-f396-40f7-a85a-2359872522ea</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3308.167376</td>\n",
       "      <td>-785.326695</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.130728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.570399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485658</th>\n",
       "      <td>0532b480-e573-4aea-903c-8bbb63073c28</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3304.085838</td>\n",
       "      <td>-752.161365</td>\n",
       "      <td>Endothelial 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035509</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485659</th>\n",
       "      <td>de1aa791-7745-4d92-a157-1b3728e642d1</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3302.139228</td>\n",
       "      <td>-804.944667</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485660</th>\n",
       "      <td>1041b7cc-10ce-434e-a355-ebaad7ad5477</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3290.053075</td>\n",
       "      <td>-903.291624</td>\n",
       "      <td>Astrocyte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485661</th>\n",
       "      <td>a4d7cf41-3bb0-4dc5-8e8e-8a2dba676194</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3288.516458</td>\n",
       "      <td>-829.594599</td>\n",
       "      <td>Endothelial 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028412</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Cell_ID  Animal_ID Animal_sex   Behavior  \\\n",
       "485657  4e351e96-f396-40f7-a85a-2359872522ea         16     Female  Parenting   \n",
       "485658  0532b480-e573-4aea-903c-8bbb63073c28         16     Female  Parenting   \n",
       "485659  de1aa791-7745-4d92-a157-1b3728e642d1         16     Female  Parenting   \n",
       "485660  1041b7cc-10ce-434e-a355-ebaad7ad5477         16     Female  Parenting   \n",
       "485661  a4d7cf41-3bb0-4dc5-8e8e-8a2dba676194         16     Female  Parenting   \n",
       "\n",
       "        Bregma   Centroid_X  Centroid_Y     Cell_class Neuron_cluster_ID  \\\n",
       "485657    0.26 -3308.167376 -785.326695      Ambiguous               NaN   \n",
       "485658    0.26 -3304.085838 -752.161365  Endothelial 1               NaN   \n",
       "485659    0.26 -3302.139228 -804.944667      Ambiguous               NaN   \n",
       "485660    0.26 -3290.053075 -903.291624      Astrocyte               NaN   \n",
       "485661    0.26 -3288.516458 -829.594599  Endothelial 2               NaN   \n",
       "\n",
       "        Ace2  ...  Penk      Scg2       Sln       Sst      Tac1      Tac2  \\\n",
       "485657   0.0  ...   0.0  0.000000  0.000000  0.006684  0.000000  0.005351   \n",
       "485658   0.0  ...   0.0  0.042109  0.121758  0.000000  0.035509  0.000065   \n",
       "485659   0.0  ...   0.0  0.000000  0.000000  0.000000  0.018027  0.000000   \n",
       "485660   0.0  ...   0.0  0.000000  0.000000  0.012018  0.017317  0.000000   \n",
       "485661   0.0  ...   0.0  0.000000  0.000000  0.012636  0.009897  0.000000   \n",
       "\n",
       "              Th       Trh      Ucn3       Vgf  \n",
       "485657  0.130728  0.000000  0.001195  0.570399  \n",
       "485658  0.018795  0.000145  0.000000  0.000000  \n",
       "485659  0.005419  0.010961  0.000000  0.947691  \n",
       "485660  0.000000  0.024745  0.012103  0.000000  \n",
       "485661  0.000000  0.028412  0.012981  0.000000  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MESSI_jupyter_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latter-northeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-08a28c1950fb>:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if filtered_df[\"Animal_ID\"].unique() != []:\n",
      "<ipython-input-18-08a28c1950fb>:7: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if filtered_df[\"Animal_ID\"].unique() != []:\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "cell_categories = list(it.product(sexes, behaviors, celltypes))\n",
    "for category in cell_categories:\n",
    "    sex, behavior, celltype = category\n",
    "    filtered_df = merfish_df[(merfish_df['Animal_sex'] == sex) & (merfish_df['Behavior'] == behavior) & (merfish_df['Cell_class'] == celltype)]\n",
    "    if filtered_df[\"Animal_ID\"].unique() != []:\n",
    "        MESSI_jupyter_example.to_csv(f'../data/raw/merfish_messi/{sex}_{behavior}_{celltype}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alive-marine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n"
     ]
    }
   ],
   "source": [
    "for category in cell_categories:\n",
    "    sex, behavior, celltype = category\n",
    "    filtered_df = merfish_df[(merfish_df['Animal_sex'] == sex) & (merfish_df['Behavior'] == behavior) & (merfish_df['Cell_class'] == celltype)]\n",
    "    print(filtered_df[\"Animal_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example.to_csv('../data/raw/merfish_messi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-finder",
   "metadata": {},
   "source": [
    "# Step 2: Create the torch Geometric object that represents this subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "communist-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/non_response.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(160)) - set(self.features))\n",
    "\n",
    "        data_list = self.construct_graphs(n_neighbors, train, log_transform)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[144] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish_messi.csv\", \"merfish_messi.hdf5\"]\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.csv\")\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(self, data, anid, breg, n_neighbors, log_transform):\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "        nbrs = neighbors.NearestNeighbors(\n",
    "            n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "        )\n",
    "        nbrs.fit(locations_for_this_slice)\n",
    "        _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "        edges = np.concatenate(\n",
    "            [np.c_[kneighbors[:, 0], kneighbors[:, i + 1]] for i in range(n_neighbors)],\n",
    "            axis=0,\n",
    "        )\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "        )\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minimal-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_messi_csv = pd.read_csv('../data/raw/merfish_messi.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secure-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MerfishDataset('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-beast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MerfishDataset(16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-marriage",
   "metadata": {},
   "source": [
    "#### The code below just shows that the graph objects are created identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "double-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/raw/merfish_messi.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infinite-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_ID\n",
      "Animal_sex\n",
      "Behavior\n",
      "Bregma\n",
      "Cell_ID\n",
      "Cell_class\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "Neuron_cluster_ID\n",
      "expression\n",
      "gene_names\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conservative-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/raw/merfish.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_ID\n",
      "Animal_sex\n",
      "Behavior\n",
      "Bregma\n",
      "Cell_ID\n",
      "Cell_class\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "Neuron_cluster_ID\n",
      "expression\n",
      "gene_names\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-russia",
   "metadata": {},
   "source": [
    "# Step 3: Get a Trained and Tested Example Running!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-waterproof",
   "metadata": {},
   "source": [
    "Just use the filtered merfish dataset in the train.py and predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-disposal",
   "metadata": {},
   "source": [
    "This will be accomplished by creating a class that inherits from MerfishDataset, overwrites the methods I change, and run a new example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-figure",
   "metadata": {},
   "source": [
    "# Step 4: Testing the Trained Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-course",
   "metadata": {},
   "source": [
    "Make sure that in predict.py that the correct checkpoint file is selected for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separated-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatial import predict, train\n",
    "from spatial.merfish_dataset import MerfishDataset, FilteredMerfishDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "going-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from spatial.merfish_dataset import FilteredMerfishDataset, MerfishDataset\n",
    "from spatial.models.monet_ae import MonetAutoencoder2D, TrivialAutoencoder\n",
    "from spatial.train import train\n",
    "from spatial.predict import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-neighborhood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/omegaconf/omegaconf.py:572: UserWarning: update() merge flag is is not specified, defaulting to False.\n",
      "For more details, see https://github.com/omry/omegaconf/issues/367\n",
      "  warnings.warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Checkpoint directory /home/roko/spatial//output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25343bc56b724cf0944bec1317656268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.23230068385601044,\n",
      " 'test_loss: mae_response': 0.36871105432510376,\n",
      " 'test_loss: mse': 0.2573970556259155}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# equivalent to spatial\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "\n",
    "with initialize(config_path=\"../config\"):\n",
    "    cfg_from_terminal = compose(config_name=\"config\")\n",
    "    # for now just to keep the code running\n",
    "    output = test(cfg_from_terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-parts",
   "metadata": {},
   "source": [
    "# Choosing the Correct Filtered Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-riding",
   "metadata": {},
   "source": [
    "We can see in the source code that the cell types are listed as follows:\n",
    "\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    \n",
    "So, we can keep only the cell types the MESSI uses to evaluate their performance. These would be [1, 2, 6, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunrise-duration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer, l1_losses, inputs, gene_expressions, celltypes = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "major-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = torch.tensor(MerfishDataset('../data').responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-adventure",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excitatory_cells = (celltypes == 6).nonzero(as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepST_inputs = torch.index_select(torch.index_select(inputs, 0, excitatory_cells), 1, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monetary-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(deepST_inputs.numpy())\n",
    "df.to_csv(\"results/inputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civilian-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepST_outputs = torch.index_select(torch.index_select(gene_expressions, 0, excitatory_cells), 1, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superb-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(deepST_outputs.numpy())\n",
    "df.to_csv(\"results/deepST_outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "covered-possession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.4199e-02, 4.9734e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 9.5009e-01, 9.5009e-01,  ..., 1.4219e-02, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [6.1154e-01, 1.2611e+00, 0.0000e+00,  ..., 3.8231e-02, 6.9036e-03,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6553e-03, 5.8650e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.4980e+00,  ..., 8.1744e-04, 6.8809e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6887e-03, 0.0000e+00,\n",
       "         4.6684e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-diving",
   "metadata": {},
   "source": [
    "# Step 5: Testing the Filtered Merfish Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-namibia",
   "metadata": {},
   "source": [
    "The goal is rather than saving every (anid, bregma) combination of cells, we can filter it by overwriting the merfish_csv method and filtering the dataset in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "rational-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the original class we are inheriting from.\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/non_response.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(160)) - set(self.features))\n",
    "\n",
    "        data_list = self.construct_graphs(n_neighbors, train, log_transform)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[144] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish.csv\", \"merfish.hdf5\"]\n",
    "\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.csv\")\n",
    "\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        print(self.merfish_csv, self.merfish_hdf5)\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "        print(dataframe.shape)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "            \n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(self, data, anid, breg, n_neighbors, log_transform):\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "        nbrs = neighbors.NearestNeighbors(\n",
    "            n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "        )\n",
    "        nbrs.fit(locations_for_this_slice)\n",
    "        _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "        edges = np.concatenate(\n",
    "            [np.c_[kneighbors[:, 0], kneighbors[:, i + 1]] for i in range(n_neighbors)],\n",
    "            axis=0,\n",
    "        )\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "        )\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "representative-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilteredMerfishDataset(MerfishDataset):\n",
    "\n",
    "    def __init__(self, root, n_neighbors=3, train=True, log_transform=True, non_response_genes_file=\"/home/roko/spatial/spatial/non_response.txt\", sexes=None, behaviors=None):\n",
    "        self.root = root\n",
    "        self.sexes = sexes\n",
    "        self.behaviors = behaviors\n",
    "        original_csv_file = super().merfish_csv\n",
    "        new_df = pd.read_csv(original_csv_file)\n",
    "        print(f\"Original Data {new_df.shape}\")\n",
    "        if self.sexes is not None:\n",
    "            new_df = new_df[new_df[\"Animal_sex\"].isin(self.sexes)]\n",
    "        if self.behaviors is not None:\n",
    "            new_df = new_df[new_df[\"Behavior\"].isin(self.behaviors)]\n",
    "        if new_df.shape[0] == 0:\n",
    "            raise ValueError(\"Dataframe has no rows. Cannot build graph.\")\n",
    "        new_df.to_csv(self.root + '/raw/merfish_messi.csv', index=False)\n",
    "        print(f\"Filtered Data {new_df.shape}\")\n",
    "        # print(\"Filtered csv file created!\")\n",
    "        MerfishDataset.download(self)\n",
    "        super().__init__(root, n_neighbors=n_neighbors, train=train, log_transform=log_transform, non_response_genes_file=non_response_genes_file)\n",
    "        # print(\"Filtered hdf5 file created!\")\n",
    "\n",
    "#     @property\n",
    "#     def raw_file_names(self):\n",
    "#         return [\"merfish_messi.csv\", \"merfish_messi.hdf5\"]\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.csv\")\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.hdf5\")\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        print(self.merfish_hdf5)\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        anid_to_bregma_count = {1: 12, 2: 12, 3: 6, 4: 5, 5: 6,\n",
    "                                6: 6, 7: 12, 8: 6, 9: 6, 10: 6,\n",
    "                                11: 6, 12: 4, 13: 4, 14: 4, 15: 4, \n",
    "                                16: 4, 17: 4, 18: 4, 19: 4, 20: 4,\n",
    "                                21: 4, 22: 4, 23: 4, 24: 4, 25: 4,\n",
    "                                26: 4, 27: 2, 28: 4, 29: 4, 30: 4}\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        min_animal = anid_to_bregma_count[np.min(data.anids)]\n",
    "        unique_slices = unique_slices[min_animal:] if train else unique_slices[:min_animal]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "rising-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (298694, 170)\n",
      "../datacopy/raw/merfish_messi.csv ../datacopy/raw/merfish_messi.hdf5\n",
      "(298694, 170)\n",
      "../datacopy/raw/merfish_messi.hdf5\n"
     ]
    }
   ],
   "source": [
    "test = FilteredMerfishDataset('../datacopy', sexes=[\"Female\", \"Male\"], behaviors=[\"Parenting\", \"Mating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "independent-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 16668], pos=[5556, 2], x=[5556, 160], y=[5556, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "nominated-parks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FilteredMerfishDataset(50)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "polar-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "../datacopy/raw/merfish_messi.csv ../datacopy/raw/merfish_messi.hdf5\n",
      "(205348, 170)\n",
      "../datacopy/raw/merfish_messi.hdf5\n"
     ]
    }
   ],
   "source": [
    "test1 = FilteredMerfishDataset('../datacopy', sexes=[\"Female\"], behaviors=[\"Naive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "latter-gregory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 18273], pos=[6091, 2], x=[6091, 160], y=[6091, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "involved-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FilteredMerfishDataset(23)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "under-renaissance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 19527], pos=[6509, 2], x=[6509, 160], y=[6509, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MerfishDataset('../datacopy')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "streaming-techno",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (298694, 170)\n",
      "../data/raw/merfish_messi.csv ../data/raw/merfish_messi.hdf5\n",
      "(298694, 170)\n",
      "../data/raw/merfish_messi.hdf5\n"
     ]
    }
   ],
   "source": [
    "test = FilteredMerfishDataset('../data', sexes=[\"Female\", \"Male\"], behaviors=[\"Parenting\", \"Mating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "olympic-claim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 16668], pos=[5556, 2], x=[5556, 160], y=[5556, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-sitting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
