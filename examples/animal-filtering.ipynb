{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cathedral-faculty",
   "metadata": {},
   "source": [
    "# Step 1: Recreating the data example in MESSI's home tutorial notebook. (Get Animals 16-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brutal-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "animated-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish_df = pd.read_csv('../data/raw/merfish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elder-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example = merfish_df[(merfish_df['Animal_sex'] == \"Female\") & (merfish_df['Behavior'] == \"Parenting\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example.to_csv('../data/raw/merfish_messi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-finder",
   "metadata": {},
   "source": [
    "# Step 2: Create the torch Geometric object that represents this subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "communist-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/non_response.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(160)) - set(self.features))\n",
    "\n",
    "        data_list = self.construct_graphs(n_neighbors, train, log_transform)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[144] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish_messi.csv\", \"merfish_messi.hdf5\"]\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.csv\")\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(self, data, anid, breg, n_neighbors, log_transform):\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "        nbrs = neighbors.NearestNeighbors(\n",
    "            n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "        )\n",
    "        nbrs.fit(locations_for_this_slice)\n",
    "        _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "        edges = np.concatenate(\n",
    "            [np.c_[kneighbors[:, 0], kneighbors[:, i + 1]] for i in range(n_neighbors)],\n",
    "            axis=0,\n",
    "        )\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "        )\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minimal-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_messi_csv = pd.read_csv('../data/raw/merfish_messi.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secure-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MerfishDataset('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-beast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MerfishDataset(16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-marriage",
   "metadata": {},
   "source": [
    "#### The code below just shows that the graph objects are created identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "double-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/raw/merfish_messi.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infinite-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_ID\n",
      "Animal_sex\n",
      "Behavior\n",
      "Bregma\n",
      "Cell_ID\n",
      "Cell_class\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "Neuron_cluster_ID\n",
      "expression\n",
      "gene_names\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conservative-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/raw/merfish.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_ID\n",
      "Animal_sex\n",
      "Behavior\n",
      "Bregma\n",
      "Cell_ID\n",
      "Cell_class\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "Neuron_cluster_ID\n",
      "expression\n",
      "gene_names\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-russia",
   "metadata": {},
   "source": [
    "# Step 3: Get a Trained and Tested Example Running!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-waterproof",
   "metadata": {},
   "source": [
    "Just use the filtered merfish dataset in the train.py and predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-disposal",
   "metadata": {},
   "source": [
    "This will be accomplished by creating a class that inherits from MerfishDataset, overwrites the methods I change, and run a new example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-figure",
   "metadata": {},
   "source": [
    "# Step 4: Testing the Trained Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-course",
   "metadata": {},
   "source": [
    "Make sure that in predict.py that the correct checkpoint file is selected for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "separated-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatial import predict, train\n",
    "from spatial.merfish_dataset import MerfishDataset, FilteredMerfishDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "going-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from spatial.merfish_dataset import FilteredMerfishDataset, MerfishDataset\n",
    "from spatial.models.monet_ae import MonetAutoencoder2D, TrivialAutoencoder\n",
    "from spatial.train import train\n",
    "from spatial.predict import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-neighborhood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/omegaconf/omegaconf.py:572: UserWarning: update() merge flag is is not specified, defaulting to False.\n",
      "For more details, see https://github.com/omry/omegaconf/issues/367\n",
      "  warnings.warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Checkpoint directory /home/roko/spatial//output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25343bc56b724cf0944bec1317656268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.23230068385601044,\n",
      " 'test_loss: mae_response': 0.36871105432510376,\n",
      " 'test_loss: mse': 0.2573970556259155}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# equivalent to spatial\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "\n",
    "with initialize(config_path=\"../config\"):\n",
    "    cfg_from_terminal = compose(config_name=\"config\")\n",
    "    # for now just to keep the code running\n",
    "    output = test(cfg_from_terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-parts",
   "metadata": {},
   "source": [
    "# Choosing the Correct Filtered Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-riding",
   "metadata": {},
   "source": [
    "We can see in the source code that the cell types are listed as follows:\n",
    "\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    \n",
    "So, we can keep only the cell types the MESSI uses to evaluate their performance. These would be [1, 2, 6, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunrise-duration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer, l1_losses, inputs, gene_expressions, celltypes = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "major-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = torch.tensor(MerfishDataset('../data').responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-adventure",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excitatory_cells = (celltypes == 6).nonzero(as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepST_inputs = torch.index_select(torch.index_select(inputs, 0, excitatory_cells), 1, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monetary-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(deepST_inputs.numpy())\n",
    "df.to_csv(\"results/inputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civilian-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepST_outputs = torch.index_select(torch.index_select(gene_expressions, 0, excitatory_cells), 1, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superb-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(deepST_outputs.numpy())\n",
    "df.to_csv(\"results/deepST_outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "covered-possession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.4199e-02, 4.9734e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 9.5009e-01, 9.5009e-01,  ..., 1.4219e-02, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [6.1154e-01, 1.2611e+00, 0.0000e+00,  ..., 3.8231e-02, 6.9036e-03,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6553e-03, 5.8650e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.4980e+00,  ..., 8.1744e-04, 6.8809e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6887e-03, 0.0000e+00,\n",
       "         4.6684e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-regard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
