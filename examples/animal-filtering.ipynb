{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cathedral-faculty",
   "metadata": {},
   "source": [
    "# Step 1: Recreating the data example in MESSI's home tutorial notebook. (Get Animals 16-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "brutal-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "animated-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish_df = pd.read_csv('../data/raw/merfish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "floppy-melissa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Female', 'Male'], dtype=object),\n",
       " array(['Naive', 'Parenting', 'Virgin Parenting', 'Aggression to pup',\n",
       "        'Aggression to adult', 'Mating'], dtype=object),\n",
       " array(['Astrocyte', 'Inhibitory', 'OD Mature 2', 'Endothelial 1',\n",
       "        'Ambiguous', 'Pericytes', 'Endothelial 2', 'OD Mature 1',\n",
       "        'OD Immature 1', 'Excitatory', 'Microglia', 'Endothelial 3',\n",
       "        'OD Mature 4', 'OD Immature 2', 'OD Mature 3', 'Ependymal'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexes = merfish_df[\"Animal_sex\"].unique()\n",
    "behaviors = merfish_df[\"Behavior\"].unique()\n",
    "celltypes = merfish_df[\"Cell_class\"].unique()\n",
    "(sexes, behaviors, celltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "domestic-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish_df.to_csv('justatest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sophisticated-external",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027848, 170)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = merfish_df[(merfish_df[\"Animal_sex\"].isin([\"Female\", \"Male\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wicked-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485657, 170)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[(merfish_df[\"Behavior\"].isin([\"Naive\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accurate-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457111, 170)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = merfish_df[(merfish_df[\"Animal_sex\"].isin([\"Female\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indian-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86902, 170)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df[(new_df[\"Behavior\"].isin([\"Parenting\"]))]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "straight-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 12\n",
      "2 12\n",
      "3 6\n",
      "4 5\n",
      "5 6\n",
      "6 6\n",
      "7 12\n",
      "8 6\n",
      "9 6\n",
      "10 6\n",
      "11 6\n",
      "12 4\n",
      "13 4\n",
      "14 4\n",
      "15 4\n",
      "16 4\n",
      "17 4\n",
      "18 4\n",
      "19 4\n",
      "20 4\n",
      "21 4\n",
      "22 4\n",
      "23 4\n",
      "24 4\n",
      "25 4\n",
      "26 4\n",
      "27 2\n",
      "28 4\n",
      "29 4\n",
      "30 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 31):\n",
    "    merfish_df_subset = merfish_df[merfish_df['Animal_ID'] == i]\n",
    "    print(i, len(merfish_df_subset['Bregma'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "elder-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example = merfish_df[(merfish_df['Animal_sex'] == \"Female\") & (merfish_df['Behavior'] == \"Parenting\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "signed-cheat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_ID</th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Animal_sex</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Bregma</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Cell_class</th>\n",
       "      <th>Neuron_cluster_ID</th>\n",
       "      <th>Ace2</th>\n",
       "      <th>...</th>\n",
       "      <th>Penk</th>\n",
       "      <th>Scg2</th>\n",
       "      <th>Sln</th>\n",
       "      <th>Sst</th>\n",
       "      <th>Tac1</th>\n",
       "      <th>Tac2</th>\n",
       "      <th>Th</th>\n",
       "      <th>Trh</th>\n",
       "      <th>Ucn3</th>\n",
       "      <th>Vgf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485657</th>\n",
       "      <td>4e351e96-f396-40f7-a85a-2359872522ea</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3308.167376</td>\n",
       "      <td>-785.326695</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.130728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.570399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485658</th>\n",
       "      <td>0532b480-e573-4aea-903c-8bbb63073c28</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3304.085838</td>\n",
       "      <td>-752.161365</td>\n",
       "      <td>Endothelial 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035509</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.018795</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485659</th>\n",
       "      <td>de1aa791-7745-4d92-a157-1b3728e642d1</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3302.139228</td>\n",
       "      <td>-804.944667</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485660</th>\n",
       "      <td>1041b7cc-10ce-434e-a355-ebaad7ad5477</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3290.053075</td>\n",
       "      <td>-903.291624</td>\n",
       "      <td>Astrocyte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485661</th>\n",
       "      <td>a4d7cf41-3bb0-4dc5-8e8e-8a2dba676194</td>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>Parenting</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3288.516458</td>\n",
       "      <td>-829.594599</td>\n",
       "      <td>Endothelial 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028412</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Cell_ID  Animal_ID Animal_sex   Behavior  \\\n",
       "485657  4e351e96-f396-40f7-a85a-2359872522ea         16     Female  Parenting   \n",
       "485658  0532b480-e573-4aea-903c-8bbb63073c28         16     Female  Parenting   \n",
       "485659  de1aa791-7745-4d92-a157-1b3728e642d1         16     Female  Parenting   \n",
       "485660  1041b7cc-10ce-434e-a355-ebaad7ad5477         16     Female  Parenting   \n",
       "485661  a4d7cf41-3bb0-4dc5-8e8e-8a2dba676194         16     Female  Parenting   \n",
       "\n",
       "        Bregma   Centroid_X  Centroid_Y     Cell_class Neuron_cluster_ID  \\\n",
       "485657    0.26 -3308.167376 -785.326695      Ambiguous               NaN   \n",
       "485658    0.26 -3304.085838 -752.161365  Endothelial 1               NaN   \n",
       "485659    0.26 -3302.139228 -804.944667      Ambiguous               NaN   \n",
       "485660    0.26 -3290.053075 -903.291624      Astrocyte               NaN   \n",
       "485661    0.26 -3288.516458 -829.594599  Endothelial 2               NaN   \n",
       "\n",
       "        Ace2  ...  Penk      Scg2       Sln       Sst      Tac1      Tac2  \\\n",
       "485657   0.0  ...   0.0  0.000000  0.000000  0.006684  0.000000  0.005351   \n",
       "485658   0.0  ...   0.0  0.042109  0.121758  0.000000  0.035509  0.000065   \n",
       "485659   0.0  ...   0.0  0.000000  0.000000  0.000000  0.018027  0.000000   \n",
       "485660   0.0  ...   0.0  0.000000  0.000000  0.012018  0.017317  0.000000   \n",
       "485661   0.0  ...   0.0  0.000000  0.000000  0.012636  0.009897  0.000000   \n",
       "\n",
       "              Th       Trh      Ucn3       Vgf  \n",
       "485657  0.130728  0.000000  0.001195  0.570399  \n",
       "485658  0.018795  0.000145  0.000000  0.000000  \n",
       "485659  0.005419  0.010961  0.000000  0.947691  \n",
       "485660  0.000000  0.024745  0.012103  0.000000  \n",
       "485661  0.000000  0.028412  0.012981  0.000000  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MESSI_jupyter_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9454f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example = merfish_df[(merfish_df['Animal_ID'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25a0cc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_ID</th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Animal_sex</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Bregma</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Cell_class</th>\n",
       "      <th>Neuron_cluster_ID</th>\n",
       "      <th>Ace2</th>\n",
       "      <th>...</th>\n",
       "      <th>Penk</th>\n",
       "      <th>Scg2</th>\n",
       "      <th>Sln</th>\n",
       "      <th>Sst</th>\n",
       "      <th>Tac1</th>\n",
       "      <th>Tac2</th>\n",
       "      <th>Th</th>\n",
       "      <th>Trh</th>\n",
       "      <th>Ucn3</th>\n",
       "      <th>Vgf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6749ccb4-2ed1-4029-968f-820a287f43c8</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3211.562145</td>\n",
       "      <td>2608.541476</td>\n",
       "      <td>Astrocyte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865263</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.054826</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6cac74bd-4ea7-4701-8701-42563cc65eb8</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3207.923151</td>\n",
       "      <td>2621.795437</td>\n",
       "      <td>Inhibitory</td>\n",
       "      <td>I-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277939</td>\n",
       "      <td>0.868702</td>\n",
       "      <td>0.580957</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9f29bd57-16a5-4b26-b9f5-37598809da9e</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3209.578004</td>\n",
       "      <td>2633.153494</td>\n",
       "      <td>Inhibitory</td>\n",
       "      <td>I-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377907</td>\n",
       "      <td>0.049332</td>\n",
       "      <td>0.084898</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d7eb4e0b-276e-47e3-a55c-0b033180a2fe</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3203.853515</td>\n",
       "      <td>2756.045983</td>\n",
       "      <td>Inhibitory</td>\n",
       "      <td>I-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>0.089038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.031364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54434f3a-eba9-4aec-af35-c9d317ffa1d5</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-3202.682705</td>\n",
       "      <td>2608.803635</td>\n",
       "      <td>Inhibitory</td>\n",
       "      <td>I-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250661</td>\n",
       "      <td>0.159618</td>\n",
       "      <td>0.211159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Cell_ID  Animal_ID Animal_sex Behavior  \\\n",
       "0  6749ccb4-2ed1-4029-968f-820a287f43c8          1     Female    Naive   \n",
       "1  6cac74bd-4ea7-4701-8701-42563cc65eb8          1     Female    Naive   \n",
       "2  9f29bd57-16a5-4b26-b9f5-37598809da9e          1     Female    Naive   \n",
       "3  d7eb4e0b-276e-47e3-a55c-0b033180a2fe          1     Female    Naive   \n",
       "4  54434f3a-eba9-4aec-af35-c9d317ffa1d5          1     Female    Naive   \n",
       "\n",
       "   Bregma   Centroid_X   Centroid_Y  Cell_class Neuron_cluster_ID  Ace2  ...  \\\n",
       "0    0.26 -3211.562145  2608.541476   Astrocyte               NaN   0.0  ...   \n",
       "1    0.26 -3207.923151  2621.795437  Inhibitory               I-5   0.0  ...   \n",
       "2    0.26 -3209.578004  2633.153494  Inhibitory               I-6   0.0  ...   \n",
       "3    0.26 -3203.853515  2756.045983  Inhibitory               I-5   0.0  ...   \n",
       "4    0.26 -3202.682705  2608.803635  Inhibitory               I-9   0.0  ...   \n",
       "\n",
       "       Penk      Scg2       Sln       Sst      Tac1      Tac2   Th  Trh  Ucn3  \\\n",
       "0  0.133016  0.000000  0.865263  0.002977  0.054826  0.008934  0.0  0.0   0.0   \n",
       "1  0.000000  0.000000  0.277939  0.868702  0.580957  0.010079  0.0  0.0   0.0   \n",
       "2  0.213939  0.000000  0.377907  0.049332  0.084898  0.008951  0.0  0.0   0.0   \n",
       "3  0.050882  0.089038  0.000000  0.000000  0.001530  0.031364  0.0  0.0   0.0   \n",
       "4  1.250661  0.159618  0.211159  0.000000  0.087730  0.000000  0.0  0.0   0.0   \n",
       "\n",
       "        Vgf  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.001138  \n",
       "4  0.029419  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MESSI_jupyter_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latter-northeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-08a28c1950fb>:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if filtered_df[\"Animal_ID\"].unique() != []:\n",
      "<ipython-input-18-08a28c1950fb>:7: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if filtered_df[\"Animal_ID\"].unique() != []:\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "cell_categories = list(it.product(sexes, behaviors, celltypes))\n",
    "for category in cell_categories:\n",
    "    sex, behavior, celltype = category\n",
    "    filtered_df = merfish_df[(merfish_df['Animal_sex'] == sex) & (merfish_df['Behavior'] == behavior) & (merfish_df['Cell_class'] == celltype)]\n",
    "    if filtered_df[\"Animal_ID\"].unique() != []:\n",
    "        MESSI_jupyter_example.to_csv(f'../data/raw/merfish_messi/{sex}_{behavior}_{celltype}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alive-marine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[16 17 18 19]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[20 21 22 23 24]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[25 26 27]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[ 5  6  7  8  9 10 11]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[12 13 14 15]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[34 35 36]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[31 32 33]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n",
      "[28 29 30]\n"
     ]
    }
   ],
   "source": [
    "for category in cell_categories:\n",
    "    sex, behavior, celltype = category\n",
    "    filtered_df = merfish_df[(merfish_df['Animal_sex'] == sex) & (merfish_df['Behavior'] == behavior) & (merfish_df['Cell_class'] == celltype)]\n",
    "    print(filtered_df[\"Animal_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSI_jupyter_example.to_csv('../data/raw/merfish_messi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-finder",
   "metadata": {},
   "source": [
    "# Step 2: Create the torch Geometric object that represents this subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "communist-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/non_response.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(160)) - set(self.features))\n",
    "\n",
    "        data_list = self.construct_graphs(n_neighbors, train, log_transform)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[144] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish_messi.csv\", \"merfish_messi.hdf5\"]\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.csv\")\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(self, data, anid, breg, n_neighbors, log_transform):\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "        nbrs = neighbors.NearestNeighbors(\n",
    "            n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "        )\n",
    "        nbrs.fit(locations_for_this_slice)\n",
    "        _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "        edges = np.concatenate(\n",
    "            [np.c_[kneighbors[:, 0], kneighbors[:, i + 1]] for i in range(n_neighbors)],\n",
    "            axis=0,\n",
    "        )\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "        )\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train, log_transform=True):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(data, anid, breg, n_neighbors, log_transform)\n",
    "            )\n",
    "\n",
    "        return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minimal-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_messi_csv = pd.read_csv('../data/raw/merfish_messi.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secure-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MerfishDataset('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-beast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MerfishDataset(16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-marriage",
   "metadata": {},
   "source": [
    "#### The code below just shows that the graph objects are created identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "double-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/raw/merfish_messi.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infinite-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_ID\n",
      "Animal_sex\n",
      "Behavior\n",
      "Bregma\n",
      "Cell_ID\n",
      "Cell_class\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "Neuron_cluster_ID\n",
      "expression\n",
      "gene_names\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conservative-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/raw/merfish.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal_ID\n",
      "Animal_sex\n",
      "Behavior\n",
      "Bregma\n",
      "Cell_ID\n",
      "Cell_class\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "Neuron_cluster_ID\n",
      "expression\n",
      "gene_names\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the groups in HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-russia",
   "metadata": {},
   "source": [
    "# Step 3: Get a Trained and Tested Example Running!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-waterproof",
   "metadata": {},
   "source": [
    "Just use the filtered merfish dataset in the train.py and predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-disposal",
   "metadata": {},
   "source": [
    "This will be accomplished by creating a class that inherits from MerfishDataset, overwrites the methods I change, and run a new example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-figure",
   "metadata": {},
   "source": [
    "# Step 4: Testing the Trained Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-course",
   "metadata": {},
   "source": [
    "Make sure that in predict.py that the correct checkpoint file is selected for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separated-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatial import predict, train\n",
    "from spatial.merfish_dataset import MerfishDataset, FilteredMerfishDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from spatial.merfish_dataset import FilteredMerfishDataset, MerfishDataset\n",
    "from spatial.models.monet_ae import MonetAutoencoder2D, TrivialAutoencoder\n",
    "from spatial.train import train\n",
    "from spatial.predict import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "republican-neighborhood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Error instantiating 'spatial.merfish_dataset.FilteredMerfishDataset' : __init__() got an unexpected keyword argument 'animals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:62\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             v\u001b[38;5;241m.\u001b[39m_set_parent(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'animals'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m cfg_from_terminal \u001b[38;5;241m=\u001b[39m compose(config_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# for now just to keep the code running\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_from_terminal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spatial/spatial/predict.py:23\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(cfg, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(cfg: DictConfig, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Set up testing data.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# ensuring data dimension is correct\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mobservables_dimension \u001b[38;5;241m!=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:180\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     _recursive_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mRECURSIVE, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    178\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop level config has to be OmegaConf DictConfig, plain dict, or a Structured Config class or instance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:249\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, *args)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 value \u001b[38;5;241m=\u001b[39m instantiate_node(\n\u001b[1;32m    246\u001b[0m                     value, convert\u001b[38;5;241m=\u001b[39mconvert, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    247\u001b[0m                 )\n\u001b[1;32m    248\u001b[0m             kwargs[key] \u001b[38;5;241m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured, instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    253\u001b[0m         convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mPARTIAL \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mobject_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     ):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:64\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _target_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_convert_target_to_string(_target_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     )\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:62\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_config(v):\n\u001b[1;32m     60\u001b[0m             v\u001b[38;5;241m.\u001b[39m_set_parent(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_convert_target_to_string(_target_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     )\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: Error instantiating 'spatial.merfish_dataset.FilteredMerfishDataset' : __init__() got an unexpected keyword argument 'animals'"
     ]
    }
   ],
   "source": [
    "# equivalent to spatial\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "\n",
    "with initialize(config_path=\"../config\"):\n",
    "    cfg_from_terminal = compose(config_name=\"config\")\n",
    "    # for now just to keep the code running\n",
    "    output = test(cfg_from_terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-parts",
   "metadata": {},
   "source": [
    "# Choosing the Correct Filtered Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-riding",
   "metadata": {},
   "source": [
    "We can see in the source code that the cell types are listed as follows:\n",
    "\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    \n",
    "So, we can keep only the cell types the MESSI uses to evaluate their performance. These would be [1, 2, 6, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-duration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainer, l1_losses, inputs, gene_expressions, celltypes, test_results = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = torch.tensor(MerfishDataset('../data').responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-adventure",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excitatory_cells = (celltypes == 6).nonzero(as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepST_inputs = torch.index_select(torch.index_select(inputs, 0, excitatory_cells), 1, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monetary-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(deepST_inputs.numpy())\n",
    "df.to_csv(\"results/inputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civilian-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepST_outputs = torch.index_select(torch.index_select(gene_expressions, 0, excitatory_cells), 1, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superb-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(deepST_outputs.numpy())\n",
    "df.to_csv(\"results/deepST_outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "covered-possession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.4199e-02, 4.9734e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 9.5009e-01, 9.5009e-01,  ..., 1.4219e-02, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [6.1154e-01, 1.2611e+00, 0.0000e+00,  ..., 3.8231e-02, 6.9036e-03,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6553e-03, 5.8650e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.4980e+00,  ..., 8.1744e-04, 6.8809e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6887e-03, 0.0000e+00,\n",
       "         4.6684e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-diving",
   "metadata": {},
   "source": [
    "# Step 5: Testing the Filtered Merfish Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-namibia",
   "metadata": {},
   "source": [
    "The goal is rather than saving every (anid, bregma) combination of cells, we can filter it by overwriting the merfish_csv method and filtering the dataset in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a3ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "import json\n",
    "import itertools as it\n",
    "import pathlib\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rational-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        neighbor_celltypes=False,\n",
    "        radius=None,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/\"\n",
    "        \"non_response_blank_removed.txt\",\n",
    "    ):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # non-response genes (columns) in MERFISH\n",
    "        with open(non_response_genes_file, \"r\", encoding=\"utf8\") as genes_file:\n",
    "            self.features = [int(x) for x in genes_file.read().split(\",\")]\n",
    "            genes_file.close()\n",
    "\n",
    "        # response genes (columns in MERFISH)\n",
    "        self.responses = list(set(range(155)) - set(self.features))\n",
    "        # REMOVE LATER (responses are specific genes)\n",
    "        self.responses = [93]\n",
    "\n",
    "        data_list = self.construct_graphs(\n",
    "            n_neighbors, train, log_transform, neighbor_celltypes, radius\n",
    "        )\n",
    "\n",
    "        print(data_list)\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    # from https://datadryad.org/stash/dataset/doi:10.5061/dryad.8t8s248\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[[12, 13, 14, 15, 16, 144]] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish.csv\", \"merfish.hdf5\"]\n",
    "\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.csv\")\n",
    "\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(\n",
    "        self, data, anid, breg, n_neighbors, log_transform, neighbor_celltypes, radius\n",
    "    ):\n",
    "        def get_neighbors(edges, x_shape):\n",
    "            return [edges[:, edges[0] == i][1] for i in range(x_shape)]\n",
    "\n",
    "        def get_celltype_simplex(cell_behavior_tensor, neighbors_tensor):\n",
    "            num_classes = cell_behavior_tensor.max() + 1\n",
    "            return torch.cat(\n",
    "                [\n",
    "                    (\n",
    "                        torch.mean(\n",
    "                            1.0\n",
    "                            * F.one_hot(\n",
    "                                cell_behavior_tensor.index_select(0, neighbors),\n",
    "                                num_classes=num_classes,\n",
    "                            ),\n",
    "                            dim=0,\n",
    "                        )\n",
    "                    ).unsqueeze(0)\n",
    "                    for neighbors in neighbors_tensor\n",
    "                ],\n",
    "                dim=0,\n",
    "            )\n",
    "\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "\n",
    "        # only include self edges if n_neighbors is 0\n",
    "        if n_neighbors == 0:\n",
    "            edges = np.concatenate(\n",
    "                [\n",
    "                    np.c_[np.array([i]), np.array([i])]\n",
    "                    for i in range(locations_for_this_slice.shape[0])\n",
    "                ],\n",
    "                axis=0,\n",
    "            )\n",
    "            print(edges)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if radius is None:\n",
    "                nbrs = neighbors.NearestNeighbors(\n",
    "                    n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "                )\n",
    "                nbrs.fit(locations_for_this_slice)\n",
    "                _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "                edges = np.concatenate(\n",
    "                    [\n",
    "                        np.c_[kneighbors[:, 0], kneighbors[:, i]]\n",
    "                        for i in range(n_neighbors + 1)\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "\n",
    "                tree = cKDTree(locations_for_this_slice)\n",
    "                kneighbors = tree.query_ball_point(\n",
    "                    locations_for_this_slice, r=radius, return_sorted=False\n",
    "                )\n",
    "                edges = np.concatenate(\n",
    "                    [\n",
    "                        np.c_[\n",
    "                            np.repeat(i, len(kneighbors[i]) - 1),\n",
    "                            [x for x in kneighbors[i] if x != i],\n",
    "                        ]\n",
    "                        for i in range(len(kneighbors))\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "\n",
    "        # if we want to first log transform the data, we do it here\n",
    "        # make this one return statement only changing x\n",
    "        predictors_x = torch.tensor(subexpression.astype(np.float32))\n",
    "        if neighbor_celltypes:\n",
    "            test_simplex = get_celltype_simplex(\n",
    "                torch.tensor(labelinfo[:, 1]),\n",
    "                get_neighbors(edges, predictors_x.shape[0]),\n",
    "            )\n",
    "            predictors_x = torch.cat((predictors_x, test_simplex), dim=1)\n",
    "        if log_transform:\n",
    "            predictors_x = torch.log1p(predictors_x)\n",
    "\n",
    "        return torch_geometric.data.Data(\n",
    "            x=predictors_x,\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "            bregma=breg,\n",
    "        )\n",
    "\n",
    "    def construct_graphs(\n",
    "        self,\n",
    "        n_neighbors,\n",
    "        train,\n",
    "        log_transform=True,\n",
    "        neighbor_celltypes=False,\n",
    "        radius=None,\n",
    "    ):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "            num_graphs = int(np.ceil(max(0, (n_neighbors - 3) // 2) + 1))\n",
    "\n",
    "            # print(num_graphs)\n",
    "\n",
    "            data_graphs = []\n",
    "\n",
    "            # for each new graph\n",
    "            for i in range(1, num_graphs + 1):\n",
    "\n",
    "                # subset 1/num_graphs of the data based on quantiles\n",
    "                graph_filter = np.where(\n",
    "                    (\n",
    "                        data.locations[:, 0]\n",
    "                        <= np.quantile(data.locations[:, 0], i / num_graphs)\n",
    "                    )\n",
    "                    & (\n",
    "                        data.locations[:, 0]\n",
    "                        >= np.quantile(data.locations[:, 0], (i - 1) / num_graphs)\n",
    "                    )\n",
    "                )[0]\n",
    "\n",
    "                data = types.SimpleNamespace(\n",
    "                    anids=h5f[\"Animal_ID\"][graph_filter],\n",
    "                    bregs=h5f[\"Bregma\"][graph_filter],\n",
    "                    expression=h5f[\"expression\"][graph_filter, :],\n",
    "                    locations=np.c_[\n",
    "                        h5f[\"Centroid_X\"][graph_filter], h5f[\"Centroid_Y\"][graph_filter]\n",
    "                    ],\n",
    "                    behavior=h5f[\"Behavior\"][graph_filter].astype(\"U\"),\n",
    "                    celltypes=h5f[\"Cell_class\"][graph_filter].astype(\"U\"),\n",
    "                )\n",
    "\n",
    "                data_graphs.append(data)\n",
    "\n",
    "        # see if you can update data locations AFTER data was created\n",
    "        # create a deepcopy and then split the locations\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        # print(len(data_graphs))\n",
    "        for data in data_graphs:\n",
    "\n",
    "            # get the (animal_id,bregma) pairs that define a unique slice\n",
    "            unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "            # are we looking at train or test sets?\n",
    "            unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "            # print(len(unique_slices))\n",
    "\n",
    "            for anid, breg in unique_slices:\n",
    "                data_list.append(\n",
    "                    self.construct_graph(\n",
    "                        data,\n",
    "                        anid,\n",
    "                        breg,\n",
    "                        n_neighbors,\n",
    "                        log_transform,\n",
    "                        neighbor_celltypes,\n",
    "                        radius,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "representative-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilteredMerfishDataset(MerfishDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        n_neighbors=3,\n",
    "        train=True,\n",
    "        log_transform=True,\n",
    "        neighbor_celltypes=False,\n",
    "        radius=None,\n",
    "        non_response_genes_file=\"/home/roko/spatial/spatial/\"\n",
    "        \"non_response_blank_removed.txt\",\n",
    "        animals=None,\n",
    "        bregmas=None,\n",
    "        sexes=None,\n",
    "        behaviors=None,\n",
    "        test_animal=None,\n",
    "        full_animal_holdout=False,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.animals = animals\n",
    "        self.bregmas = bregmas\n",
    "        self.sexes = sexes\n",
    "        self.behaviors = behaviors\n",
    "        self.test_animal = test_animal\n",
    "        self.full_animal_holdout = full_animal_holdout\n",
    "        original_csv_file = super().merfish_csv\n",
    "        new_df = pd.read_csv(original_csv_file)\n",
    "        # print(f\"Original Data {new_df.shape}\")\n",
    "        if self.sexes is not None:\n",
    "            new_df = new_df[new_df[\"Animal_sex\"].isin(self.sexes)]\n",
    "        if self.behaviors is not None:\n",
    "            new_df = new_df[new_df[\"Behavior\"].isin(self.behaviors)]\n",
    "        if self.animals is not None:\n",
    "            new_df = new_df[new_df[\"Animal_ID\"].isin(self.animals)]\n",
    "        if self.bregmas is not None:\n",
    "            new_df = new_df[new_df[\"Bregma\"].isin(self.bregmas)]\n",
    "        if new_df.shape[0] == 0:\n",
    "            raise ValueError(\"Dataframe has no rows. Cannot build graph.\")\n",
    "        new_df.to_csv(str(self.root) + \"/raw/merfish_messi.csv\", index=False)\n",
    "        print(f\"Filtered Data {new_df.shape}\")\n",
    "        # print(\"Filtered csv file created!\")\n",
    "        MerfishDataset.download(self)\n",
    "        super().__init__(\n",
    "            root,\n",
    "            n_neighbors=n_neighbors,\n",
    "            train=train,\n",
    "            log_transform=log_transform,\n",
    "            neighbor_celltypes=neighbor_celltypes,\n",
    "            non_response_genes_file=non_response_genes_file,\n",
    "            radius=radius,\n",
    "        )\n",
    "        # print(\"Filtered hdf5 file created!\")\n",
    "\n",
    "    #     @property\n",
    "    #     def raw_file_names(self):\n",
    "    #         return [\"merfish_messi.csv\", \"merfish_messi.hdf5\"]\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.csv\")\n",
    "\n",
    "    # THIS LINE WAS EDITED TO SHOW NEW FILE\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish_messi.hdf5\")\n",
    "\n",
    "    def construct_graphs(\n",
    "        self,\n",
    "        n_neighbors,\n",
    "        train,\n",
    "        log_transform=True,\n",
    "        neighbor_celltypes=False,\n",
    "        radius=None,\n",
    "    ):\n",
    "        print(self.merfish_hdf5)\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        anid_to_bregma_count = {\n",
    "            1: 12,\n",
    "            2: 12,\n",
    "            3: 6,\n",
    "            4: 5,\n",
    "            5: 6,\n",
    "            6: 6,\n",
    "            7: 12,\n",
    "            8: 6,\n",
    "            9: 6,\n",
    "            10: 6,\n",
    "            11: 6,\n",
    "            12: 4,\n",
    "            13: 4,\n",
    "            14: 4,\n",
    "            15: 4,\n",
    "            16: 4,\n",
    "            17: 4,\n",
    "            18: 4,\n",
    "            19: 4,\n",
    "            20: 4,\n",
    "            21: 4,\n",
    "            22: 4,\n",
    "            23: 4,\n",
    "            24: 4,\n",
    "            25: 4,\n",
    "            26: 4,\n",
    "            27: 2,\n",
    "            28: 4,\n",
    "            29: 4,\n",
    "            30: 4,\n",
    "        }\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "\n",
    "        # if we want a specific animals\n",
    "        if self.test_animal is not None:\n",
    "\n",
    "            animal_path = pathlib.Path(__file__).parent.absolute()\n",
    "            animal_path = animal_path.joinpath(\"animal_id.json\")\n",
    "            with open(animal_path, encoding=\"utf8\") as json_file:\n",
    "                animals = json.load(json_file)\n",
    "\n",
    "            for sex, behavior in it.product(self.sexes, self.behaviors):\n",
    "                try:\n",
    "                    if self.test_animal in animals[behavior][sex]:\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Animal ID {self.test_animal} does not belong\"\n",
    "                    f\"to the set of {self.behaviors}, {self.sexes} animals\"\n",
    "                )\n",
    "\n",
    "            # we need to find which of the slices\n",
    "            sorted_anids = np.sort(np.unique(data.anids))\n",
    "            slices_before_test_anid = 0\n",
    "            for anid in sorted_anids:\n",
    "                if anid != self.test_animal:\n",
    "                    slices_before_test_anid += anid_to_bregma_count[anid]\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            mask_train = np.ones(unique_slices.shape[0], dtype=bool)\n",
    "            mask_train[\n",
    "                slices_before_test_anid : (\n",
    "                    slices_before_test_anid + anid_to_bregma_count[self.test_animal]\n",
    "                )\n",
    "            ] = 0\n",
    "            unique_slices = (\n",
    "                unique_slices[(1 - mask_train).astype(\"bool\")]\n",
    "                if not train\n",
    "                else unique_slices[mask_train]\n",
    "            )\n",
    "\n",
    "        elif self.full_animal_holdout and (len(self.animals) > 1 or np.unique(unique_slices[:,0]) > 1):\n",
    "            print(f'BEFORE: {unique_slices}')\n",
    "            min_animal = anid_to_bregma_count[np.min(data.anids)]\n",
    "            unique_slices = (\n",
    "                unique_slices[min_animal:] if train else unique_slices[:min_animal]\n",
    "            )\n",
    "            print(f'AFTER: {unique_slices}')\n",
    "\n",
    "        else:\n",
    "            num_slices = len(unique_slices)\n",
    "            print(num_slices)\n",
    "            min_holdout = max(1, round((1/7)*num_slices)) \n",
    "            unique_slices = unique_slices[:(num_slices - min_holdout)] if train else unique_slices[(num_slices - min_holdout):]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(\n",
    "                self.construct_graph(\n",
    "                    data,\n",
    "                    anid,\n",
    "                    breg,\n",
    "                    n_neighbors,\n",
    "                    log_transform,\n",
    "                    neighbor_celltypes,\n",
    "                    radius,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rising-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data (348454, 170)\n",
      "../data/raw/merfish_messi.hdf5\n",
      "62\n",
      "[Data(bregma=0.11, edge_index=[2, 23196], pos=[5799, 2], x=[5799, 155], y=[5799, 2]), Data(bregma=0.16, edge_index=[2, 24268], pos=[6067, 2], x=[6067, 155], y=[6067, 2]), Data(bregma=0.11, edge_index=[2, 22908], pos=[5727, 2], x=[5727, 155], y=[5727, 2]), Data(bregma=0.16, edge_index=[2, 21136], pos=[5284, 2], x=[5284, 155], y=[5284, 2]), Data(bregma=0.11, edge_index=[2, 23556], pos=[5889, 2], x=[5889, 155], y=[5889, 2]), Data(bregma=0.16, edge_index=[2, 22944], pos=[5736, 2], x=[5736, 155], y=[5736, 2]), Data(bregma=0.11, edge_index=[2, 23060], pos=[5765, 2], x=[5765, 155], y=[5765, 2]), Data(bregma=0.16, edge_index=[2, 23356], pos=[5839, 2], x=[5839, 155], y=[5839, 2]), Data(bregma=0.11, edge_index=[2, 21716], pos=[5429, 2], x=[5429, 155], y=[5429, 2]), Data(bregma=0.16, edge_index=[2, 20572], pos=[5143, 2], x=[5143, 155], y=[5143, 2]), Data(bregma=0.11, edge_index=[2, 24000], pos=[6000, 2], x=[6000, 155], y=[6000, 2]), Data(bregma=0.16, edge_index=[2, 23120], pos=[5780, 2], x=[5780, 155], y=[5780, 2]), Data(bregma=0.11, edge_index=[2, 22612], pos=[5653, 2], x=[5653, 155], y=[5653, 2]), Data(bregma=0.16, edge_index=[2, 23392], pos=[5848, 2], x=[5848, 155], y=[5848, 2]), Data(bregma=0.11, edge_index=[2, 22224], pos=[5556, 2], x=[5556, 155], y=[5556, 2]), Data(bregma=0.16, edge_index=[2, 19620], pos=[4905, 2], x=[4905, 155], y=[4905, 2]), Data(bregma=0.11, edge_index=[2, 23160], pos=[5790, 2], x=[5790, 155], y=[5790, 2]), Data(bregma=0.16, edge_index=[2, 22252], pos=[5563, 2], x=[5563, 155], y=[5563, 2]), Data(bregma=0.11, edge_index=[2, 23520], pos=[5880, 2], x=[5880, 155], y=[5880, 2]), Data(bregma=0.16, edge_index=[2, 22476], pos=[5619, 2], x=[5619, 155], y=[5619, 2]), Data(bregma=0.11, edge_index=[2, 22844], pos=[5711, 2], x=[5711, 155], y=[5711, 2]), Data(bregma=0.16, edge_index=[2, 22016], pos=[5504, 2], x=[5504, 155], y=[5504, 2]), Data(bregma=0.11, edge_index=[2, 21668], pos=[5417, 2], x=[5417, 155], y=[5417, 2]), Data(bregma=0.16, edge_index=[2, 21444], pos=[5361, 2], x=[5361, 155], y=[5361, 2]), Data(bregma=0.11, edge_index=[2, 22660], pos=[5665, 2], x=[5665, 155], y=[5665, 2]), Data(bregma=0.16, edge_index=[2, 23868], pos=[5967, 2], x=[5967, 155], y=[5967, 2]), Data(bregma=0.11, edge_index=[2, 22132], pos=[5533, 2], x=[5533, 155], y=[5533, 2]), Data(bregma=0.16, edge_index=[2, 21568], pos=[5392, 2], x=[5392, 155], y=[5392, 2]), Data(bregma=0.11, edge_index=[2, 21132], pos=[5283, 2], x=[5283, 155], y=[5283, 2]), Data(bregma=0.16, edge_index=[2, 22480], pos=[5620, 2], x=[5620, 155], y=[5620, 2]), Data(bregma=0.11, edge_index=[2, 19508], pos=[4877, 2], x=[4877, 155], y=[4877, 2]), Data(bregma=0.16, edge_index=[2, 20516], pos=[5129, 2], x=[5129, 155], y=[5129, 2]), Data(bregma=0.11, edge_index=[2, 22496], pos=[5624, 2], x=[5624, 155], y=[5624, 2]), Data(bregma=0.16, edge_index=[2, 20848], pos=[5212, 2], x=[5212, 155], y=[5212, 2]), Data(bregma=0.11, edge_index=[2, 23428], pos=[5857, 2], x=[5857, 155], y=[5857, 2]), Data(bregma=0.16, edge_index=[2, 21796], pos=[5449, 2], x=[5449, 155], y=[5449, 2]), Data(bregma=0.11, edge_index=[2, 22424], pos=[5606, 2], x=[5606, 155], y=[5606, 2]), Data(bregma=0.16, edge_index=[2, 21472], pos=[5368, 2], x=[5368, 155], y=[5368, 2]), Data(bregma=0.11, edge_index=[2, 23756], pos=[5939, 2], x=[5939, 155], y=[5939, 2]), Data(bregma=0.16, edge_index=[2, 23844], pos=[5961, 2], x=[5961, 155], y=[5961, 2]), Data(bregma=0.11, edge_index=[2, 23376], pos=[5844, 2], x=[5844, 155], y=[5844, 2]), Data(bregma=0.16, edge_index=[2, 23548], pos=[5887, 2], x=[5887, 155], y=[5887, 2]), Data(bregma=0.11, edge_index=[2, 20600], pos=[5150, 2], x=[5150, 155], y=[5150, 2]), Data(bregma=0.16, edge_index=[2, 20564], pos=[5141, 2], x=[5141, 155], y=[5141, 2]), Data(bregma=0.11, edge_index=[2, 22704], pos=[5676, 2], x=[5676, 155], y=[5676, 2]), Data(bregma=0.16, edge_index=[2, 22396], pos=[5599, 2], x=[5599, 155], y=[5599, 2]), Data(bregma=0.11, edge_index=[2, 23508], pos=[5877, 2], x=[5877, 155], y=[5877, 2]), Data(bregma=0.16, edge_index=[2, 23260], pos=[5815, 2], x=[5815, 155], y=[5815, 2]), Data(bregma=0.11, edge_index=[2, 23016], pos=[5754, 2], x=[5754, 155], y=[5754, 2]), Data(bregma=0.16, edge_index=[2, 22032], pos=[5508, 2], x=[5508, 155], y=[5508, 2]), Data(bregma=0.11, edge_index=[2, 22800], pos=[5700, 2], x=[5700, 155], y=[5700, 2]), Data(bregma=0.16, edge_index=[2, 24076], pos=[6019, 2], x=[6019, 155], y=[6019, 2]), Data(bregma=0.11, edge_index=[2, 23264], pos=[5816, 2], x=[5816, 155], y=[5816, 2])]\n"
     ]
    }
   ],
   "source": [
    "test = FilteredMerfishDataset('../data', bregmas=[0.11, 0.16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "independent-private",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data (348454, 170)\n",
      "../data/raw/merfish_messi.hdf5\n",
      "62\n",
      "[Data(bregma=0.16, edge_index=[2, 23320], pos=[5830, 2], x=[5830, 155], y=[5830, 2]), Data(bregma=0.11, edge_index=[2, 22744], pos=[5686, 2], x=[5686, 155], y=[5686, 2]), Data(bregma=0.16, edge_index=[2, 22836], pos=[5709, 2], x=[5709, 155], y=[5709, 2]), Data(bregma=0.11, edge_index=[2, 22268], pos=[5567, 2], x=[5567, 155], y=[5567, 2]), Data(bregma=0.16, edge_index=[2, 19632], pos=[4908, 2], x=[4908, 155], y=[4908, 2]), Data(bregma=0.11, edge_index=[2, 22628], pos=[5657, 2], x=[5657, 155], y=[5657, 2]), Data(bregma=0.16, edge_index=[2, 23992], pos=[5998, 2], x=[5998, 155], y=[5998, 2]), Data(bregma=0.11, edge_index=[2, 22924], pos=[5731, 2], x=[5731, 155], y=[5731, 2]), Data(bregma=0.16, edge_index=[2, 23340], pos=[5835, 2], x=[5835, 155], y=[5835, 2])]\n"
     ]
    }
   ],
   "source": [
    "new_test = FilteredMerfishDataset('../data', bregmas=[0.11, 0.16], train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "polar-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "../datacopy/raw/merfish_messi.csv ../datacopy/raw/merfish_messi.hdf5\n",
      "(205348, 170)\n",
      "../datacopy/raw/merfish_messi.hdf5\n"
     ]
    }
   ],
   "source": [
    "test1 = FilteredMerfishDataset('../datacopy', sexes=[\"Female\"], behaviors=[\"Naive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "latter-gregory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 18273], pos=[6091, 2], x=[6091, 160], y=[6091, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "involved-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FilteredMerfishDataset(23)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "under-renaissance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 19527], pos=[6509, 2], x=[6509, 160], y=[6509, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MerfishDataset('../datacopy')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "streaming-techno",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (298694, 170)\n",
      "../data/raw/merfish_messi.csv ../data/raw/merfish_messi.hdf5\n",
      "(298694, 170)\n",
      "../data/raw/merfish_messi.hdf5\n"
     ]
    }
   ],
   "source": [
    "test = FilteredMerfishDataset('../data', sexes=[\"Female\", \"Male\"], behaviors=[\"Parenting\", \"Mating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "olympic-claim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 16668], pos=[5556, 2], x=[5556, 160], y=[5556, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-sitting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
