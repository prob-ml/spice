{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from spatial.models.monet_ae import MonetDense\n",
    "from spatial.predict_xenium import test\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the results\n",
    "test_loss_rad_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"/nfs/turbo/lsa-regier/scratch/roko/output/lightning_logs/checkpoints/MonetDenseXenium\"\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(ckpt_dir):\n",
    "    # Check if the file is a checkpoint file\n",
    "    if filename.endswith('.ckpt'):\n",
    "        model_name, hidden_layers, num_kernels, radius, run_name, optim, num_splits = filename.split(\"__\")\n",
    "        num_splits = num_splits.removesuffix(\".ckpt\")\n",
    "        num_splits = num_splits.removeprefix(\"NUM_SPLITS=\")\n",
    "        if '[512]' not in hidden_layers and \"POLAR_AND_DEGREE\" not in run_name:\n",
    "            continue\n",
    "        with initialize(config_path=\"../config\"):\n",
    "            # try:\n",
    "                try:\n",
    "                    cfg_from_terminal = compose(config_name=\"configXenium\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.data\", \"../data\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.root\", \"/nfs/turbo/lsa-regier/scratch/roko\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.kernel_size\", int(num_kernels))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.hidden_dimensions\", eval(hidden_layers))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.logger_name\", run_name)\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.trainer.strategy\", \"auto\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"radius\", int(radius))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"gpus\", [1])\n",
    "                    OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", int(num_splits))\n",
    "                    print(cfg_from_terminal.training.filepath)\n",
    "                    # Check if the key already exists in the dictionary\n",
    "                    if int(radius) in test_loss_rad_dict and int(num_kernels) in test_loss_rad_dict[int(radius)]:\n",
    "                        print(f\"Key ({int(radius)}, {int(num_kernels)}) already exists. Skipping test.\")\n",
    "                        continue\n",
    "                    output = test(cfg_from_terminal)\n",
    "                    trainer, l1_losses, inputs_BASE, gene_expressions_BASE, celltypes, test_results_BASE = output\n",
    "                    # Store the results over (radius, num_kernels) in a nested dict\n",
    "                    if int(radius) not in test_loss_rad_dict:\n",
    "                        test_loss_rad_dict[int(radius)] = {}\n",
    "                    test_loss_rad_dict[int(radius)][int(num_kernels)] = test_results_BASE[0]['test_loss']\n",
    "                except Exception as e:\n",
    "                    if \"CUDA out of memory\" in str(e):\n",
    "                        OmegaConf.update(cfg_from_terminal, \"training.filepath\", \"${model.name}__${model.kwargs.kernel_size}__${radius}__${training.logger_name}__${optimizer.name}__NUM_SPLITS=\" + str(num_splits))\n",
    "                        OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", 5)\n",
    "                        print(\"Increasing splits to 5 due to OOM error.\")\n",
    "                        output = test(cfg_from_terminal)\n",
    "                        trainer, l1_losses, inputs_BASE, gene_expressions_BASE, celltypes, test_results_BASE = output\n",
    "                        # Store the results over (radius, num_kernels) in a nested dict\n",
    "                        if int(radius) not in test_loss_rad_dict:\n",
    "                            test_loss_rad_dict[int(radius)] = {}\n",
    "                        test_loss_rad_dict[int(radius)][int(num_kernels)] = test_results_BASE[0]['test_loss']\n",
    "                    else:\n",
    "                        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_RESPONSE_FILE = \"../spatial/non_response_blank_removed_xenium.txt\"\n",
    "with open(NON_RESPONSE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    non_response_genes = f.read().split(',')\n",
    "\n",
    "non_response_genes = [int(x) for x in non_response_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_response_genes_set = set(non_response_genes)\n",
    "response_genes_indexes = [i for i in range(len(inputs_BASE[0])) if i not in non_response_genes_set]\n",
    "((inputs_BASE[:, response_genes_indexes] - gene_expressions_BASE) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_BASE[:, response_genes_indexes].mean(axis=1), gene_expressions_BASE.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a dictionary to store the losses for each kernel value\n",
    "kernel_losses = {}\n",
    "\n",
    "# Iterate through the test_loss_rad_dict to populate kernel_losses\n",
    "for radius, radius_losses in sorted(test_loss_rad_dict.items()):\n",
    "    for kernel, loss in radius_losses.items():\n",
    "        if kernel not in kernel_losses:\n",
    "            kernel_losses[kernel] = []\n",
    "        kernel_losses[kernel].append((radius, loss))\n",
    "\n",
    "# Plot the losses for each kernel value\n",
    "for kernel, losses in kernel_losses.items():\n",
    "    radii, losses = zip(*losses)  # Unpack the list of tuples into two separate tuples\n",
    "    plt.plot(radii, losses, label=f\"Kernel: {kernel}\", marker='o')\n",
    "\n",
    "plt.xlabel(\"Radius\")\n",
    "plt.ylabel(\"Test Loss\")\n",
    "plt.title(\"Test Loss for Different Kernel Values and Radius\")\n",
    "plt.xticks(range(0, 41, 5))  # Adjust x-axis tick marks to be less frequent\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_rad_dict = {}\n",
    "\n",
    "ckpt_dir = \"/nfs/turbo/lsa-regier/scratch/roko/output/lightning_logs/checkpoints/MonetDenseXenium\"\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(ckpt_dir):\n",
    "    # Check if the file is a checkpoint file\n",
    "    if filename.endswith('.ckpt'):\n",
    "        model_name, hidden_layers, num_kernels, radius, run_name, optim, num_splits = filename.split(\"__\")\n",
    "        num_splits = num_splits.removesuffix(\".ckpt\")\n",
    "        num_splits = num_splits.removeprefix(\"NUM_SPLITS=\")\n",
    "        if \"[512, 512, 512]\" not in hidden_layers or \"POLAR_AND\" not in run_name or int(radius) != 0 or int(num_kernels) != 10:\n",
    "            continue\n",
    "        with initialize(config_path=\"../config\"):\n",
    "            # try:\n",
    "                try:\n",
    "                    cfg_from_terminal = compose(config_name=\"configXenium\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.data\", \"../data\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.root\", \"/nfs/turbo/lsa-regier/scratch/roko\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.kernel_size\", int(num_kernels))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.hidden_dimensions\", eval(hidden_layers))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.logger_name\", run_name)\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.trainer.strategy\", \"auto\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"radius\", int(radius))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"gpus\", [1])\n",
    "                    OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", int(num_splits))\n",
    "                    print(cfg_from_terminal.training.filepath)\n",
    "                    # Check if the key already exists in the dictionary\n",
    "                    if int(radius) in test_loss_rad_dict and int(num_kernels) in test_loss_rad_dict[int(radius)]:\n",
    "                        print(f\"Key ({int(radius)}, {int(num_kernels)}) already exists. Skipping test.\")\n",
    "                        continue\n",
    "                    output = test(cfg_from_terminal)\n",
    "                    trainer, l1_losses, inputs_BASE, gene_expressions_BASE, celltypes, test_results_BASE = output\n",
    "                    # Store the results over (radius, num_kernels) in a nested dict\n",
    "                    if int(radius) not in test_loss_rad_dict:\n",
    "                        test_loss_rad_dict[int(radius)] = {}\n",
    "                    test_loss_rad_dict[int(radius)][int(num_kernels)] = test_results_BASE[0]['test_loss']\n",
    "                except Exception as e:\n",
    "                    if \"CUDA out of memory\" in str(e):\n",
    "                        OmegaConf.update(cfg_from_terminal, \"training.filepath\", \"${model.name}__${model.kwargs.kernel_size}__${radius}__${training.logger_name}__${optimizer.name}__NUM_SPLITS=\" + str(num_splits))\n",
    "                        OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", 5)\n",
    "                        print(\"Increasing splits to 5 due to OOM error.\")\n",
    "                        output = test(cfg_from_terminal)\n",
    "                        trainer, l1_losses, inputs_BASE, gene_expressions_BASE, celltypes, test_results_BASE = output\n",
    "                        # Store the results over (radius, num_kernels) in a nested dict\n",
    "                        if int(radius) not in test_loss_rad_dict:\n",
    "                            test_loss_rad_dict[int(radius)] = {}\n",
    "                        test_loss_rad_dict[int(radius)][int(num_kernels)] = test_results_BASE[0]['test_loss']\n",
    "                    else:\n",
    "                        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_rad_dict = {}\n",
    "\n",
    "ckpt_dir = \"/nfs/turbo/lsa-regier/scratch/roko/output/lightning_logs/checkpoints/MonetDenseXenium\"\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(ckpt_dir):\n",
    "    # Check if the file is a checkpoint file\n",
    "    if filename.endswith('.ckpt'):\n",
    "        model_name, hidden_layers, num_kernels, radius, run_name, optim, num_splits = filename.split(\"__\")\n",
    "        num_splits = num_splits.removesuffix(\".ckpt\")\n",
    "        num_splits = num_splits.removeprefix(\"NUM_SPLITS=\")\n",
    "        if \"[512, 512, 512]\" not in hidden_layers or \"POLAR_AND\" not in run_name or int(radius) != 30 or int(num_kernels) != 10:\n",
    "            continue\n",
    "        with initialize(config_path=\"../config\"):\n",
    "            # try:\n",
    "                try:\n",
    "                    cfg_from_terminal = compose(config_name=\"configXenium\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.data\", \"../data\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.root\", \"/nfs/turbo/lsa-regier/scratch/roko\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.kernel_size\", int(num_kernels))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.hidden_dimensions\", eval(hidden_layers))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.logger_name\", run_name)\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.trainer.strategy\", \"auto\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"radius\", int(radius))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"gpus\", [1])\n",
    "                    OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", int(num_splits))\n",
    "                    print(cfg_from_terminal.training.filepath)\n",
    "                    # Check if the key already exists in the dictionary\n",
    "                    if int(radius) in test_loss_rad_dict and int(num_kernels) in test_loss_rad_dict[int(radius)]:\n",
    "                        print(f\"Key ({int(radius)}, {int(num_kernels)}) already exists. Skipping test.\")\n",
    "                        continue\n",
    "                    output = test(cfg_from_terminal)\n",
    "                    trainer, l1_losses, inputs_SPATIAL, gene_expressions_SPATIAL, celltypes, test_results_SPATIAL = output\n",
    "                    # Store the results over (radius, num_kernels) in a nested dict\n",
    "                    if int(radius) not in test_loss_rad_dict:\n",
    "                        test_loss_rad_dict[int(radius)] = {}\n",
    "                    test_loss_rad_dict[int(radius)][int(num_kernels)] = test_results_SPATIAL[0]['test_loss']\n",
    "                except Exception as e:\n",
    "                    if \"CUDA out of memory\" in str(e):\n",
    "                        OmegaConf.update(cfg_from_terminal, \"training.filepath\", \"${model.name}__${model.kwargs.kernel_size}__${radius}__${training.logger_name}__${optimizer.name}__NUM_SPLITS=\" + str(num_splits))\n",
    "                        OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", 5)\n",
    "                        print(\"Increasing splits to 5 due to OOM error.\")\n",
    "                        output = test(cfg_from_terminal)\n",
    "                        trainer, l1_losses, inputs_SPATIAL, gene_expressions_SPATIAL, celltypes, test_results_SPATIAL = output\n",
    "                        # Store the results over (radius, num_kernels) in a nested dict\n",
    "                        if int(radius) not in test_loss_rad_dict:\n",
    "                            test_loss_rad_dict[int(radius)] = {}\n",
    "                        test_loss_rad_dict[int(radius)][int(num_kernels)] = test_results_SPATIAL[0]['test_loss']\n",
    "                    else:\n",
    "                        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_RESPONSE_FILE = \"../spatial/non_response_blank_removed_xenium.txt\"\n",
    "with open(NON_RESPONSE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    non_response_genes = f.read().split(',')\n",
    "\n",
    "non_response_genes = [int(x) for x in non_response_genes]\n",
    "\n",
    "xenium_df = pd.read_csv(\"../data/raw/xenium.csv\", index_col=\"cell_id\")\n",
    " \n",
    "location_names = [\"x_location\", \"y_location\", \"z_location\", \"qv\"]\n",
    "\n",
    "non_response_gene_names = xenium_df.columns[non_response_genes]\n",
    "# First, combine non_response_gene_names and location_names into a single list\n",
    "response_gene_names = xenium_df.columns[~xenium_df.columns.isin(non_response_gene_names | location_names)]\n",
    "combined_names = list(non_response_gene_names) + location_names\n",
    "# Then, use the ~ operator to get the indexes of columns that are not in the combined list\n",
    "response_gene_indexes = (~xenium_df.columns.isin(combined_names)).nonzero()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ','.join(xenium_df.columns[response_gene_indexes]) == ','.join(response_gene_names), \"Response genes don't line up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 30\n",
    "loss_dict = {rad: {}}\n",
    "for i, gene in enumerate(response_gene_names):\n",
    "    inputs_SPATIAL_responses = inputs_SPATIAL[:, response_gene_indexes]\n",
    "    loss_dict[rad][gene] = {\"base\": torch.mean( (inputs_SPATIAL_responses[:, i] - gene_expressions_BASE[:, i]) ** 2 ).item(), \"spatial\": torch.mean( (inputs_SPATIAL_responses[:, i] - gene_expressions_SPATIAL[:, i]) ** 2 ).item()}\n",
    "    loss_dict[rad][gene][\"diff\"] = loss_dict[rad][gene][\"spatial\"] - loss_dict[rad][gene][\"base\"]\n",
    "    loss_dict[rad][gene][\"percent_diff\"] = (loss_dict[rad][gene][\"diff\"]/loss_dict[rad][gene][\"base\"]) * 100.0\n",
    "    loss_dict[rad][gene][\"sparsity\"] = (inputs_SPATIAL_responses[:, i] == 0).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "# ICML-style font + layout with bold title and axes\n",
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\"],\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"figure.dpi\": 300  # High DPI for high-quality output\n",
    "})\n",
    "\n",
    "# Data prep\n",
    "percent_differences = np.array([-loss_dict[30][x][\"percent_diff\"] for x in loss_dict[30]])\n",
    "\n",
    "# Define bin edges\n",
    "bin_width = 1\n",
    "bins = np.arange(np.floor(percent_differences.min()), np.ceil(percent_differences.max()) + bin_width, bin_width)\n",
    "\n",
    "# Split bins <0 and >=0\n",
    "neg_values = percent_differences[percent_differences < 0]\n",
    "pos_values = percent_differences[percent_differences >= 0]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5.2))\n",
    "\n",
    "# Colorblind-safe colors\n",
    "color_neg = \"#0072B2\"  # blue\n",
    "color_pos = \"#E69F00\"  # orange\n",
    "\n",
    "# Histograms\n",
    "ax.hist(neg_values, bins=bins, color=color_neg, alpha=0.85, label=\"No Gain\")\n",
    "ax.hist(pos_values, bins=bins, color=color_pos, alpha=0.85, label=\"Spatial Gain\")\n",
    "\n",
    "# Vertical line at 0%\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=1.6, label=\"No Gain Threshold\")\n",
    "\n",
    "# Labels and legend\n",
    "ax.set_title(\"Percent Loss Reduction: Spatial vs Baseline\", pad=10, fontweight='bold')  # Bold title\n",
    "ax.set_xlabel(\"Percent Reduction in Test Loss\", labelpad=8, fontweight='bold')  # Bold x-axis label\n",
    "ax.set_ylabel(\"Number of Genes\", labelpad=8, fontweight='bold')  # Bold y-axis label\n",
    "ax.legend(loc=\"upper right\", frameon=False)  # Bold legend\n",
    "\n",
    "# Grid + layout\n",
    "ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "fig.tight_layout(pad=1.2)\n",
    "\n",
    "# Optional save\n",
    "fig.savefig(\"xenium_spatial_vs_baseline.png\", bbox_inches='tight', dpi=300)  # High DPI for high-quality output\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank genes based on their percent decrease and save in a dictionary\n",
    "# First, let's create a dictionary with gene names as keys and their percent differences as values\n",
    "gene_percent_diffs = {x: -loss_dict[30][x][\"percent_diff\"] for x in loss_dict[30]}\n",
    "\n",
    "# Now, let's sort the genes based on their percent differences in descending order (largest decrease first)\n",
    "sorted_genes = sorted(gene_percent_diffs, key=gene_percent_diffs.get, reverse=True)\n",
    "\n",
    "# Print the top 10 genes with the largest percent decrease\n",
    "print(\"Top 10 genes with the largest percent decrease:\")\n",
    "for gene in sorted_genes[:10]:\n",
    "    print(f\"{gene}: {gene_percent_diffs[gene]}% decrease\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_decrease_genes = sum(1 for gene in gene_percent_diffs if gene_percent_diffs[gene] > 0)\n",
    "total_genes = len(gene_percent_diffs)\n",
    "percentage_positive_decrease = (positive_decrease_genes / total_genes) * 100\n",
    "\n",
    "print(f\"Percentage of genes with a positive decrease: {percentage_positive_decrease:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's sort the genes based on their percent differences in descending order (largest decrease first)\n",
    "sorted_genes = sorted(loss_dict[30], key=lambda gene: -loss_dict[30][gene][\"percent_diff\"], reverse=True)\n",
    "\n",
    "# Now, iterate through each gene in the sorted order\n",
    "for gene in sorted_genes:\n",
    "    # Extract percent difference and sparsity for each gene\n",
    "    percent_diff = loss_dict[30][gene][\"percent_diff\"]\n",
    "    sparsity = loss_dict[30][gene][\"sparsity\"]\n",
    "    \n",
    "    # Print the gene name, percent difference, and sparsity in descending order of percent difference\n",
    "    print(f\"Gene Name: {gene}, Percent Difference: {percent_diff}%, Sparsity: {sparsity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Extract percent differences and sparsity for each gene\n",
    "percent_diffs = np.array([-loss_dict[30][gene][\"percent_diff\"] for gene in sorted_genes])\n",
    "sparsities = np.array([loss_dict[30][gene][\"sparsity\"] for gene in sorted_genes])\n",
    "\n",
    "# Compute Pearson correlation\n",
    "corr, pval = pearsonr(percent_diffs, sparsities)\n",
    "\n",
    "# Create plot\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "fig, ax = plt.subplots(figsize=(5.5, 3.5))\n",
    "scatter = ax.scatter(percent_diffs, sparsities, alpha=0.6, edgecolor='k', linewidth=0.3, s=30)\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_title(\"Predictive Gain for Genes by Sparsity\", fontsize=12)\n",
    "ax.set_xlabel(\"Percent MSE Reduction from Spatial Information\", fontsize=11)\n",
    "ax.set_ylabel(\"Gene Sparsity\", fontsize=11)\n",
    "\n",
    "# Add horizontal line at y=0.5\n",
    "ax.axhline(y=0.5, color='r', linestyle='--')\n",
    "\n",
    "# Add caption for the horizontal line\n",
    "ax.text(10, 0.55, \">50% of Expression Reads are 0\", fontsize=10, color='r', verticalalignment='top')\n",
    "\n",
    "# Add correlation in a box\n",
    "bbox_props = dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white', alpha=0.8)\n",
    "ax.text(0.95, 0.95,\n",
    "        f\"Pearson r = {corr:.2f}\\np = {pval:.1e}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='right',\n",
    "        bbox=bbox_props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sparsity_scatter_Xenium.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_rad_dict = {}\n",
    "loss_dict = {}\n",
    "\n",
    "ckpt_dir = \"/nfs/turbo/lsa-regier/scratch/roko/output/lightning_logs/checkpoints/MonetDenseXenium\"\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(ckpt_dir):\n",
    "    # Check if the file is a checkpoint file\n",
    "    if filename.endswith('.ckpt'):\n",
    "        model_name, hidden_layers, num_kernels, radius, run_name, optim, num_splits = filename.split(\"__\")\n",
    "        num_splits = num_splits.removesuffix(\".ckpt\")\n",
    "        num_splits = num_splits.removeprefix(\"NUM_SPLITS=\")\n",
    "        if \"[512, 512, 512]\" not in hidden_layers or \"POLAR_AND\" not in run_name or int(num_kernels) != 10:\n",
    "            continue\n",
    "        with initialize(config_path=\"../config\"):\n",
    "            # try:\n",
    "                try:\n",
    "                    cfg_from_terminal = compose(config_name=\"configXenium\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.data\", \"../data\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"paths.root\", \"/nfs/turbo/lsa-regier/scratch/roko\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.kernel_size\", int(num_kernels))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"model.kwargs.hidden_dimensions\", eval(hidden_layers))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.logger_name\", run_name)\n",
    "                    OmegaConf.update(cfg_from_terminal, \"training.trainer.strategy\", \"auto\")\n",
    "                    OmegaConf.update(cfg_from_terminal, \"radius\", int(radius))\n",
    "                    OmegaConf.update(cfg_from_terminal, \"gpus\", [1])\n",
    "                    OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", int(num_splits))\n",
    "                    print(cfg_from_terminal.training.filepath)\n",
    "                    # Check if the key already exists in the dictionary\n",
    "                    if int(radius) in test_loss_rad_dict:\n",
    "                        print(f\"Key ({int(radius)}, {int(num_kernels)}) already exists. Skipping test.\")\n",
    "                        continue\n",
    "                    output = test(cfg_from_terminal)\n",
    "                    trainer, l1_losses, inputs_SPATIAL, gene_expressions_SPATIAL, celltypes, test_results_SPATIAL = output\n",
    "                    # Store the results over (radius, num_kernels) in a nested dict\n",
    "                    if int(radius) not in test_loss_rad_dict:\n",
    "                        test_loss_rad_dict[int(radius)] = {}\n",
    "                    test_loss_rad_dict[int(radius)] = test_results_SPATIAL[0]['test_loss']\n",
    "                except Exception as e:\n",
    "                    if \"CUDA out of memory\" in str(e):\n",
    "                        OmegaConf.update(cfg_from_terminal, \"training.filepath\", \"${model.name}__${model.kwargs.kernel_size}__${radius}__${training.logger_name}__${optimizer.name}__NUM_SPLITS=\" + str(num_splits))\n",
    "                        OmegaConf.update(cfg_from_terminal, \"datasets.dataset.splits\", 5)\n",
    "                        print(\"Increasing splits to 5 due to OOM error.\")\n",
    "                        output = test(cfg_from_terminal)\n",
    "                        trainer, l1_losses, inputs_SPATIAL, gene_expressions_SPATIAL, celltypes, test_results_SPATIAL = output\n",
    "                        # Store the results over (radius, num_kernels) in a nested dict\n",
    "                        if int(radius) not in test_loss_rad_dict:\n",
    "                            test_loss_rad_dict[int(radius)] = {}\n",
    "                        test_loss_rad_dict[int(radius)] = test_results_SPATIAL[0]['test_loss']\n",
    "                    else:\n",
    "                        raise e\n",
    "    loss_dict[radius] = {}\n",
    "    for i, gene in enumerate(response_gene_names):\n",
    "        inputs_SPATIAL_responses = inputs_SPATIAL[:, response_gene_indexes]\n",
    "        loss_dict[radius][gene] = {\"base\": torch.mean( (inputs_SPATIAL_responses[:, i] - gene_expressions_BASE[:, i]) ** 2 ).item(), \"spatial\": torch.mean( (inputs_SPATIAL_responses[:, i] - gene_expressions_SPATIAL[:, i]) ** 2 ).item()}\n",
    "        loss_dict[radius][gene][\"diff\"] = loss_dict[radius][gene][\"spatial\"] - loss_dict[radius][gene][\"base\"]\n",
    "        loss_dict[radius][gene][\"percent_diff\"] = (loss_dict[radius][gene][\"diff\"]/loss_dict[radius][gene][\"base\"]) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "# Assuming these variables are defined elsewhere in your code\n",
    "# radius_values, genes, data, response_indexes\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 28))\n",
    "\n",
    "quarter = 0\n",
    "\n",
    "# Initialize an empty array to store the full loss data\n",
    "full_loss_array = np.array([])\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    \n",
    "    quarter += 1\n",
    "    radius_values = list(range(0, 31, 5))\n",
    "    n = len(response_gene_indexes)\n",
    "    genes = response_gene_names[n * (quarter - 1) // 6 : n * quarter // 6]\n",
    "    \n",
    "    # Initialize an empty array to store the loss data for the current quarter\n",
    "    loss_array = np.array([])\n",
    "    \n",
    "    # Loop through each gene and radius to build the loss array\n",
    "    for gene in genes:\n",
    "        for rad in radius_values:\n",
    "            # Extract the percent difference for the current gene and radius\n",
    "            percent_diff = loss_dict[str(rad)][gene][\"percent_diff\"]\n",
    "            # Append the negative of the percent difference to the loss array\n",
    "            loss_array = np.append(loss_array, -percent_diff)\n",
    "    \n",
    "    # Reshape the loss array to match the dimensions of the genes and radius values\n",
    "    loss_array = loss_array.reshape(len(genes), len(radius_values))\n",
    "    \n",
    "    # If this is the first quarter, initialize the full_loss_array\n",
    "    if full_loss_array.size == 0:\n",
    "        full_loss_array = loss_array.T\n",
    "    else:\n",
    "        # Append the current loss array to the full loss array\n",
    "        full_loss_array = np.append(full_loss_array, loss_array.T, axis=1)\n",
    "    \n",
    "    # Plotting the loss array\n",
    "    im = ax.imshow(loss_array, cmap='seismic', \n",
    "                   vmin=-np.max(np.abs(full_loss_array)), \n",
    "                   vmax=np.max(np.abs(full_loss_array)))\n",
    "    \n",
    "    # Adjusting the aspect ratio to make cells wider horizontally\n",
    "    ax.set_aspect(0.8)\n",
    "    \n",
    "    # Adding a colorbar with an adjusted fraction to make it thinner\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, fraction=0.05)\n",
    "    cbar.ax.set_ylabel(\"% Loss Reduction\", fontsize=20, rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    # Setting x-axis ticks and labels\n",
    "    ax.set_xticks(np.arange(len(radius_values)))\n",
    "    ax.set_xticklabels(list(radius_values))\n",
    "    \n",
    "    # Setting y-axis ticks and labels with a custom font dict\n",
    "    gene_font = {'fontsize': 10, 'fontweight': 'bold', 'color': 'navy'}\n",
    "    ax.set_yticks(np.arange(len(genes)))\n",
    "    ax.set_yticklabels(genes, fontdict=gene_font)\n",
    "    \n",
    "    # Adjusting tick font sizes for both axes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Dynamically adjusting text color and font weight based on cell value\n",
    "    for i in range(len(genes)):\n",
    "        for j in range(len(radius_values)):\n",
    "            text_color = 'red' if loss_array[i, j] < 0 else 'black'\n",
    "            # Making text bold if the loss is greater than 10 (adjust the condition as needed)\n",
    "            fontweight = 'bold' if loss_array[i, j] > 10 else 'normal'\n",
    "            ax.text(j, i, f\"{loss_array[i, j]:.2f}\",\n",
    "                    ha=\"center\", va=\"center\", color=text_color,\n",
    "                    fontsize=15, fontweight=fontweight)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"spatial_vertical_full_Xenium.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-G_n0JvVf-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
