{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anndata in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (0.7.8)\n",
      "Requirement already satisfied: pandas>=1.1.1 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (1.22.3)\n",
      "Requirement already satisfied: xlrd<2.0 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (1.2.0)\n",
      "Requirement already satisfied: natsort in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (8.0.2)\n",
      "Requirement already satisfied: packaging>=20 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (21.3)\n",
      "Requirement already satisfied: scipy>1.4 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (1.8.0)\n",
      "Requirement already satisfied: h5py in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from anndata) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from packaging>=20->anndata) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from pandas>=1.1.1->anndata) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from pandas>=1.1.1->anndata) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.1->anndata) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import h5py\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg\n",
    "rng=np.random.default_rng()\n",
    "import tqdm.notebook\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import ipywidgets\n",
    "import sklearn.neighbors\n",
    "\n",
    "original_url= \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "csv_location='/data/spatial/moffit_merfish/original_file.csv'\n",
    "h5ad_location='/data/spatial/moffit_merfish/original_file.h5ad'\n",
    "connectivity_matrix_template='/data/spatial/moffit_merfish/connectivity_%dneighbors.h5ad'\n",
    "genetypes_location='/data/spatial/moffit_merfish/genetypes.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(csv_location, \"wb\") as csvf:\n",
    "    csvf.write(requests.get(self.url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# munge into hdf5 file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataframe = pd.read_csv(csv_location)\n",
    "\n",
    "dct={}\n",
    "for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "    if dtype.kind == \"O\":\n",
    "        dct[colnm]=np.require(dataframe[colnm], dtype=\"U36\")\n",
    "    else:\n",
    "        dct[colnm]=np.require(dataframe[colnm])\n",
    "expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "gene_names = np.array(dataframe.keys()[9:], dtype=\"U80\")\n",
    "cellid=dct.pop('Cell_ID')\n",
    "\n",
    "ad=anndata.AnnData(\n",
    "    X=expression,\n",
    "    var=pd.DataFrame(index=gene_names),\n",
    "    obs=pd.DataFrame(dct,index=cellid)\n",
    ")\n",
    "\n",
    "ad.write_h5ad(h5ad_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# supplement hdf5 file with a column indicating \"tissue id\" for each cell"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ad=anndata.read_h5ad(h5ad_location)\n",
    "animal_ids=np.unique(ad.obs['Animal_ID'])\n",
    "bregmas=np.unique(ad.obs['Bregma'])\n",
    "tissue_id=np.zeros(len(ad),dtype=int)\n",
    "n_tissues=0\n",
    "    \n",
    "for aid in animal_ids:\n",
    "    for bregma in bregmas:\n",
    "        good=(ad.obs['Animal_ID']==aid)&(ad.obs['Bregma']==bregma)\n",
    "        if np.sum(good)>0:\n",
    "            tissue_id[good]=n_tissues\n",
    "            n_tissues+=1\n",
    "ad.obs['Tissue_ID']=tissue_id\n",
    "ad.write_h5ad(h5ad_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create global graph (using 3 nearest neigbors)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ad=anndata.read_h5ad(h5ad_location)\n",
    "row=np.zeros(0,dtype=int)\n",
    "col=np.zeros(0,dtype=int)\n",
    "nneigh=3\n",
    "\n",
    "for tid in tqdm.notebook.tqdm(np.unique(ad.obs['Tissue_ID'])):\n",
    "    good=ad.obs['Tissue_ID']==tid\n",
    "    pos=np.array(ad.obs[good][['Centroid_X','Centroid_Y']])\n",
    "    p=sklearn.neighbors.BallTree(pos)\n",
    "    E=sklearn.neighbors.kneighbors_graph(pos,nneigh,mode='connectivity')\n",
    "    idxs=np.where(good)[0]\n",
    "    col=np.r_[col,idxs[E.tocoo().col]]\n",
    "    row=np.r_[row,idxs[E.tocoo().row]]\n",
    "    \n",
    "E=sp.sparse.coo_matrix((np.ones(len(col)),(row,col)),shape=(len(ad),len(ad))).tocsr()\n",
    "anndata.AnnData(E).write_h5ad(connectivity_matrix_template%nneigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write down ligand/receptor sets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ligands=np.array(['Cbln1', 'Cxcl14', 'Cbln2', 'Vgf', 'Scg2', 'Cartpt', 'Tac2',\n",
    "       'Bdnf', 'Bmp7', 'Cyr61', 'Fn1', 'Fst', 'Gad1', 'Ntng1', 'Pnoc',\n",
    "       'Selplg', 'Sema3c', 'Sema4d', 'Serpine1', 'Adcyap1', 'Cck', 'Crh',\n",
    "       'Gal', 'Gnrh1', 'Nts', 'Oxt', 'Penk', 'Sst', 'Tac1', 'Trh', 'Ucn3'])\n",
    "\n",
    "receptors=np.array(['Crhbp', 'Gabra1', 'Gpr165', 'Glra3', 'Gabrg1', 'Adora2a',\n",
    "       'Avpr1a', 'Avpr2', 'Brs3', 'Calcr', 'Cckar', 'Cckbr', 'Crhr1',\n",
    "       'Crhr2', 'Galr1', 'Galr2', 'Grpr', 'Htr2c', 'Igf1r', 'Igf2r',\n",
    "       'Kiss1r', 'Lepr', 'Lpar1', 'Mc4r', 'Npy1r', 'Npy2r', 'Ntsr1',\n",
    "       'Oprd1', 'Oprk1', 'Oprl1', 'Oxtr', 'Pdgfra', 'Prlr', 'Ramp3',\n",
    "       'Rxfp1', 'Slc17a7', 'Slc18a2', 'Tacr1', 'Tacr3', 'Trhr'])\n",
    "\n",
    "response_genes=np.array(['Ace2', 'Aldh1l1', 'Amigo2', 'Ano3', 'Aqp4', 'Ar', 'Arhgap36',\n",
    "       'Baiap2', 'Ccnd2', 'Cd24a', 'Cdkn1a', 'Cenpe', 'Chat', 'Coch',\n",
    "       'Col25a1', 'Cplx3', 'Cpne5', 'Creb3l1', 'Cspg5', 'Cyp19a1',\n",
    "       'Cyp26a1', 'Dgkk', 'Ebf3', 'Egr2', 'Ermn', 'Esr1', 'Etv1',\n",
    "       'Fbxw13', 'Fezf1', 'Fos', 'Gbx2', 'Gda', 'Gem', 'Gjc3', 'Greb1',\n",
    "       'Irs4', 'Isl1', 'Klf4', 'Krt90', 'Lmod1', 'Man1a', 'Mbp', 'Mki67',\n",
    "       'Mlc1', 'Myh11', 'Ndnf', 'Ndrg1', 'Necab1', 'Nnat', 'Nos1',\n",
    "       'Npas1', 'Nup62cl', 'Omp', 'Onecut2', 'Opalin', 'Pak3', 'Pcdh11x',\n",
    "       'Pgr', 'Plin3', 'Pou3f2', 'Rgs2', 'Rgs5', 'Rnd3', 'Scgn',\n",
    "       'Serpinb1b', 'Sgk1', 'Slc15a3', 'Slc17a6', 'Slc17a8', 'Slco1a4',\n",
    "       'Sln', 'Sox4', 'Sox6', 'Sox8', 'Sp9', 'Synpr', 'Syt2', 'Syt4',\n",
    "       'Sytl4', 'Th', 'Tiparp', 'Tmem108', 'Traf4', 'Ttn', 'Ttyh2'])\n",
    "\n",
    "with open(genetypes_location,'wb') as f:\n",
    "    pickle.dump(dict(ligands=ligands,receptors=receptors,response_genes=response_genes),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run a simple experiment: use ligands and receptors to predict response genes in excitatory cells, with a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "nneigh=3\n",
    "ad=anndata.read_h5ad(h5ad_location)\n",
    "connectivity_matrix=anndata.read_h5ad(connectivity_matrix_template%nneigh).X\n",
    "gene_lookup={x:i for (i,x) in enumerate(ad.var.index)}\n",
    "\n",
    "with open(genetypes_location,'rb') as f:\n",
    "    genetypes=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encode cell classes\n",
    "def oh_encode(lst):\n",
    "    lst=np.array(lst)\n",
    "    group_names=np.unique(lst)\n",
    "    group_indexes=np.zeros((len(lst),len(group_names)),dtype=bool)\n",
    "    for i,nm in enumerate(group_names):\n",
    "        group_indexes[lst==nm,i]=True\n",
    "    return group_names,group_indexes\n",
    "cell_classes,cell_class_onehots=oh_encode(ad.obs['Cell_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to construct a prediction problem for a subset of cells\n",
    "\n",
    "def construct_problem(mask,target_gene,neighbor_genes,self_genes,filter_excitatory=False):\n",
    "    '''\n",
    "    mask -- set of cells\n",
    "    target_gene -- gene to predict\n",
    "    neighbor_genes -- names of genes which will be read from neighbors\n",
    "    self_genes -- names of genes which will be read from target cell\n",
    "    '''\n",
    "    \n",
    "    # load subset of data relevant to mask\n",
    "    local_processed_expression=np.log1p(ad.X[mask].astype(float)) # get expression on subset of cells\n",
    "    local_edges=connectivity_matrix[mask][:,mask]   # get edges for subset\n",
    "    \n",
    "    selfset_idxs=[gene_lookup[x] for x in self_genes] # collect the column indexes associated with them\n",
    "    selfset_exprs = local_processed_expression[:,selfset_idxs] # collect ligand and receptor expressions\n",
    "       \n",
    "    neighborset_idxs=[gene_lookup[x] for x in neighbor_genes] # collect the column indexes associated with them\n",
    "    neighset_exprs = local_processed_expression[:,neighborset_idxs] # collect ligand and receptor expressions\n",
    "        \n",
    "    n_neighs=(local_edges@np.ones(local_edges.shape[0]))\n",
    "    neigh_avgs = (local_edges@neighset_exprs) / n_neighs[:,None] # average ligand/receptor for neighbors\n",
    "    \n",
    "    neigh_cellclass_avgs = (local_edges@cell_class_onehots[mask]) / n_neighs[:,None] # celltype simplex\n",
    "    \n",
    "    positions=np.array(ad.obs[['Centroid_X','Centroid_Y','Bregma']])[mask] # get positions\n",
    "    \n",
    "    covariates=np.c_[selfset_exprs,neigh_avgs,neigh_cellclass_avgs,positions] # collect all covariates\n",
    "    predict = local_processed_expression[:,gene_lookup[target_gene]] # collect what we're supposed to predict\n",
    "    \n",
    "    if filter_excitatory:\n",
    "    \n",
    "        excites=(ad.obs['Cell_class']=='Excitatory')[mask] # get the subset of these cells which are excitatory\n",
    "        covariates=covariates[excites] # subset to excites\n",
    "        predict=predict[excites]       # subset to excites\n",
    "    \n",
    "    return covariates,predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n"
     ]
    }
   ],
   "source": [
    "neighset=genetypes['ligands']\n",
    "oset=np.r_[genetypes['ligands'],genetypes['receptors']]\n",
    "# oset=neighset\n",
    "\n",
    "# oset=[]\n",
    "# neighset=[]\n",
    "\n",
    "trainX,trainY=construct_problem((ad.obs['Animal_ID']>=2)&(ad.obs['Animal_ID']<=4),'Ace2',neighset,oset)\n",
    "testX,testY=construct_problem((ad.obs['Animal_ID']==1),'Ace2',neighset,oset)\n",
    "\n",
    "print(trainX.shape,trainY.shape)\n",
    "print(testX.shape,testY.shape)\n",
    "\n",
    "# whiten covariates\n",
    "# mu=np.mean(trainX,axis=0)\n",
    "# sig=np.std(trainX,axis=0)\n",
    "# trainX=(trainX-mu)/sig\n",
    "# testX=(testX-mu)/sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cbln1', 'Cxcl14', 'Cbln2', 'Vgf', 'Scg2', 'Cartpt', 'Tac2',\n",
       "       'Bdnf', 'Bmp7', 'Cyr61', 'Fn1', 'Fst', 'Gad1', 'Ntng1', 'Pnoc',\n",
       "       'Selplg', 'Sema3c', 'Sema4d', 'Serpine1', 'Adcyap1', 'Cck', 'Crh',\n",
       "       'Gal', 'Gnrh1', 'Nts', 'Oxt', 'Penk', 'Sst', 'Tac1', 'Trh', 'Ucn3'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17033753860011874"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=sklearn.linear_model.Ridge(alpha=1.0)\n",
    "model.fit(trainX,trainY)\n",
    "np.mean(np.abs(model.predict(testX)-testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.115 GB of training data: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.146 s\n",
      "Binning 0.013 GB of validation data: 0.085 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.04677, val loss: 0.04547, in 0.090s\n",
      "[2/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.04527, val loss: 0.04426, in 0.081s\n",
      "[3/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.04403, val loss: 0.04334, in 0.088s\n",
      "[4/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04296, val loss: 0.04260, in 0.078s\n",
      "[5/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.04208, val loss: 0.04201, in 0.080s\n",
      "[6/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.04133, val loss: 0.04153, in 0.070s\n",
      "[7/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.04067, val loss: 0.04111, in 0.076s\n",
      "[8/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.04012, val loss: 0.04072, in 0.080s\n",
      "[9/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03963, val loss: 0.04041, in 0.075s\n",
      "[10/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03921, val loss: 0.04015, in 0.073s\n",
      "[11/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03882, val loss: 0.03993, in 0.077s\n",
      "[12/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03847, val loss: 0.03973, in 0.077s\n",
      "[13/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03815, val loss: 0.03959, in 0.073s\n",
      "[14/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03786, val loss: 0.03945, in 0.069s\n",
      "[15/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03761, val loss: 0.03939, in 0.073s\n",
      "[16/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03736, val loss: 0.03924, in 0.076s\n",
      "[17/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03715, val loss: 0.03918, in 0.076s\n",
      "[18/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.03692, val loss: 0.03907, in 0.078s\n",
      "[19/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03673, val loss: 0.03903, in 0.070s\n",
      "[20/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03655, val loss: 0.03898, in 0.069s\n",
      "[21/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03638, val loss: 0.03889, in 0.072s\n",
      "[22/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03623, val loss: 0.03884, in 0.072s\n",
      "[23/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03609, val loss: 0.03882, in 0.073s\n",
      "[24/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.03595, val loss: 0.03880, in 0.066s\n",
      "[25/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03582, val loss: 0.03876, in 0.069s\n",
      "[26/10000] 1 tree, 31 leaves, max depth = 18, train loss: 0.03567, val loss: 0.03879, in 0.067s\n",
      "[27/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.03554, val loss: 0.03879, in 0.070s\n",
      "[28/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.03541, val loss: 0.03870, in 0.070s\n",
      "[29/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03529, val loss: 0.03872, in 0.064s\n",
      "[30/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03518, val loss: 0.03870, in 0.068s\n",
      "[31/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03509, val loss: 0.03868, in 0.084s\n",
      "[32/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03500, val loss: 0.03871, in 0.069s\n",
      "[33/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03491, val loss: 0.03868, in 0.063s\n",
      "[34/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03481, val loss: 0.03869, in 0.070s\n",
      "[35/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.03471, val loss: 0.03866, in 0.081s\n",
      "[36/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03461, val loss: 0.03862, in 0.071s\n",
      "[37/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03452, val loss: 0.03861, in 0.063s\n",
      "[38/10000] 1 tree, 31 leaves, max depth = 17, train loss: 0.03443, val loss: 0.03859, in 0.070s\n",
      "[39/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03436, val loss: 0.03860, in 0.070s\n",
      "[40/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03429, val loss: 0.03859, in 0.068s\n",
      "[41/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03422, val loss: 0.03860, in 0.064s\n",
      "[42/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03414, val loss: 0.03861, in 0.066s\n",
      "[43/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03406, val loss: 0.03863, in 0.063s\n",
      "[44/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03398, val loss: 0.03862, in 0.063s\n",
      "[45/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03392, val loss: 0.03862, in 0.072s\n",
      "[46/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03386, val loss: 0.03866, in 0.077s\n",
      "[47/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03377, val loss: 0.03868, in 0.075s\n",
      "[48/10000] 1 tree, 31 leaves, max depth = 18, train loss: 0.03373, val loss: 0.03869, in 0.070s\n",
      "[49/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03367, val loss: 0.03871, in 0.066s\n",
      "[50/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03361, val loss: 0.03869, in 0.065s\n",
      "[51/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03355, val loss: 0.03867, in 0.075s\n",
      "[52/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03350, val loss: 0.03866, in 0.058s\n",
      "[53/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03343, val loss: 0.03863, in 0.077s\n",
      "[54/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03338, val loss: 0.03862, in 0.070s\n",
      "[55/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03332, val loss: 0.03862, in 0.069s\n",
      "[56/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03328, val loss: 0.03862, in 0.064s\n",
      "[57/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03323, val loss: 0.03864, in 0.068s\n",
      "[58/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03318, val loss: 0.03865, in 0.068s\n",
      "[59/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03313, val loss: 0.03866, in 0.073s\n",
      "[60/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03308, val loss: 0.03867, in 0.073s\n",
      "[61/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03304, val loss: 0.03867, in 0.066s\n",
      "[62/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03300, val loss: 0.03865, in 0.065s\n",
      "[63/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03295, val loss: 0.03867, in 0.060s\n",
      "[64/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.03290, val loss: 0.03868, in 0.069s\n",
      "[65/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03285, val loss: 0.03868, in 0.060s\n",
      "[66/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03279, val loss: 0.03872, in 0.069s\n",
      "[67/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03274, val loss: 0.03874, in 0.064s\n",
      "[68/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03268, val loss: 0.03873, in 0.062s\n",
      "[69/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03263, val loss: 0.03875, in 0.086s\n",
      "[70/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03259, val loss: 0.03875, in 0.084s\n",
      "[71/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03255, val loss: 0.03874, in 0.073s\n",
      "[72/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03250, val loss: 0.03875, in 0.072s\n",
      "[73/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03245, val loss: 0.03876, in 0.054s\n",
      "[74/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03240, val loss: 0.03876, in 0.059s\n",
      "[75/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03236, val loss: 0.03877, in 0.063s\n",
      "[76/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03232, val loss: 0.03876, in 0.069s\n",
      "[77/10000] 1 tree, 31 leaves, max depth = 18, train loss: 0.03227, val loss: 0.03875, in 0.079s\n",
      "[78/10000] 1 tree, 31 leaves, max depth = 16, train loss: 0.03222, val loss: 0.03875, in 0.068s\n",
      "[79/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03215, val loss: 0.03877, in 0.061s\n",
      "[80/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03212, val loss: 0.03877, in 0.062s\n",
      "[81/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03208, val loss: 0.03877, in 0.062s\n",
      "[82/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03204, val loss: 0.03876, in 0.071s\n",
      "[83/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03200, val loss: 0.03877, in 0.058s\n",
      "[84/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03196, val loss: 0.03877, in 0.064s\n",
      "[85/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03193, val loss: 0.03876, in 0.060s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03189, val loss: 0.03877, in 0.050s\n",
      "[87/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03184, val loss: 0.03877, in 0.059s\n",
      "[88/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03179, val loss: 0.03877, in 0.070s\n",
      "[89/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03176, val loss: 0.03878, in 0.074s\n",
      "[90/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03171, val loss: 0.03877, in 0.079s\n",
      "[91/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03167, val loss: 0.03878, in 0.051s\n",
      "[92/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03161, val loss: 0.03877, in 0.063s\n",
      "[93/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03157, val loss: 0.03877, in 0.061s\n",
      "[94/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03153, val loss: 0.03876, in 0.064s\n",
      "[95/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03148, val loss: 0.03877, in 0.064s\n",
      "[96/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.03146, val loss: 0.03878, in 0.048s\n",
      "[97/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03142, val loss: 0.03878, in 0.050s\n",
      "[98/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03139, val loss: 0.03878, in 0.058s\n",
      "[99/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03134, val loss: 0.03878, in 0.052s\n",
      "[100/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.03131, val loss: 0.03878, in 0.054s\n",
      "[101/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03128, val loss: 0.03878, in 0.046s\n",
      "[102/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03124, val loss: 0.03879, in 0.076s\n",
      "[103/10000] 1 tree, 31 leaves, max depth = 13, train loss: 0.03120, val loss: 0.03879, in 0.052s\n",
      "[104/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03116, val loss: 0.03880, in 0.046s\n",
      "[105/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03114, val loss: 0.03880, in 0.059s\n",
      "[106/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03111, val loss: 0.03881, in 0.047s\n",
      "[107/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03107, val loss: 0.03880, in 0.059s\n",
      "[108/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03105, val loss: 0.03880, in 0.053s\n",
      "[109/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03101, val loss: 0.03879, in 0.059s\n",
      "[110/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03096, val loss: 0.03879, in 0.068s\n",
      "[111/10000] 1 tree, 31 leaves, max depth = 14, train loss: 0.03092, val loss: 0.03878, in 0.058s\n",
      "[112/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03088, val loss: 0.03879, in 0.054s\n",
      "[113/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03086, val loss: 0.03879, in 0.048s\n",
      "[114/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03083, val loss: 0.03880, in 0.063s\n",
      "[115/10000] 1 tree, 31 leaves, max depth = 9, train loss: 0.03079, val loss: 0.03882, in 0.055s\n",
      "[116/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03075, val loss: 0.03882, in 0.060s\n",
      "[117/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03072, val loss: 0.03883, in 0.048s\n",
      "[118/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.03070, val loss: 0.03883, in 0.058s\n",
      "[119/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03068, val loss: 0.03883, in 0.073s\n",
      "[120/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03065, val loss: 0.03883, in 0.050s\n",
      "[121/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03062, val loss: 0.03881, in 0.064s\n",
      "[122/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03057, val loss: 0.03881, in 0.061s\n",
      "[123/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03054, val loss: 0.03881, in 0.056s\n",
      "[124/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03050, val loss: 0.03883, in 0.051s\n",
      "[125/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03047, val loss: 0.03883, in 0.051s\n",
      "[126/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03044, val loss: 0.03884, in 0.063s\n",
      "[127/10000] 1 tree, 31 leaves, max depth = 8, train loss: 0.03040, val loss: 0.03884, in 0.078s\n",
      "[128/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03037, val loss: 0.03885, in 0.057s\n",
      "[129/10000] 1 tree, 31 leaves, max depth = 12, train loss: 0.03034, val loss: 0.03887, in 0.067s\n",
      "[130/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03031, val loss: 0.03890, in 0.054s\n",
      "[131/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03028, val loss: 0.03890, in 0.065s\n",
      "[132/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03024, val loss: 0.03891, in 0.068s\n",
      "[133/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03022, val loss: 0.03891, in 0.081s\n",
      "[134/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03019, val loss: 0.03892, in 0.084s\n",
      "[135/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03014, val loss: 0.03892, in 0.089s\n",
      "[136/10000] 1 tree, 31 leaves, max depth = 10, train loss: 0.03011, val loss: 0.03894, in 0.052s\n",
      "[137/10000] 1 tree, 31 leaves, max depth = 11, train loss: 0.03007, val loss: 0.03893, in 0.050s\n",
      "[138/10000] 1 tree, 31 leaves, max depth = 15, train loss: 0.03004, val loss: 0.03894, in 0.058s\n",
      "Fit 138 trees in 11.459 s, (4278 total leaves)\n",
      "Time spent computing histograms: 3.211s\n",
      "Time spent finding best splits:  1.100s\n",
      "Time spent applying splits:      0.278s\n",
      "Time spent predicting:           0.035s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16080342723552601"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "model=HistGradientBoostingRegressor(loss=\"squared_error\", min_samples_leaf=2, verbose=1, random_state=129, max_iter=10000, n_iter_no_change=100)\n",
    "model.fit(trainX,trainY)\n",
    "np.mean(np.abs(model.predict(testX)-testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same 3 cells as above but w/ standardizing this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[2, 3, 4]\n",
      "(131693, 121) (131693,)\n",
      "(73655, 121) (73655,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n",
      "[1, 3, 4]\n",
      "(136309, 121) (136309,)\n",
      "(69039, 121) (69039,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     testX\u001b[38;5;241m=\u001b[39m(testX\u001b[38;5;241m-\u001b[39mmu)\u001b[38;5;241m/\u001b[39msig\n\u001b[1;32m     51\u001b[0m     model\u001b[38;5;241m=\u001b[39mHistGradientBoostingRegressor(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     MAE_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(model\u001b[38;5;241m.\u001b[39mpredict(testX)\u001b[38;5;241m-\u001b[39mtestY)))\n\u001b[1;32m     55\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:343\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    341\u001b[0m X_binned_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_data(X_train, is_training_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     X_binned_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     X_binned_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:772\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._bin_data\u001b[0;34m(self, X, is_training_data)\u001b[0m\n\u001b[1;32m    770\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_mapper\u001b[38;5;241m.\u001b[39mfit_transform(X)  \u001b[38;5;66;03m# F-aligned array\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 772\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_mapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# F-aligned array\u001b[39;00m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;66;03m# We convert the array to C-contiguous since predicting is faster\u001b[39;00m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;66;03m# with this layout (training is faster on F-arrays though)\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(X_binned)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py:277\u001b[0m, in \u001b[0;36m_BinMapper.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    275\u001b[0m n_threads \u001b[38;5;241m=\u001b[39m _openmp_effective_n_threads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_threads)\n\u001b[1;32m    276\u001b[0m binned \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(X, dtype\u001b[38;5;241m=\u001b[39mX_BINNED_DTYPE, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m \u001b[43m_map_to_bins\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin_thresholds_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing_values_bin_idx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinned\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binned\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response_genes=['Ace2', 'Aldh1l1', 'Amigo2', 'Ano3', 'Aqp4', 'Ar', 'Arhgap36',\n",
    "       'Baiap2', 'Ccnd2', 'Cd24a', 'Cdkn1a', 'Cenpe', 'Chat', 'Coch',\n",
    "       'Col25a1', 'Cplx3', 'Cpne5', 'Creb3l1', 'Cspg5', 'Cyp19a1',\n",
    "       'Cyp26a1', 'Dgkk', 'Ebf3', 'Egr2', 'Ermn', 'Esr1', 'Etv1',\n",
    "       'Fbxw13', 'Fezf1', 'Gbx2', 'Gda', 'Gem', 'Gjc3', 'Greb1',\n",
    "       'Irs4', 'Isl1', 'Klf4', 'Krt90', 'Lmod1', 'Man1a', 'Mbp', 'Mki67',\n",
    "       'Mlc1', 'Myh11', 'Ndnf', 'Ndrg1', 'Necab1', 'Nnat', 'Nos1',\n",
    "       'Npas1', 'Nup62cl', 'Omp', 'Onecut2', 'Opalin', 'Pak3', 'Pcdh11x',\n",
    "       'Pgr', 'Plin3', 'Pou3f2', 'Rgs2', 'Rgs5', 'Rnd3', 'Scgn',\n",
    "       'Serpinb1b', 'Sgk1', 'Slc15a3', 'Slc17a6', 'Slc17a8', 'Slco1a4',\n",
    "       'Sln', 'Sox4', 'Sox6', 'Sox8', 'Sp9', 'Synpr', 'Syt2', 'Syt4',\n",
    "       'Sytl4', 'Th', 'Tiparp', 'Tmem108', 'Traf4', 'Ttn', 'Ttyh2']\n",
    "\n",
    "import time\n",
    "import json\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "all_MAEs = []\n",
    "\n",
    "time_dict = {}\n",
    "L1_loss_dict = {}\n",
    "\n",
    "for animal in [1,2,3,4]:\n",
    "    start = time.time()\n",
    "    MAE_list = []\n",
    "    for target_gene in response_genes:\n",
    "        neighset=genetypes['ligands']\n",
    "        oset=np.r_[genetypes['ligands'],genetypes['receptors']]\n",
    "        # oset=neighset\n",
    "\n",
    "        # oset=[]\n",
    "        # neighset=[]\n",
    "        \n",
    "        train_animals = [1,2,3,4]\n",
    "        train_animals.remove(animal)\n",
    "        print(train_animals)\n",
    "        # FIX THIS SO THAT ONLY FIRST 4 ANIMALS GET USED\n",
    "        trainX,trainY=construct_problem((ad.obs['Animal_ID']!=animal)&(ad.obs['Animal_ID']<=4),target_gene,neighset,oset)\n",
    "        testX,testY=construct_problem((ad.obs['Animal_ID']==animal),target_gene,neighset,oset)\n",
    "\n",
    "        print(trainX.shape,trainY.shape)\n",
    "        print(testX.shape,testY.shape)\n",
    "\n",
    "        # whiten covariates\n",
    "        mu=np.mean(trainX,axis=0)\n",
    "        sig=np.std(trainX,axis=0)\n",
    "        trainX=(trainX-mu)/sig\n",
    "        testX=(testX-mu)/sig\n",
    "\n",
    "        model=HistGradientBoostingRegressor(loss=\"absolute_error\")\n",
    "        model.fit(trainX,trainY)\n",
    "        MAE_list.append(np.mean(np.abs(model.predict(testX)-testY)))\n",
    "\n",
    "    end = time.time()\n",
    "    time_dict[f\"Female_Naive_{animal}\"] = end-start\n",
    "    L1_loss_dict[f\"Female_Naive_{animal}\"] = float(np.mean(MAE_list))\n",
    "\n",
    "    with open(\"XGBoost_L1_time.json\", \"w\") as outfile:\n",
    "        json.dump(time_dict, outfile, indent=4)\n",
    "\n",
    "    with open(\"XGBoost_L1_MAE.json\", \"w\") as outfile:\n",
    "        json.dump(L1_loss_dict, outfile, indent=4)\n",
    "    \n",
    "    all_MAEs.append(np.mean(MAE_list))\n",
    "    \n",
    "print(np.mean(all_MAEs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_genes=['Ace2', 'Aldh1l1', 'Amigo2', 'Ano3', 'Aqp4', 'Ar', 'Arhgap36',\n",
    "       'Baiap2', 'Ccnd2', 'Cd24a', 'Cdkn1a', 'Cenpe', 'Chat', 'Coch',\n",
    "       'Col25a1', 'Cplx3', 'Cpne5', 'Creb3l1', 'Cspg5', 'Cyp19a1',\n",
    "       'Cyp26a1', 'Dgkk', 'Ebf3', 'Egr2', 'Ermn', 'Esr1', 'Etv1',\n",
    "       'Fbxw13', 'Fezf1', 'Gbx2', 'Gda', 'Gem', 'Gjc3', 'Greb1',\n",
    "       'Irs4', 'Isl1', 'Klf4', 'Krt90', 'Lmod1', 'Man1a', 'Mbp', 'Mki67',\n",
    "       'Mlc1', 'Myh11', 'Ndnf', 'Ndrg1', 'Necab1', 'Nnat', 'Nos1',\n",
    "       'Npas1', 'Nup62cl', 'Omp', 'Onecut2', 'Opalin', 'Pak3', 'Pcdh11x',\n",
    "       'Pgr', 'Plin3', 'Pou3f2', 'Rgs2', 'Rgs5', 'Rnd3', 'Scgn',\n",
    "       'Serpinb1b', 'Sgk1', 'Slc15a3', 'Slc17a6', 'Slc17a8', 'Slco1a4',\n",
    "       'Sln', 'Sox4', 'Sox6', 'Sox8', 'Sp9', 'Synpr', 'Syt2', 'Syt4',\n",
    "       'Sytl4', 'Th', 'Tiparp', 'Tmem108', 'Traf4', 'Ttn', 'Ttyh2']\n",
    "\n",
    "import time\n",
    "import json\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "all_MAEs = []\n",
    "\n",
    "time_dict = {}\n",
    "L1_loss_dict = {}\n",
    "\n",
    "for animal in [1,2,3,4]:\n",
    "    start = time.time()\n",
    "    MAE_list = []\n",
    "    for target_gene in response_genes:\n",
    "        neighset=genetypes['ligands']\n",
    "        oset=np.r_[genetypes['ligands'],genetypes['receptors']]\n",
    "        # oset=neighset\n",
    "\n",
    "        # oset=[]\n",
    "        # neighset=[]\n",
    "        \n",
    "        train_animals = [1,2,3,4]\n",
    "        train_animals.remove(animal)\n",
    "        print(train_animals)\n",
    "        # FIX THIS SO THAT ONLY FIRST 4 ANIMALS GET USED\n",
    "        trainX,trainY=construct_problem((ad.obs['Animal_ID']!=animal)&(ad.obs['Animal_ID']<=4),target_gene,neighset,oset,True)\n",
    "        testX,testY=construct_problem((ad.obs['Animal_ID']==animal),target_gene,neighset,oset,True)\n",
    "\n",
    "        print(trainX.shape,trainY.shape)\n",
    "        print(testX.shape,testY.shape)\n",
    "\n",
    "        # whiten covariates\n",
    "        mu=np.mean(trainX,axis=0)\n",
    "        sig=np.std(trainX,axis=0)\n",
    "        trainX=(trainX-mu)/sig\n",
    "        testX=(testX-mu)/sig\n",
    "\n",
    "        model=HistGradientBoostingRegressor(loss=\"absolute_error\")\n",
    "        model.fit(trainX,trainY)\n",
    "        MAE_list.append(np.mean(np.abs(model.predict(testX)-testY)))\n",
    "\n",
    "    end = time.time()\n",
    "    time_dict[f\"Female_Naive_{animal}\"] = end-start\n",
    "    L1_loss_dict[f\"Female_Naive_{animal}\"] = float(np.mean(MAE_list))\n",
    "\n",
    "    with open(\"XGBoost_L1_time_excitatory.json\", \"w\") as outfile:\n",
    "        json.dump(time_dict, outfile, indent=4)\n",
    "\n",
    "    with open(\"XGBoost_L1_MAE_excitatory.json\", \"w\") as outfile:\n",
    "        json.dump(L1_loss_dict, outfile, indent=4)\n",
    "    \n",
    "    all_MAEs.append(np.mean(MAE_list))\n",
    "    \n",
    "print(np.mean(all_MAEs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(893456, 121) (893456,)\n",
      "(134392, 121) (134392,)\n"
     ]
    }
   ],
   "source": [
    "neighset=genetypes['ligands']\n",
    "oset=np.r_[genetypes['ligands'],genetypes['receptors']]\n",
    "# oset=neighset\n",
    "\n",
    "# oset=[]\n",
    "# neighset=[]\n",
    "\n",
    "trainX,trainY=construct_problem((ad.obs['Animal_ID']<=30),'Th',neighset,oset)\n",
    "testX,testY=construct_problem((ad.obs['Animal_ID']>30),'Th',neighset,oset)\n",
    "\n",
    "print(trainX.shape,trainY.shape)\n",
    "print(testX.shape,testY.shape)\n",
    "\n",
    "# whiten covariates\n",
    "mu=np.mean(trainX,axis=0)\n",
    "sig=np.std(trainX,axis=0)\n",
    "trainX=(trainX-mu)/sig\n",
    "testX=(testX-mu)/sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06757797610786355"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=sklearn.linear_model.Ridge(alpha=1.0)\n",
    "model.fit(trainX,trainY)\n",
    "np.mean(np.abs(model.predict(testX)-testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05254223324894638"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "model=HistGradientBoostingRegressor(loss=\"absolute_error\")\n",
    "model.fit(trainX,trainY)\n",
    "np.mean(np.abs(model.predict(testX)-testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighset=genetypes['ligands']\n",
    "oset=np.r_[genetypes['ligands'],genetypes['receptors']]\n",
    "# oset=neighset\n",
    "\n",
    "# oset=[]\n",
    "# neighset=[]\n",
    "\n",
    "trainX,trainY=construct_problem((ad.obs['Animal_ID']<=30),'Th',neighset,oset)\n",
    "testX,testY=construct_problem((ad.obs['Animal_ID']>30),'Th',neighset,oset)\n",
    "\n",
    "mu=np.mean(trainX,axis=0)\n",
    "sig=np.std(trainX,axis=0)\n",
    "trainX_Jackson=(trainX-mu)/sig\n",
    "testX_Jackson=(testX-mu)/sig\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(trainX)\n",
    "trainX_Roman = scaler.transform(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06757765995432916"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=sklearn.linear_model.Ridge(alpha=1.0)\n",
    "model.fit(trainX,trainY)\n",
    "np.mean(np.abs(model.predict(testX)-testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05254223324894638"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "model=HistGradientBoostingRegressor(loss=\"absolute_error\")\n",
    "model.fit(trainX,trainY)\n",
    "np.mean(np.abs(model.predict(testX)-testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.predict(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
