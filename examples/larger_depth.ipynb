{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364eebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0,1,2,3,4,5\"\n",
    "os.environ['OMP_NUM_THREADS']=\"4\"\n",
    "os.environ['NUMBA_NUM_THREADS']=\"4\"\n",
    "os.environ['MKL_NUM_THREADS']=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import pandas as pd; import anndata; import numpy as np; import gzip; import io; import h5py\n",
    "import collections; import matplotlib.pyplot as plt; import time; import sys; import tqdm.notebook\n",
    "import pickle; import scipy as sp; import scipy.sparse; import scipy.stats; rng=np.random.default_rng()\n",
    "import PIL; PIL.Image.MAX_IMAGE_PIXELS = None; import matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\":  (1.0, 1.0, 1.0, 1.0),\n",
    "    \"axes.facecolor\":    (1.0, 1.0, 1.0, 1.0),\n",
    "    \"savefig.facecolor\": (1.0, 1.0, 1.0, 1.0),\n",
    "    \"text.usetex\": True,\n",
    "})\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae73ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "import torch_geometric\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7034b2",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbca3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(fn):\n",
    "    with h5py.File(fn,'r') as f:\n",
    "        dct={}\n",
    "        for x in ['Animal_ID', 'Animal_sex', 'Behavior', 'Bregma', 'Cell_ID', 'Cell_class', \n",
    "                  'Centroid_X', 'Centroid_Y', 'Neuron_cluster_ID']:\n",
    "            dct[x]=f[x][:]\n",
    "            if dct[x].dtype.kind=='S':\n",
    "                dct[x]=dct[x].astype(\"U\")\n",
    "        for x in ['Animal_ID', 'Animal_sex', 'Behavior', 'Bregma', 'Cell_class', 'Neuron_cluster_ID']:\n",
    "            dct[x]=pd.Categorical(dct[x])\n",
    "        X=f['expression'][:]\n",
    "        var=pd.DataFrame(index=f['gene_names'][:].astype('U'))\n",
    "    ad=anndata.AnnData(X=X,var=var,obs=pd.DataFrame(data=dct),dtype=np.float32) # <-- stored as float16 (!)\n",
    "    ad.obs['tissue_id']=pd.Categorical(ad.obs.Animal_ID.astype(str).str.cat(ad.obs.Bregma.astype(str),sep='_'))\n",
    "   \n",
    "    dct=collections.defaultdict(list)\n",
    "    for x in ad.obs.tissue_id.cat.categories:\n",
    "        idx=np.where(ad.obs.tissue_id==x)[0][0]\n",
    "        for nm in ['Animal_ID','Animal_sex','Behavior','Bregma']:\n",
    "            dct[nm].append(ad.obs.iloc[idx][nm])\n",
    "        dct['tissue_id'].append(x)\n",
    "    df=pd.DataFrame(dct,index=dct['tissue_id'])\n",
    "    df['split']=np.where(df['Animal_ID'].values>30,'test','train')\n",
    "    ad.uns['tissueinfo']=df\n",
    "\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c564ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basefn='/data/spatial/deepst_synthetic/'\n",
    "ad=process(basefn+\"synth0.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba7bfb",
   "metadata": {},
   "source": [
    "# construct edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a59fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius=30\n",
    "loc=ad.obs[['Centroid_X','Centroid_Y']].values\n",
    "rows=[]\n",
    "cols=[]\n",
    "for nm in tqdm.notebook.tqdm(ad.obs.tissue_id.cat.categories):\n",
    "    indicator=ad.obs.tissue_id==nm\n",
    "    adjacency=sklearn.neighbors.radius_neighbors_graph(loc[indicator],radius).tocoo()\n",
    "    rows.extend(np.where(indicator)[0][adjacency.row])\n",
    "    cols.extend(np.where(indicator)[0][adjacency.col])\n",
    "adjacency=sp.sparse.coo_matrix((np.ones(len(rows)),(rows,cols)),shape=(len(ad),len(ad))).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"../data/raw/synth0.hdf5\", \"r\") as h5f:\n",
    "    print(\"EXPRESSION AFTER\")\n",
    "    expression = h5f[\"expression\"][:]\n",
    "    print(type(expression[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ad.X[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.X, expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b44b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1sum=(adjacency@expression[:,1]+expression[:,1])\n",
    "X0=expression[:,0]\n",
    "\n",
    "print(\"MSE\",np.mean((np.where(X1sum>1,X1sum,0)-X0)**2))\n",
    "print(\"MSE\",np.mean((np.where(X1sum>=1,X1sum,0)-X0)**2))\n",
    "print(\"MSE\",np.mean((np.where(X1sum>.997,X1sum,0)-X0)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.where(X1sum>1,X1sum,0),X0)\n",
    "plt.xlabel(\"What formula says X0 should be\")\n",
    "plt.ylabel(\"What X0 actually is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77dc33c",
   "metadata": {},
   "source": [
    "# construct nefarious edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835774ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius=30 # oh noes, I got the radius wrong!\n",
    "loc=ad.obs[['Centroid_X','Centroid_Y']].values\n",
    "rows=[]\n",
    "cols=[]\n",
    "for nm in tqdm.notebook.tqdm(ad.obs.tissue_id.cat.categories):\n",
    "    indicator=ad.obs.tissue_id==nm\n",
    "    adjacency=sklearn.neighbors.radius_neighbors_graph(loc[indicator],radius).tocoo()\n",
    "    rows.extend(np.where(indicator)[0][adjacency.row])\n",
    "    cols.extend(np.where(indicator)[0][adjacency.col])\n",
    "nefarious_adjacency=sp.sparse.coo_matrix((np.ones(len(rows)),(rows,cols)),shape=(len(ad),len(ad))).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae613db4",
   "metadata": {},
   "source": [
    "# formulate dataset for use with pytorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9282187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pseudo(edge_index, pos):\n",
    "    coord1 = pos[edge_index[0]]\n",
    "    coord2 = pos[edge_index[1]]\n",
    "    edge_dir = coord2 - coord1\n",
    "    rho = torch.sqrt(edge_dir[:, 0] ** 2 + edge_dir[:, 1] ** 2).unsqueeze(-1)\n",
    "    return rho\n",
    "\n",
    "X=ad.X[:,1:]\n",
    "Y=ad.X[:,[0]]\n",
    "loc=ad.obs[['Centroid_X','Centroid_Y']].values\n",
    "\n",
    "datalist_train=[]\n",
    "datalist_test=[]\n",
    "for tid in tqdm.notebook.tqdm(ad.obs.tissue_id.cat.categories):\n",
    "    indicator=ad.obs.tissue_id==tid\n",
    "    subadj=nefarious_adjacency[indicator][:,indicator].tocoo()\n",
    "    subpos= torch.tensor(loc[indicator].astype(np.float32))\n",
    "    ei=torch.tensor(np.stack([subadj.row,subadj.col]).astype(int))\n",
    "    pseudo=calc_pseudo(ei,subpos)#/30.0 # between 0 and 1, since only considering neighbors within radius 30\n",
    "    batch=torch_geometric.data.Data(\n",
    "        x=torch.tensor(np.log1p(X[indicator])),\n",
    "        y=torch.tensor(np.log1p(Y[indicator])),\n",
    "        edge_index=ei,\n",
    "        edge_attr=pseudo,\n",
    "    )\n",
    "    if ad.uns['tissueinfo'].loc[tid].Animal_ID>30:\n",
    "        datalist_test.append(batch)\n",
    "    else:\n",
    "        datalist_train.append(batch)\n",
    "    \n",
    "\n",
    "dl_train=torch_geometric.loader.DataLoader(datalist_train,shuffle=True)\n",
    "dl_test=torch_geometric.loader.DataLoader(datalist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6482148",
   "metadata": {},
   "source": [
    "# try to learn with GMMconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3beb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseReluGMMConvNetwork(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sizes,\n",
    "        edge_dim,\n",
    "        n_kernels,\n",
    "        **gmmargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        lst = []\n",
    "        for i in range(len(sizes) - 1):\n",
    "            gmmc = torch_geometric.nn.GMMConv(\n",
    "                sizes[i], sizes[i + 1], dim=edge_dim,kernel_size=n_kernels)\n",
    "            lst.append(gmmc)\n",
    "            \n",
    "        self.gmms = torch.nn.ModuleList(lst)\n",
    "\n",
    "    def forward(self, vals, edges, pseudo):\n",
    "        orig_vals = vals\n",
    "        for i, gmmlayer in enumerate(self.gmms):\n",
    "            vals = gmmlayer(vals, edges, pseudo)\n",
    "            \n",
    "            if (i != len(self.gmms) - 1):\n",
    "                vals = torch.relu(vals)\n",
    "\n",
    "        return vals\n",
    "\n",
    "class MSEPredictor(pl.LightningModule):\n",
    "    def __init__(self,n,lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.net=DenseReluGMMConvNetwork([n,512,512,512,1],edge_dim=1,n_kernels=5)\n",
    "        \n",
    "    def calc_lossinfo(self,batch):\n",
    "        guess=self.net(batch.x,batch.edge_index,batch.edge_attr)\n",
    "        print(batch.y)\n",
    "        loss=torch.mean((guess-batch.y)**2)\n",
    "        return dict(\n",
    "            loss=loss\n",
    "        )\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        info=self.calc_lossinfo(batch)\n",
    "        self.log('train_loss',info['loss'],prog_bar=True,batch_size=1)\n",
    "        return info['loss']\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        info=self.calc_lossinfo(batch)\n",
    "        self.log('val_loss',info['loss'],prog_bar=True,batch_size=1)\n",
    "        return info['loss']\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ea94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('lightning_logs/version_0'):\n",
    "    shutil.rmtree('lightning_logs/version_0')\n",
    "\n",
    "logger=pl.loggers.CSVLogger('.',version=0)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,accelerator='gpu',\n",
    "    devices=[3],logger=logger,log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "model=MSEPredictor(ad.shape[1]-1)\n",
    "\n",
    "trainer.fit(model,train_dataloaders=dl_train,val_dataloaders=dl_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('lightning_logs/version_0/metrics.csv')\n",
    "n=len(df)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(df['train_loss'].dropna().index,df['train_loss'].dropna(),'.')\n",
    "plt.plot(df['val_loss'].dropna().index,df['val_loss'].dropna(),'rx')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "df2=df.iloc[n//2:]\n",
    "plt.plot(df2['train_loss'].dropna().index,df2['train_loss'].dropna(),'.')\n",
    "plt.plot(df2['val_loss'].dropna().index,df2['val_loss'].dropna(),'rx')\n",
    "\n",
    "# plt.xlim(250,None)\n",
    "# plt.ylim(1e6,1.5e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660da2e",
   "metadata": {},
   "source": [
    "$\\uparrow$ that's not converged.  Needs more epochs.  But anyway, it doesn't run out of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final losses for each validation tissue\n",
    "losses=[]\n",
    "for batch in tqdm.notebook.tqdm(dl_test):\n",
    "    losses.append(float(model.calc_lossinfo(batch)['loss'].detach().cpu().numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(losses).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kernels at each layer\n",
    "xs=np.r_[0:1:100j]\n",
    "for i,gmm in enumerate(model.net.gmms):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    for mu,sig in zip(gmm.mu.detach().cpu().numpy().ravel(),gmm.sigma.detach().cpu().numpy().ravel()):\n",
    "        sig=np.abs(sig)\n",
    "        plt.plot(xs,sp.stats.norm.pdf(xs,loc=mu,scale=sig),color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd3c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
