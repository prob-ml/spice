{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "molecular-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A graph convolutional autoencoder for MERFISH data.\"\"\"\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from spatial.models import base_networks\n",
    "\n",
    "\n",
    "def calc_pseudo(edge_index, pos):\n",
    "    \"\"\"\n",
    "    Calculate pseudo\n",
    "\n",
    "    Input:\n",
    "      - edge_index, an (N_edges x 2) long tensor indicating edges of a graph\n",
    "      - pos, an (N_vertices x 2) float tensor indicating coordinates of nodes\n",
    "\n",
    "    Output:\n",
    "      - pseudo, an (N_edges x 2) float tensor indicating edge-values\n",
    "        (to be used in graph-convnet)\n",
    "    \"\"\"\n",
    "    coord1 = pos[edge_index[0]]\n",
    "    coord2 = pos[edge_index[1]]\n",
    "    edge_dir = coord2 - coord1\n",
    "    rho = torch.sqrt(edge_dir[:, 0] ** 2 + edge_dir[:, 1] ** 2).unsqueeze(-1)\n",
    "    theta = torch.atan2(edge_dir[:, 1], edge_dir[:, 0]).unsqueeze(-1)\n",
    "    return torch.cat((rho, theta), dim=1)\n",
    "\n",
    "\n",
    "class BasicAEMixin(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Mixin implementing\n",
    "\n",
    "    - loss calculations\n",
    "    - training_step, validation_step,test_step,configure_optimizers for pytorchlightning\n",
    "    \"\"\"\n",
    "\n",
    "    def calc_loss(self, pred, val):\n",
    "        if self.loss_type == \"mse_against_log1pdata\":\n",
    "            return torch.sum((pred - torch.log(1 + val)) ** 2)\n",
    "        elif self.loss_type == \"mse\":\n",
    "            return torch.sum((pred - val) ** 2)\n",
    "        else:\n",
    "            raise NotImplementedError(self.loss_type)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, reconstruction = self(batch)\n",
    "        loss = calc_loss(reconstruction, batch.x)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, reconstruction = self(batch)\n",
    "        loss = self.calc_loss(reconstruction, batch.x)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "\n",
    "class TrivialAutoencoder(BasicAEMixin):\n",
    "    \"\"\"Autoencoder for graph data, ignoring the graph structurea\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, observables_dimension, hidden_dimensions, latent_dimension, loss_type\n",
    "    ):\n",
    "        \"\"\"\n",
    "        observables_dimension -- number of values associated with each graph node\n",
    "        hidden_dimensions -- list of hidden values to associate with each graph node\n",
    "        latent_dimension -- number of latent values to associate with each graph node\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        self.encoder_network = base_networks.construct_dense_relu_network(\n",
    "            [observables_dimension] + list(hidden_dimensions) + [latent_dimension],\n",
    "        )\n",
    "\n",
    "        self.decoder_network = base_networks.construct_dense_relu_network(\n",
    "            [latent_dimension]\n",
    "            + list(reversed(hidden_dimensions))\n",
    "            + [observables_dimension],\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        latent_loadings = self.encoder_network(batch.x)\n",
    "        expr_reconstruction = self.decoder_network(latent_loadings)\n",
    "        return latent_loadings, expr_reconstruction\n",
    "\n",
    "\n",
    "class MonetAutoencoder2D(BasicAEMixin):\n",
    "    \"\"\"Autoencoder for graph data whose nodes are embedded in 2d\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        observables_dimension,\n",
    "        hidden_dimensions,\n",
    "        latent_dimension,\n",
    "        loss_type,\n",
    "        dim,\n",
    "        kernel_size,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        observables_dimension -- number of values associated with each graph node\n",
    "        latent_dimension -- number of latent values to associate with each graph node\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        self.encoder_network = base_networks.DenseReluGMMConvNetwork(\n",
    "            [observables_dimension] + list(hidden_dimensions) + [latent_dimension],\n",
    "            dim=2,\n",
    "            kernel_size=25,\n",
    "        )\n",
    "        self.decoder_network = base_networks.DenseReluGMMConvNetwork(\n",
    "            [latent_dimension]\n",
    "            + list(reversed(hidden_dimensions))\n",
    "            + [observables_dimension],\n",
    "            dim=2,\n",
    "            kernel_size=25,\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        pseudo = calc_pseudo(batch.edge_index, batch.pos)\n",
    "        latent_loadings = self.encoder_network(batch.x, batch.edge_index, pseudo)\n",
    "        expr_reconstruction = self.decoder_network(\n",
    "            latent_loadings, batch.edge_index, pseudo\n",
    "        )\n",
    "        return latent_loadings, expr_reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aging-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import types\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "class MerfishDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(self, root, n_neighbors=3, train=True):\n",
    "        super().__init__(root)\n",
    "\n",
    "        data_list = self.construct_graphs(n_neighbors, train)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            self.gene_names = h5f[\"gene_names\"][:][~self.bad_genes].astype(\"U\")\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    url = \"https://datadryad.org/stash/downloads/file_stream/67671\"\n",
    "\n",
    "    behavior_types = [\n",
    "        \"Naive\",\n",
    "        \"Parenting\",\n",
    "        \"Virgin Parenting\",\n",
    "        \"Aggression to pup\",\n",
    "        \"Aggression to adult\",\n",
    "        \"Mating\",\n",
    "    ]\n",
    "    behavior_lookup = {x: i for (i, x) in enumerate(behavior_types)}\n",
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]\n",
    "    celltype_lookup = {x: i for (i, x) in enumerate(cell_types)}\n",
    "\n",
    "    bad_genes = np.zeros(161, dtype=bool)\n",
    "    bad_genes[144] = True\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"merfish.csv\", \"merfish.hdf5\"]\n",
    "\n",
    "    @property\n",
    "    def merfish_csv(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.csv\")\n",
    "\n",
    "    @property\n",
    "    def merfish_hdf5(self):\n",
    "        return os.path.join(self.raw_dir, \"merfish.hdf5\")\n",
    "\n",
    "    def download(self):\n",
    "        # download csv if necessary\n",
    "        if not os.path.exists(self.merfish_csv):\n",
    "            with open(self.merfish_csv, \"wb\") as csvf:\n",
    "                csvf.write(requests.get(self.url).content)\n",
    "\n",
    "        # process csv if necessary\n",
    "        dataframe = pd.read_csv(self.merfish_csv)\n",
    "\n",
    "        with h5py.File(self.merfish_hdf5, \"w\") as h5f:\n",
    "            for colnm, dtype in zip(dataframe.keys()[:9], dataframe.dtypes[:9]):\n",
    "                if dtype.kind == \"O\":\n",
    "                    data = np.require(dataframe[colnm], dtype=\"S36\")\n",
    "                    h5f.create_dataset(colnm, data=data)\n",
    "                else:\n",
    "                    h5f.create_dataset(colnm, data=np.require(dataframe[colnm]))\n",
    "\n",
    "            expression = np.array(dataframe[dataframe.keys()[9:]]).astype(np.float16)\n",
    "            h5f.create_dataset(\"expression\", data=expression)\n",
    "\n",
    "            gene_names = np.array(dataframe.keys()[9:], dtype=\"S80\")\n",
    "            h5f.create_dataset(\"gene_names\", data=gene_names)\n",
    "\n",
    "    def construct_graph(self, data, anid, breg, n_neighbors):\n",
    "        # get subset of cells in this slice\n",
    "        good = (data.anids == anid) & (data.bregs == breg)\n",
    "\n",
    "        # figure out neighborhood structure\n",
    "        locations_for_this_slice = data.locations[good]\n",
    "        nbrs = neighbors.NearestNeighbors(\n",
    "            n_neighbors=n_neighbors + 1, algorithm=\"ball_tree\"\n",
    "        )\n",
    "        nbrs.fit(locations_for_this_slice)\n",
    "        _, kneighbors = nbrs.kneighbors(locations_for_this_slice)\n",
    "        edges = np.concatenate(\n",
    "            [np.c_[kneighbors[:, 0], kneighbors[:, i + 1]] for i in range(n_neighbors)],\n",
    "            axis=0,\n",
    "        )\n",
    "        edges = torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "        # remove gene 144.  which is bad.  for some reason.\n",
    "        subexpression = data.expression[good]\n",
    "        subexpression = subexpression[:, ~self.bad_genes]\n",
    "\n",
    "        # get behavior ids\n",
    "        behavior_ids = np.array([self.behavior_lookup[x] for x in data.behavior[good]])\n",
    "        celltype_ids = np.array([self.celltype_lookup[x] for x in data.celltypes[good]])\n",
    "        labelinfo = np.c_[behavior_ids, celltype_ids]\n",
    "\n",
    "        # make it into a torch geometric data object, add it to the list!\n",
    "        return torch_geometric.data.Data(\n",
    "            x=torch.tensor(subexpression.astype(np.float32)),\n",
    "            edge_index=edges,\n",
    "            pos=torch.tensor(locations_for_this_slice.astype(np.float32)),\n",
    "            y=torch.tensor(labelinfo),\n",
    "        )\n",
    "\n",
    "    def construct_graphs(self, n_neighbors, train):\n",
    "        # load hdf5\n",
    "        with h5py.File(self.merfish_hdf5, \"r\") as h5f:\n",
    "            # pylint: disable=no-member\n",
    "            data = types.SimpleNamespace(\n",
    "                anids=h5f[\"Animal_ID\"][:],\n",
    "                bregs=h5f[\"Bregma\"][:],\n",
    "                expression=h5f[\"expression\"][:],\n",
    "                locations=np.c_[h5f[\"Centroid_X\"][:], h5f[\"Centroid_Y\"][:]],\n",
    "                behavior=h5f[\"Behavior\"][:].astype(\"U\"),\n",
    "                celltypes=h5f[\"Cell_class\"][:].astype(\"U\"),\n",
    "            )\n",
    "\n",
    "        # get the (animal_id,bregma) pairs that define a unique slice\n",
    "        unique_slices = np.unique(np.c_[data.anids, data.bregs], axis=0)\n",
    "\n",
    "        # are we looking at train or test sets?\n",
    "        unique_slices = unique_slices[:150] if train else unique_slices[150:]\n",
    "\n",
    "        # store all the slices in this list...\n",
    "        data_list = []\n",
    "        for anid, breg in unique_slices:\n",
    "            data_list.append(self.construct_graph(data, anid, breg, n_neighbors))\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "animal-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merfish = pd.read_csv(\"../data/raw/merfish.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
