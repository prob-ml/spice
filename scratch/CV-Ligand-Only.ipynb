{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d5a0a00",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb453cc3",
   "metadata": {},
   "source": [
    "OR Write a single script that starts with call to FilteredMerfishDataset, extract animals with that behavior and sex, and then run a CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a061577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from spatial.merfish_dataset import FilteredMerfishDataset, MerfishDataset\n",
    "from spatial.models.monet_ae import MonetAutoencoder2D, TrivialAutoencoder\n",
    "from spatial.train import train\n",
    "from spatial.predict import test\n",
    "\n",
    "import torch\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e0766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cbln1', 'Cxcl14', 'Crhbp', 'Gabra1', 'Cbln2', 'Gpr165', 'Glra3', 'Gabrg1', 'Adora2a', 'Vgf', 'Scg2', 'Cartpt', 'Tac2', 'Bdnf', 'Bmp7', 'Cyr61', 'Fn1', 'Fst', 'Gad1', 'Ntng1', 'Pnoc', 'Selplg', 'Sema3c', 'Sema4d', 'Serpine1', 'Adcyap1', 'Cck', 'Crh', 'Gal', 'Gnrh1', 'Nts', 'Oxt', 'Penk', 'Sst', 'Tac1', 'Trh', 'Ucn3', 'Avpr1a', 'Avpr2', 'Brs3', 'Calcr', 'Cckar', 'Cckbr', 'Crhr1', 'Crhr2', 'Galr1', 'Galr2', 'Grpr', 'Htr2c', 'Igf1r', 'Igf2r', 'Kiss1r', 'Lepr', 'Lpar1', 'Mc4r', 'Npy1r', 'Npy2r', 'Ntsr1', 'Oprd1', 'Oprk1', 'Oprl1', 'Oxtr', 'Pdgfra', 'Prlr', 'Ramp3', 'Rxfp1', 'Slc17a7', 'Slc18a2', 'Tacr1', 'Tacr3', 'Trhr']\n",
      "There are 71 genes recognized as either ligands or receptors (including new ones).\n",
      "There are 0 blank genes.\n",
      "There are 84 genes that are treated as response variables.\n",
      "There are 31 ligands.\n",
      "There are 40 receptors.\n"
     ]
    }
   ],
   "source": [
    "# read in merfish dataset and get columns names\n",
    "import pandas as pd\n",
    "\n",
    "# get relevant data stuff\n",
    "df_file = pd.ExcelFile(\"~/spatial/data/messi.xlsx\")\n",
    "messi_df = pd.read_excel(df_file, \"All.Pairs\")\n",
    "merfish_df = pd.read_csv(\"~/spatial/data/raw/merfish.csv\")\n",
    "merfish_df = merfish_df.drop(['Blank_1', 'Blank_2', 'Blank_3', 'Blank_4', 'Blank_5', 'Fos'], axis=1)\n",
    "\n",
    "# these are the 13 ligands or receptors found in MESSI\n",
    "non_response_genes = ['Cbln1', 'Cxcl14', 'Crhbp', 'Gabra1', 'Cbln2', 'Gpr165', \n",
    "                      'Glra3', 'Gabrg1', 'Adora2a', 'Vgf', 'Scg2', 'Cartpt',\n",
    "                      'Tac2']\n",
    "# this list stores the control genes aka \"Blank_{int}\"\n",
    "blank_genes = []\n",
    "\n",
    "# we will populate all of the non-response genes as being in one or the other\n",
    "# the ones already filled in come from the existing 13 L/R genes above\n",
    "ligands = [\"Cbln1\", \"Cxcl14\", \"Cbln2\", \"Vgf\", \"Scg2\", \"Cartpt\", \"Tac2\"]\n",
    "receptors = [\"Crhbp\", \"Gabra1\", \"Gpr165\", \"Glra3\", \"Gabrg1\", \"Adora2a\"]\n",
    "\n",
    "# ligands and receptor indexes in MERFISH\n",
    "non_response_indeces = [list(merfish_df.columns).index(gene)-9 for gene in non_response_genes]\n",
    "ligand_indeces = [list(merfish_df.columns).index(gene)-9 for gene in ligands]\n",
    "receptor_indeces = [list(merfish_df.columns).index(gene)-9 for gene in receptors]\n",
    "all_pairs_columns = [\n",
    "    \"Ligand.ApprovedSymbol\",\n",
    "    \"Receptor.ApprovedSymbol\",\n",
    "]\n",
    "\n",
    "\n",
    "# for column name in the column names above\n",
    "for column in all_pairs_columns:\n",
    "    for gene in merfish_df.columns:\n",
    "        if (\n",
    "            gene.upper() in list(messi_df[column])\n",
    "            and gene.upper() not in non_response_genes\n",
    "        ):\n",
    "            non_response_genes.append(gene)\n",
    "            non_response_indeces.append(list(merfish_df.columns).index(gene)-9)\n",
    "            if column[0] == \"L\":\n",
    "                ligands.append(gene)\n",
    "                ligand_indeces.append(list(merfish_df.columns).index(gene)-9)\n",
    "            else:\n",
    "                receptors.append(gene)\n",
    "                receptor_indeces.append(list(merfish_df.columns).index(gene)-9)\n",
    "        if gene[:5] == \"Blank\" and gene not in blank_genes:\n",
    "            blank_genes.append(gene)\n",
    "            # non_response_indeces.append(list(merfish_df.columns).index(gene)-9)\n",
    "\n",
    "print(non_response_genes)\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(non_response_genes))\n",
    "    + \" genes recognized as either ligands or receptors (including new ones).\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(blank_genes))\n",
    "    + \" blank genes.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(155 - len(blank_genes) - len(non_response_genes))\n",
    "    + \" genes that are treated as response variables.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(ligands))\n",
    "    + \" ligands.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"There are \"\n",
    "    + str(len(receptors))\n",
    "    + \" receptors.\"\n",
    ")\n",
    "\n",
    "response_indeces = list(set(range(155)) - set(non_response_indeces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59d3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors = [\"Parenting\", \"Virgin Parenting\", \"Naive\"]\n",
    "sexes = [\"Female\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a80b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('animal_id.json') as json_file:\n",
    "    animals = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90ad5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:59: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 5. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf67d719457499487cfab095e09325e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 109: val_loss reached 0.44763 (best 0.44763), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 219: val_loss reached 0.40596 (best 0.40596), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 329: val_loss reached 0.39518 (best 0.39518), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 439: val_loss reached 0.36001 (best 0.36001), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 549: val_loss reached 0.34749 (best 0.34749), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 659: val_loss reached 0.33669 (best 0.33669), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 769: val_loss reached 0.32639 (best 0.32639), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 879: val_loss reached 0.31859 (best 0.31859), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 989: val_loss reached 0.31698 (best 0.31698), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1099: val_loss reached 0.31138 (best 0.31138), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1209: val_loss reached 0.30461 (best 0.30461), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1319: val_loss reached 0.30285 (best 0.30285), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1429: val_loss reached 0.30112 (best 0.30112), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 1539: val_loss reached 0.29675 (best 0.29675), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 1649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 1759: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 1869: val_loss reached 0.29414 (best 0.29414), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 1979: val_loss reached 0.29346 (best 0.29346), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2089: val_loss reached 0.29238 (best 0.29238), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 2309: val_loss reached 0.29228 (best 0.29228), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 2419: val_loss reached 0.29038 (best 0.29038), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 2529: val_loss reached 0.28994 (best 0.28994), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 2639: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 2749: val_loss reached 0.28976 (best 0.28976), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 2859: val_loss reached 0.28871 (best 0.28871), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 2969: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 3079: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 3189: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 3409: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 3519: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 3629: val_loss reached 0.28840 (best 0.28840), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 3739: val_loss reached 0.28819 (best 0.28819), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 3849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 3959: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 4069: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 4179: val_loss reached 0.28742 (best 0.28742), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 4289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 4399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 4509: val_loss reached 0.28689 (best 0.28689), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 4619: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 4729: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 4839: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 5059: val_loss reached 0.28646 (best 0.28646), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 5169: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 5279: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 5389: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 5499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 5609: val_loss reached 0.28646 (best 0.28646), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 5719: val_loss reached 0.28610 (best 0.28610), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 5829: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 5939: val_loss reached 0.28591 (best 0.28591), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 6049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 6159: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 6269: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 6379: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 6489: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 6599: val_loss reached 0.28532 (best 0.28532), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_16.ckpt\" as top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  882.13         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.463          \t|600            \t|  877.8          \t|  99.509         \t|\n",
      "run_training_batch                 \t|  0.081112       \t|6600           \t|  535.34         \t|  60.687         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.047285       \t|6600           \t|  312.08         \t|  35.378         \t|\n",
      "training_step_and_backward         \t|  0.042937       \t|6600           \t|  283.39         \t|  32.125         \t|\n",
      "model_forward                      \t|  0.03275        \t|6600           \t|  216.15         \t|  24.503         \t|\n",
      "training_step                      \t|  0.03251        \t|6600           \t|  214.56         \t|  24.323         \t|\n",
      "get_train_batch                    \t|  0.022101       \t|7200           \t|  159.13         \t|  18.039         \t|\n",
      "fetch_next_train_batch             \t|  0.022068       \t|7200           \t|  158.89         \t|  18.012         \t|\n",
      "backward                           \t|  0.0095834      \t|6600           \t|  63.25          \t|  7.1702         \t|\n",
      "training_batch_to_device           \t|  0.0027398      \t|6600           \t|  18.083         \t|  2.0499         \t|\n",
      "on_train_batch_end                 \t|  0.0025445      \t|6600           \t|  16.794         \t|  1.9038         \t|\n",
      "get_validate_batch                 \t|  0.099996       \t|120            \t|  11.999         \t|  1.3603         \t|\n",
      "fetch_next_validate_batch          \t|  0.099925       \t|120            \t|  11.991         \t|  1.3593         \t|\n",
      "on_validation_end                  \t|  0.11816        \t|61             \t|  7.2077         \t|  0.81708        \t|\n",
      "zero_grad                          \t|  0.00057098     \t|6600           \t|  3.7685         \t|  0.4272         \t|\n",
      "evaluation_step_and_end            \t|  0.043249       \t|61             \t|  2.6382         \t|  0.29907        \t|\n",
      "validation_step                    \t|  0.043052       \t|61             \t|  2.6262         \t|  0.29771        \t|\n",
      "on_validation_start                \t|  0.0235         \t|61             \t|  1.4335         \t|  0.1625         \t|\n",
      "on_train_batch_start               \t|  0.00021698     \t|6600           \t|  1.4321         \t|  0.16234        \t|\n",
      "on_train_epoch_start               \t|  0.0017139      \t|600            \t|  1.0283         \t|  0.11658        \t|\n",
      "on_train_epoch_end                 \t|  0.00087848     \t|600            \t|  0.52709        \t|  0.059752       \t|\n",
      "training_step_end                  \t|  6.1959e-05     \t|6600           \t|  0.40893        \t|  0.046357       \t|\n",
      "on_batch_start                     \t|  5.0163e-05     \t|6600           \t|  0.33107        \t|  0.037531       \t|\n",
      "evaluation_batch_to_device         \t|  0.0039024      \t|61             \t|  0.23805        \t|  0.026985       \t|\n",
      "on_after_backward                  \t|  3.5088e-05     \t|6600           \t|  0.23158        \t|  0.026252       \t|\n",
      "on_before_zero_grad                \t|  3.1763e-05     \t|6600           \t|  0.20963        \t|  0.023765       \t|\n",
      "on_batch_end                       \t|  3.0897e-05     \t|6600           \t|  0.20392        \t|  0.023117       \t|\n",
      "on_before_optimizer_step           \t|  2.7396e-05     \t|6600           \t|  0.18081        \t|  0.020497       \t|\n",
      "on_before_backward                 \t|  2.7003e-05     \t|6600           \t|  0.17822        \t|  0.020203       \t|\n",
      "get_sanity_check_batch             \t|  0.080251       \t|2              \t|  0.1605         \t|  0.018195       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.080183       \t|2              \t|  0.16037        \t|  0.018179       \t|\n",
      "on_validation_batch_end            \t|  0.0020818      \t|61             \t|  0.12699        \t|  0.014396       \t|\n",
      "on_train_start                     \t|  0.026158       \t|1              \t|  0.026158       \t|  0.0029653      \t|\n",
      "on_sanity_check_start              \t|  0.020803       \t|1              \t|  0.020803       \t|  0.0023583      \t|\n",
      "on_epoch_end                       \t|  3.1e-05        \t|661            \t|  0.020491       \t|  0.0023229      \t|\n",
      "on_epoch_start                     \t|  2.822e-05      \t|661            \t|  0.018653       \t|  0.0021146      \t|\n",
      "on_validation_model_eval           \t|  0.00015783     \t|61             \t|  0.0096279      \t|  0.0010914      \t|\n",
      "on_validation_batch_start          \t|  0.00010872     \t|61             \t|  0.0066321      \t|  0.00075183     \t|\n",
      "validation_step_end                \t|  7.6127e-05     \t|61             \t|  0.0046438      \t|  0.00052642     \t|\n",
      "on_pretrain_routine_start          \t|  0.0042434      \t|1              \t|  0.0042434      \t|  0.00048104     \t|\n",
      "on_validation_epoch_end            \t|  3.5892e-05     \t|61             \t|  0.0021894      \t|  0.0002482      \t|\n",
      "on_validation_epoch_start          \t|  2.782e-05      \t|61             \t|  0.001697       \t|  0.00019237     \t|\n",
      "on_train_end                       \t|  0.00091906     \t|1              \t|  0.00091906     \t|  0.00010419     \t|\n",
      "configure_optimizers               \t|  0.00023226     \t|1              \t|  0.00023226     \t|  2.6329e-05     \t|\n",
      "on_fit_end                         \t|  4.1195e-05     \t|1              \t|  4.1195e-05     \t|  4.67e-06       \t|\n",
      "teardown                           \t|  3.9551e-05     \t|1              \t|  3.9551e-05     \t|  4.4836e-06     \t|\n",
      "on_fit_start                       \t|  3.6331e-05     \t|1              \t|  3.6331e-05     \t|  4.1185e-06     \t|\n",
      "on_sanity_check_end                \t|  3.2319e-05     \t|1              \t|  3.2319e-05     \t|  3.6637e-06     \t|\n",
      "on_pretrain_routine_end            \t|  2.7002e-05     \t|1              \t|  2.7002e-05     \t|  3.061e-06      \t|\n",
      "setup                              \t|  1.9878e-05     \t|1              \t|  1.9878e-05     \t|  2.2534e-06     \t|\n",
      "on_configure_sharded_model         \t|  1.8273e-05     \t|1              \t|  1.8273e-05     \t|  2.0715e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.5699e-05     \t|1              \t|  1.5699e-05     \t|  1.7797e-06     \t|\n",
      "configure_callbacks                \t|  1.1039e-05     \t|1              \t|  1.1039e-05     \t|  1.2514e-06     \t|\n",
      "on_train_dataloader                \t|  7.2529e-06     \t|1              \t|  7.2529e-06     \t|  8.222e-07      \t|\n",
      "configure_sharded_model            \t|  6.5719e-06     \t|1              \t|  6.5719e-06     \t|  7.45e-07       \t|\n",
      "on_val_dataloader                  \t|  4.8939e-06     \t|1              \t|  4.8939e-06     \t|  5.5478e-07     \t|\n",
      "prepare_data                       \t|  4.801e-06      \t|1              \t|  4.801e-06      \t|  5.4425e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0da3253a9c4b72ac258de13f947f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.6513         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.5965         \t|1              \t|  3.5965         \t|  98.499         \t|\n",
      "evaluation_step_and_end            \t|  0.61801        \t|4              \t|  2.472          \t|  67.703         \t|\n",
      "test_step                          \t|  0.60356        \t|4              \t|  2.4142         \t|  66.12          \t|\n",
      "get_test_batch                     \t|  0.090184       \t|5              \t|  0.45092        \t|  12.349         \t|\n",
      "fetch_next_test_batch              \t|  0.09014        \t|5              \t|  0.4507         \t|  12.344         \t|\n",
      "on_test_batch_end                  \t|  0.020647       \t|4              \t|  0.082589       \t|  2.2619         \t|\n",
      "evaluation_batch_to_device         \t|  0.015099       \t|4              \t|  0.060398       \t|  1.6541         \t|\n",
      "test_step_end                      \t|  0.01428        \t|4              \t|  0.057119       \t|  1.5643         \t|\n",
      "on_test_start                      \t|  0.02032        \t|1              \t|  0.02032        \t|  0.55651        \t|\n",
      "on_test_end                        \t|  0.0020966      \t|1              \t|  0.0020966      \t|  0.057421       \t|\n",
      "on_test_batch_start                \t|  6.2897e-05     \t|4              \t|  0.00025159     \t|  0.0068903      \t|\n",
      "on_test_model_eval                 \t|  9.5973e-05     \t|1              \t|  9.5973e-05     \t|  0.0026285      \t|\n",
      "on_test_epoch_end                  \t|  6.3593e-05     \t|1              \t|  6.3593e-05     \t|  0.0017416      \t|\n",
      "teardown                           \t|  4.9071e-05     \t|1              \t|  4.9071e-05     \t|  0.0013439      \t|\n",
      "on_epoch_end                       \t|  4.2004e-05     \t|1              \t|  4.2004e-05     \t|  0.0011504      \t|\n",
      "on_epoch_start                     \t|  2.2869e-05     \t|1              \t|  2.2869e-05     \t|  0.00062632     \t|\n",
      "on_configure_sharded_model         \t|  1.9056e-05     \t|1              \t|  1.9056e-05     \t|  0.0005219      \t|\n",
      "on_test_epoch_start                \t|  1.8555e-05     \t|1              \t|  1.8555e-05     \t|  0.00050817     \t|\n",
      "configure_callbacks                \t|  1.4328e-05     \t|1              \t|  1.4328e-05     \t|  0.00039241     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.344e-05      \t|1              \t|  1.344e-05      \t|  0.00036809     \t|\n",
      "setup                              \t|  1.2386e-05     \t|1              \t|  1.2386e-05     \t|  0.00033922     \t|\n",
      "on_test_dataloader                 \t|  6.075e-06      \t|1              \t|  6.075e-06      \t|  0.00016638     \t|\n",
      "configure_sharded_model            \t|  5.773e-06      \t|1              \t|  5.773e-06      \t|  0.00015811     \t|\n",
      "prepare_data                       \t|  4.421e-06      \t|1              \t|  4.421e-06      \t|  0.00012108     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.31643128395080566,\n",
      " 'test_loss: mae_response': 0.38502514362335205,\n",
      " 'test_loss: mse': 0.39279359579086304}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1c0c291da748e38c8895e8491ed868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 109: val_loss reached 0.48723 (best 0.48723), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 219: val_loss reached 0.43751 (best 0.43751), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 329: val_loss reached 0.41684 (best 0.41684), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 439: val_loss reached 0.39240 (best 0.39240), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 549: val_loss reached 0.37624 (best 0.37624), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 659: val_loss reached 0.35994 (best 0.35994), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 769: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 879: val_loss reached 0.35320 (best 0.35320), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 989: val_loss reached 0.34081 (best 0.34081), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1099: val_loss reached 0.33492 (best 0.33492), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1209: val_loss reached 0.33030 (best 0.33030), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1319: val_loss reached 0.32625 (best 0.32625), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1429: val_loss reached 0.32326 (best 0.32326), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 1539: val_loss reached 0.32121 (best 0.32121), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 1649: val_loss reached 0.31999 (best 0.31999), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 1759: val_loss reached 0.31912 (best 0.31912), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 1869: val_loss reached 0.31864 (best 0.31864), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 1979: val_loss reached 0.31631 (best 0.31631), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2089: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2199: val_loss reached 0.31461 (best 0.31461), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 2309: val_loss reached 0.31372 (best 0.31372), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 2419: val_loss reached 0.31285 (best 0.31285), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 2529: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 2639: val_loss reached 0.31221 (best 0.31221), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 2749: val_loss reached 0.31148 (best 0.31148), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 2859: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 2969: val_loss reached 0.31043 (best 0.31043), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 3079: val_loss reached 0.31037 (best 0.31037), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 3189: val_loss reached 0.30890 (best 0.30890), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 3409: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 3519: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 3629: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 3739: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 3849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 3959: val_loss reached 0.30741 (best 0.30741), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 4069: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 4179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 4289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 4399: val_loss reached 0.30733 (best 0.30733), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 4509: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 4619: val_loss reached 0.30702 (best 0.30702), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 4729: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 4839: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 5059: val_loss reached 0.30625 (best 0.30625), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 5169: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 5279: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 5389: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 5499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 5609: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 5719: val_loss reached 0.30557 (best 0.30557), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_17.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 5829: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 5939: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 6049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 6159: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 6269: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 6379: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 6489: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 6599: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  949.75         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.5815         \t|600            \t|  948.89         \t|  99.909         \t|\n",
      "run_training_batch                 \t|  0.081606       \t|6600           \t|  538.6          \t|  56.71          \t|\n",
      "optimizer_step_with_closure_0      \t|  0.047835       \t|6600           \t|  315.71         \t|  33.241         \t|\n",
      "training_step_and_backward         \t|  0.043337       \t|6600           \t|  286.02         \t|  30.115         \t|\n",
      "model_forward                      \t|  0.033122       \t|6600           \t|  218.61         \t|  23.017         \t|\n",
      "training_step                      \t|  0.032872       \t|6600           \t|  216.96         \t|  22.844         \t|\n",
      "get_train_batch                    \t|  0.025646       \t|7200           \t|  184.65         \t|  19.442         \t|\n",
      "fetch_next_train_batch             \t|  0.025612       \t|7200           \t|  184.41         \t|  19.416         \t|\n",
      "backward                           \t|  0.0095785      \t|6600           \t|  63.218         \t|  6.6563         \t|\n",
      "training_batch_to_device           \t|  0.0028003      \t|6600           \t|  18.482         \t|  1.946          \t|\n",
      "on_train_batch_end                 \t|  0.0027044      \t|6600           \t|  17.849         \t|  1.8794         \t|\n",
      "get_validate_batch                 \t|  0.12165        \t|120            \t|  14.598         \t|  1.5371         \t|\n",
      "fetch_next_validate_batch          \t|  0.12158        \t|120            \t|  14.59          \t|  1.5362         \t|\n",
      "on_validation_end                  \t|  0.11004        \t|61             \t|  6.7123         \t|  0.70675        \t|\n",
      "zero_grad                          \t|  0.00060221     \t|6600           \t|  3.9746         \t|  0.41849        \t|\n",
      "evaluation_step_and_end            \t|  0.040999       \t|61             \t|  2.501          \t|  0.26333        \t|\n",
      "validation_step                    \t|  0.040818       \t|61             \t|  2.4899         \t|  0.26217        \t|\n",
      "on_validation_start                \t|  0.027389       \t|61             \t|  1.6707         \t|  0.17591        \t|\n",
      "on_train_batch_start               \t|  0.00023246     \t|6600           \t|  1.5342         \t|  0.16154        \t|\n",
      "on_train_epoch_start               \t|  0.0018933      \t|600            \t|  1.136          \t|  0.11961        \t|\n",
      "on_train_epoch_end                 \t|  0.00093042     \t|600            \t|  0.55825        \t|  0.058779       \t|\n",
      "training_step_end                  \t|  6.2889e-05     \t|6600           \t|  0.41506        \t|  0.043702       \t|\n",
      "on_batch_start                     \t|  5.0772e-05     \t|6600           \t|  0.3351         \t|  0.035283       \t|\n",
      "evaluation_batch_to_device         \t|  0.0039894      \t|61             \t|  0.24335        \t|  0.025623       \t|\n",
      "on_after_backward                  \t|  3.6867e-05     \t|6600           \t|  0.24332        \t|  0.02562        \t|\n",
      "get_sanity_check_batch             \t|  0.10937        \t|2              \t|  0.21874        \t|  0.023032       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.10931        \t|2              \t|  0.21862        \t|  0.023019       \t|\n",
      "on_batch_end                       \t|  3.2922e-05     \t|6600           \t|  0.21728        \t|  0.022878       \t|\n",
      "on_before_zero_grad                \t|  3.2852e-05     \t|6600           \t|  0.21682        \t|  0.02283        \t|\n",
      "on_before_optimizer_step           \t|  2.8946e-05     \t|6600           \t|  0.19104        \t|  0.020115       \t|\n",
      "on_before_backward                 \t|  2.8776e-05     \t|6600           \t|  0.18992        \t|  0.019997       \t|\n",
      "on_validation_batch_end            \t|  0.0023196      \t|61             \t|  0.1415         \t|  0.014898       \t|\n",
      "on_train_start                     \t|  0.039844       \t|1              \t|  0.039844       \t|  0.0041952      \t|\n",
      "on_sanity_check_start              \t|  0.023503       \t|1              \t|  0.023503       \t|  0.0024746      \t|\n",
      "on_epoch_end                       \t|  3.3176e-05     \t|661            \t|  0.021929       \t|  0.002309       \t|\n",
      "on_epoch_start                     \t|  3.114e-05      \t|661            \t|  0.020583       \t|  0.0021672      \t|\n",
      "on_validation_model_eval           \t|  0.00016829     \t|61             \t|  0.010265       \t|  0.0010809      \t|\n",
      "on_validation_batch_start          \t|  9.5931e-05     \t|61             \t|  0.0058518      \t|  0.00061614     \t|\n",
      "validation_step_end                \t|  7.835e-05      \t|61             \t|  0.0047794      \t|  0.00050322     \t|\n",
      "on_pretrain_routine_start          \t|  0.0031929      \t|1              \t|  0.0031929      \t|  0.00033618     \t|\n",
      "on_validation_epoch_end            \t|  3.958e-05      \t|61             \t|  0.0024144      \t|  0.00025421     \t|\n",
      "on_validation_epoch_start          \t|  3.2147e-05     \t|61             \t|  0.001961       \t|  0.00020647     \t|\n",
      "on_train_end                       \t|  0.0012706      \t|1              \t|  0.0012706      \t|  0.00013378     \t|\n",
      "configure_optimizers               \t|  0.000224       \t|1              \t|  0.000224       \t|  2.3585e-05     \t|\n",
      "on_fit_end                         \t|  6.7417e-05     \t|1              \t|  6.7417e-05     \t|  7.0984e-06     \t|\n",
      "on_sanity_check_end                \t|  6.3279e-05     \t|1              \t|  6.3279e-05     \t|  6.6627e-06     \t|\n",
      "teardown                           \t|  5.3001e-05     \t|1              \t|  5.3001e-05     \t|  5.5805e-06     \t|\n",
      "on_fit_start                       \t|  3.8545e-05     \t|1              \t|  3.8545e-05     \t|  4.0584e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.4502e-05     \t|1              \t|  3.4502e-05     \t|  3.6327e-06     \t|\n",
      "on_configure_sharded_model         \t|  2.3295e-05     \t|1              \t|  2.3295e-05     \t|  2.4528e-06     \t|\n",
      "configure_callbacks                \t|  2.135e-05      \t|1              \t|  2.135e-05      \t|  2.248e-06      \t|\n",
      "on_before_accelerator_backend_setup\t|  1.643e-05      \t|1              \t|  1.643e-05      \t|  1.7299e-06     \t|\n",
      "setup                              \t|  1.5678e-05     \t|1              \t|  1.5678e-05     \t|  1.6508e-06     \t|\n",
      "on_train_dataloader                \t|  1.0106e-05     \t|1              \t|  1.0106e-05     \t|  1.0641e-06     \t|\n",
      "on_val_dataloader                  \t|  7.3409e-06     \t|1              \t|  7.3409e-06     \t|  7.7293e-07     \t|\n",
      "configure_sharded_model            \t|  6.069e-06      \t|1              \t|  6.069e-06      \t|  6.3901e-07     \t|\n",
      "prepare_data                       \t|  4.8641e-06     \t|1              \t|  4.8641e-06     \t|  5.1214e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760756c3c0a949a8a873c49d69711afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.0282         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  2.9771         \t|1              \t|  2.9771         \t|  98.312         \t|\n",
      "evaluation_step_and_end            \t|  0.53171        \t|4              \t|  2.1268         \t|  70.234         \t|\n",
      "test_step                          \t|  0.51716        \t|4              \t|  2.0686         \t|  68.312         \t|\n",
      "get_test_batch                     \t|  0.076683       \t|5              \t|  0.38342        \t|  12.662         \t|\n",
      "fetch_next_test_batch              \t|  0.07664        \t|5              \t|  0.3832         \t|  12.654         \t|\n",
      "on_test_batch_end                  \t|  0.023429       \t|4              \t|  0.093718       \t|  3.0948         \t|\n",
      "test_step_end                      \t|  0.014389       \t|4              \t|  0.057557       \t|  1.9007         \t|\n",
      "evaluation_batch_to_device         \t|  0.012626       \t|4              \t|  0.050504       \t|  1.6678         \t|\n",
      "on_test_start                      \t|  0.021399       \t|1              \t|  0.021399       \t|  0.70665        \t|\n",
      "on_test_end                        \t|  0.0021825      \t|1              \t|  0.0021825      \t|  0.072074       \t|\n",
      "on_test_batch_start                \t|  6.7639e-05     \t|4              \t|  0.00027056     \t|  0.0089345      \t|\n",
      "on_test_model_eval                 \t|  0.00013126     \t|1              \t|  0.00013126     \t|  0.0043345      \t|\n",
      "on_test_epoch_end                  \t|  6.7318e-05     \t|1              \t|  6.7318e-05     \t|  0.002223       \t|\n",
      "on_epoch_end                       \t|  3.722e-05      \t|1              \t|  3.722e-05      \t|  0.0012291      \t|\n",
      "teardown                           \t|  3.5505e-05     \t|1              \t|  3.5505e-05     \t|  0.0011725      \t|\n",
      "on_epoch_start                     \t|  2.6848e-05     \t|1              \t|  2.6848e-05     \t|  0.0008866      \t|\n",
      "on_test_epoch_start                \t|  2.1809e-05     \t|1              \t|  2.1809e-05     \t|  0.0007202      \t|\n",
      "on_configure_sharded_model         \t|  2.1248e-05     \t|1              \t|  2.1248e-05     \t|  0.00070167     \t|\n",
      "configure_callbacks                \t|  1.6408e-05     \t|1              \t|  1.6408e-05     \t|  0.00054184     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4181e-05     \t|1              \t|  1.4181e-05     \t|  0.0004683      \t|\n",
      "setup                              \t|  1.2754e-05     \t|1              \t|  1.2754e-05     \t|  0.00042117     \t|\n",
      "on_test_dataloader                 \t|  1.1677e-05     \t|1              \t|  1.1677e-05     \t|  0.00038561     \t|\n",
      "configure_sharded_model            \t|  6.8611e-06     \t|1              \t|  6.8611e-06     \t|  0.00022657     \t|\n",
      "prepare_data                       \t|  5.282e-06      \t|1              \t|  5.282e-06      \t|  0.00017443     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.28883540630340576,\n",
      " 'test_loss: mae_response': 0.34985750913619995,\n",
      " 'test_loss: mse': 0.3376012444496155}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6f00c71b304557acb16a66681c3275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 109: val_loss reached 0.43691 (best 0.43691), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 219: val_loss reached 0.38931 (best 0.38931), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 329: val_loss reached 0.35757 (best 0.35757), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 439: val_loss reached 0.33601 (best 0.33601), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 549: val_loss reached 0.32292 (best 0.32292), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 659: val_loss reached 0.31757 (best 0.31757), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 769: val_loss reached 0.30612 (best 0.30612), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 879: val_loss reached 0.29985 (best 0.29985), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 989: val_loss reached 0.29531 (best 0.29531), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1099: val_loss reached 0.29421 (best 0.29421), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1209: val_loss reached 0.28836 (best 0.28836), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1319: val_loss reached 0.28551 (best 0.28551), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1429: val_loss reached 0.28456 (best 0.28456), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 1539: val_loss reached 0.28121 (best 0.28121), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 1649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 1759: val_loss reached 0.27941 (best 0.27941), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 1869: val_loss reached 0.27781 (best 0.27781), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 1979: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2089: val_loss reached 0.27574 (best 0.27574), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 2309: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 2419: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 2529: val_loss reached 0.27417 (best 0.27417), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 2639: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 2749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 2859: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 2969: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 3079: val_loss reached 0.27306 (best 0.27306), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 3189: val_loss reached 0.27031 (best 0.27031), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 3409: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 3519: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 3629: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 3739: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 3849: val_loss reached 0.26949 (best 0.26949), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 3959: val_loss reached 0.26930 (best 0.26930), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_18.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 4069: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 4179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 4289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 4399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 4509: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 4619: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 4729: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 4839: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 5059: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 5169: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 5279: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 5389: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 5499: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 5609: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 5719: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 5829: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 5939: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 6049: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 6159: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 6269: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 6379: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 6489: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 6599: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  939.67         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.5649         \t|600            \t|  938.93         \t|  99.921         \t|\n",
      "run_training_batch                 \t|  0.080086       \t|6600           \t|  528.57         \t|  56.25          \t|\n",
      "optimizer_step_with_closure_0      \t|  0.047006       \t|6600           \t|  310.24         \t|  33.016         \t|\n",
      "training_step_and_backward         \t|  0.042578       \t|6600           \t|  281.02         \t|  29.906         \t|\n",
      "model_forward                      \t|  0.032552       \t|6600           \t|  214.84         \t|  22.863         \t|\n",
      "training_step                      \t|  0.032305       \t|6600           \t|  213.21         \t|  22.69          \t|\n",
      "get_train_batch                    \t|  0.025749       \t|7200           \t|  185.39         \t|  19.73          \t|\n",
      "fetch_next_train_batch             \t|  0.025716       \t|7200           \t|  185.15         \t|  19.704         \t|\n",
      "backward                           \t|  0.0093978      \t|6600           \t|  62.025         \t|  6.6007         \t|\n",
      "training_batch_to_device           \t|  0.0027113      \t|6600           \t|  17.895         \t|  1.9044         \t|\n",
      "on_train_batch_end                 \t|  0.002661       \t|6600           \t|  17.563         \t|  1.869          \t|\n",
      "get_validate_batch                 \t|  0.12578        \t|120            \t|  15.094         \t|  1.6063         \t|\n",
      "fetch_next_validate_batch          \t|  0.12571        \t|120            \t|  15.085         \t|  1.6054         \t|\n",
      "on_validation_end                  \t|  0.11717        \t|61             \t|  7.1471         \t|  0.7606         \t|\n",
      "zero_grad                          \t|  0.00059464     \t|6600           \t|  3.9246         \t|  0.41766        \t|\n",
      "evaluation_step_and_end            \t|  0.038161       \t|61             \t|  2.3278         \t|  0.24772        \t|\n",
      "validation_step                    \t|  0.037971       \t|61             \t|  2.3162         \t|  0.24649        \t|\n",
      "on_validation_start                \t|  0.028301       \t|61             \t|  1.7263         \t|  0.18372        \t|\n",
      "on_train_batch_start               \t|  0.00023055     \t|6600           \t|  1.5217         \t|  0.16193        \t|\n",
      "on_train_epoch_start               \t|  0.001871       \t|600            \t|  1.1226         \t|  0.11947        \t|\n",
      "on_train_epoch_end                 \t|  0.00090367     \t|600            \t|  0.5422         \t|  0.057701       \t|\n",
      "training_step_end                  \t|  6.2702e-05     \t|6600           \t|  0.41383        \t|  0.04404        \t|\n",
      "on_batch_start                     \t|  5.0942e-05     \t|6600           \t|  0.33622        \t|  0.03578        \t|\n",
      "on_after_backward                  \t|  3.6571e-05     \t|6600           \t|  0.24137        \t|  0.025686       \t|\n",
      "evaluation_batch_to_device         \t|  0.0035239      \t|61             \t|  0.21496        \t|  0.022876       \t|\n",
      "on_before_zero_grad                \t|  3.2438e-05     \t|6600           \t|  0.21409        \t|  0.022783       \t|\n",
      "on_batch_end                       \t|  3.2294e-05     \t|6600           \t|  0.21314        \t|  0.022682       \t|\n",
      "on_before_optimizer_step           \t|  2.8802e-05     \t|6600           \t|  0.1901         \t|  0.02023        \t|\n",
      "on_before_backward                 \t|  2.8504e-05     \t|6600           \t|  0.18813        \t|  0.02002        \t|\n",
      "get_sanity_check_batch             \t|  0.079043       \t|2              \t|  0.15809        \t|  0.016823       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.078983       \t|2              \t|  0.15797        \t|  0.016811       \t|\n",
      "on_validation_batch_end            \t|  0.0023492      \t|61             \t|  0.1433         \t|  0.01525        \t|\n",
      "on_train_start                     \t|  0.031519       \t|1              \t|  0.031519       \t|  0.0033542      \t|\n",
      "on_sanity_check_start              \t|  0.022322       \t|1              \t|  0.022322       \t|  0.0023755      \t|\n",
      "on_epoch_end                       \t|  3.2754e-05     \t|661            \t|  0.02165        \t|  0.002304       \t|\n",
      "on_epoch_start                     \t|  3.0714e-05     \t|661            \t|  0.020302       \t|  0.0021605      \t|\n",
      "on_validation_model_eval           \t|  0.00019183     \t|61             \t|  0.011702       \t|  0.0012453      \t|\n",
      "on_validation_batch_start          \t|  9.6583e-05     \t|61             \t|  0.0058916      \t|  0.00062698     \t|\n",
      "validation_step_end                \t|  8.2408e-05     \t|61             \t|  0.0050269      \t|  0.00053496     \t|\n",
      "on_validation_epoch_end            \t|  4.2303e-05     \t|61             \t|  0.0025805      \t|  0.00027462     \t|\n",
      "on_pretrain_routine_start          \t|  0.0025489      \t|1              \t|  0.0025489      \t|  0.00027125     \t|\n",
      "on_validation_epoch_start          \t|  3.4275e-05     \t|61             \t|  0.0020908      \t|  0.0002225      \t|\n",
      "on_train_end                       \t|  0.00049913     \t|1              \t|  0.00049913     \t|  5.3118e-05     \t|\n",
      "configure_optimizers               \t|  0.00019328     \t|1              \t|  0.00019328     \t|  2.0569e-05     \t|\n",
      "on_sanity_check_end                \t|  4.6317e-05     \t|1              \t|  4.6317e-05     \t|  4.9291e-06     \t|\n",
      "on_fit_end                         \t|  4.5864e-05     \t|1              \t|  4.5864e-05     \t|  4.8808e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.2117e-05     \t|1              \t|  3.2117e-05     \t|  3.4179e-06     \t|\n",
      "on_fit_start                       \t|  2.8969e-05     \t|1              \t|  2.8969e-05     \t|  3.0829e-06     \t|\n",
      "teardown                           \t|  2.8743e-05     \t|1              \t|  2.8743e-05     \t|  3.0588e-06     \t|\n",
      "on_configure_sharded_model         \t|  1.8342e-05     \t|1              \t|  1.8342e-05     \t|  1.9519e-06     \t|\n",
      "configure_callbacks                \t|  1.6212e-05     \t|1              \t|  1.6212e-05     \t|  1.7253e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4938e-05     \t|1              \t|  1.4938e-05     \t|  1.5897e-06     \t|\n",
      "setup                              \t|  1.4078e-05     \t|1              \t|  1.4078e-05     \t|  1.4982e-06     \t|\n",
      "on_train_dataloader                \t|  8.852e-06      \t|1              \t|  8.852e-06      \t|  9.4203e-07     \t|\n",
      "on_val_dataloader                  \t|  6.5549e-06     \t|1              \t|  6.5549e-06     \t|  6.9757e-07     \t|\n",
      "configure_sharded_model            \t|  5.757e-06      \t|1              \t|  5.757e-06      \t|  6.1266e-07     \t|\n",
      "prepare_data                       \t|  4.17e-06       \t|1              \t|  4.17e-06       \t|  4.4377e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39aa2d1fc3384b1c864a311a97a39aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.3985         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.3431         \t|1              \t|  3.3431         \t|  98.37          \t|\n",
      "evaluation_step_and_end            \t|  0.59786        \t|4              \t|  2.3914         \t|  70.368         \t|\n",
      "test_step                          \t|  0.58196        \t|4              \t|  2.3278         \t|  68.496         \t|\n",
      "get_test_batch                     \t|  0.087343       \t|5              \t|  0.43671        \t|  12.85          \t|\n",
      "fetch_next_test_batch              \t|  0.08729        \t|5              \t|  0.43645        \t|  12.843         \t|\n",
      "on_test_batch_end                  \t|  0.024779       \t|4              \t|  0.099115       \t|  2.9165         \t|\n",
      "test_step_end                      \t|  0.015695       \t|4              \t|  0.062782       \t|  1.8474         \t|\n",
      "evaluation_batch_to_device         \t|  0.014785       \t|4              \t|  0.059139       \t|  1.7402         \t|\n",
      "on_test_start                      \t|  0.020073       \t|1              \t|  0.020073       \t|  0.59066        \t|\n",
      "on_test_end                        \t|  0.001582       \t|1              \t|  0.001582       \t|  0.046551       \t|\n",
      "on_test_batch_start                \t|  8.9244e-05     \t|4              \t|  0.00035698     \t|  0.010504       \t|\n",
      "on_test_model_eval                 \t|  0.00011323     \t|1              \t|  0.00011323     \t|  0.0033318      \t|\n",
      "on_test_epoch_end                  \t|  8.3215e-05     \t|1              \t|  8.3215e-05     \t|  0.0024486      \t|\n",
      "on_epoch_end                       \t|  4.888e-05      \t|1              \t|  4.888e-05      \t|  0.0014383      \t|\n",
      "teardown                           \t|  3.9123e-05     \t|1              \t|  3.9123e-05     \t|  0.0011512      \t|\n",
      "on_epoch_start                     \t|  2.2887e-05     \t|1              \t|  2.2887e-05     \t|  0.00067345     \t|\n",
      "on_configure_sharded_model         \t|  2.0511e-05     \t|1              \t|  2.0511e-05     \t|  0.00060354     \t|\n",
      "on_test_epoch_start                \t|  1.9431e-05     \t|1              \t|  1.9431e-05     \t|  0.00057176     \t|\n",
      "configure_callbacks                \t|  1.4879e-05     \t|1              \t|  1.4879e-05     \t|  0.00043781     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4413e-05     \t|1              \t|  1.4413e-05     \t|  0.00042411     \t|\n",
      "setup                              \t|  1.239e-05      \t|1              \t|  1.239e-05      \t|  0.00036458     \t|\n",
      "on_test_dataloader                 \t|  8.0951e-06     \t|1              \t|  8.0951e-06     \t|  0.0002382      \t|\n",
      "configure_sharded_model            \t|  5.8122e-06     \t|1              \t|  5.8122e-06     \t|  0.00017102     \t|\n",
      "prepare_data                       \t|  4.8061e-06     \t|1              \t|  4.8061e-06     \t|  0.00014142     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2879277765750885,\n",
      " 'test_loss: mae_response': 0.3490711748600006,\n",
      " 'test_loss: mse': 0.3433179259300232}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5227c693335d4dd4a9dd7c8fc7538d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 109: val_loss reached 0.49640 (best 0.49640), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 219: val_loss reached 0.46207 (best 0.46207), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 329: val_loss reached 0.41681 (best 0.41681), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 439: val_loss reached 0.40027 (best 0.40027), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 549: val_loss reached 0.39190 (best 0.39190), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 659: val_loss reached 0.37239 (best 0.37239), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 769: val_loss reached 0.36608 (best 0.36608), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 879: val_loss reached 0.36164 (best 0.36164), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 989: val_loss reached 0.35384 (best 0.35384), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1099: val_loss reached 0.34948 (best 0.34948), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1209: val_loss reached 0.34499 (best 0.34499), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1319: val_loss reached 0.33980 (best 0.33980), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1429: val_loss reached 0.33922 (best 0.33922), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 1539: val_loss reached 0.33589 (best 0.33589), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 1649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 1759: val_loss reached 0.33447 (best 0.33447), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 1869: val_loss reached 0.33262 (best 0.33262), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 1979: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2089: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2199: val_loss reached 0.32899 (best 0.32899), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 2309: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 2419: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 2529: val_loss reached 0.32633 (best 0.32633), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 2639: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 2749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 2859: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 2969: val_loss reached 0.32500 (best 0.32500), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 3079: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 3189: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 3409: val_loss reached 0.32354 (best 0.32354), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 3519: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 3629: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 3739: val_loss reached 0.32192 (best 0.32192), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 3849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 3959: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 4069: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 4179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 4289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 4399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 4509: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 4619: val_loss reached 0.32157 (best 0.32157), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 4729: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 4839: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 5059: val_loss reached 0.32151 (best 0.32151), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 5169: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 5279: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 5389: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 5499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 5609: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 5719: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 5829: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 5939: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 6049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 6159: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 6269: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 6379: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 6489: val_loss reached 0.32052 (best 0.32052), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Parenting']__0.001__deepST_CV_19.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 6599: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  953.68         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.5883         \t|600            \t|  952.97         \t|  99.926         \t|\n",
      "run_training_batch                 \t|  0.082229       \t|6600           \t|  542.71         \t|  56.907         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.048183       \t|6600           \t|  318.01         \t|  33.346         \t|\n",
      "training_step_and_backward         \t|  0.043647       \t|6600           \t|  288.07         \t|  30.206         \t|\n",
      "model_forward                      \t|  0.03348        \t|6600           \t|  220.96         \t|  23.17          \t|\n",
      "training_step                      \t|  0.033228       \t|6600           \t|  219.3          \t|  22.995         \t|\n",
      "get_train_batch                    \t|  0.025934       \t|7200           \t|  186.73         \t|  19.58          \t|\n",
      "fetch_next_train_batch             \t|  0.0259         \t|7200           \t|  186.48         \t|  19.554         \t|\n",
      "backward                           \t|  0.0095181      \t|6600           \t|  62.819         \t|  6.5871         \t|\n",
      "on_train_batch_end                 \t|  0.0027645      \t|6600           \t|  18.245         \t|  1.9132         \t|\n",
      "training_batch_to_device           \t|  0.0027609      \t|6600           \t|  18.222         \t|  1.9107         \t|\n",
      "get_validate_batch                 \t|  0.11271        \t|120            \t|  13.525         \t|  1.4182         \t|\n",
      "fetch_next_validate_batch          \t|  0.11264        \t|120            \t|  13.517         \t|  1.4173         \t|\n",
      "on_validation_end                  \t|  0.097592       \t|61             \t|  5.9531         \t|  0.62423        \t|\n",
      "zero_grad                          \t|  0.00061446     \t|6600           \t|  4.0554         \t|  0.42524        \t|\n",
      "evaluation_step_and_end            \t|  0.038467       \t|61             \t|  2.3465         \t|  0.24604        \t|\n",
      "validation_step                    \t|  0.038291       \t|61             \t|  2.3357         \t|  0.24492        \t|\n",
      "on_train_batch_start               \t|  0.00023493     \t|6600           \t|  1.5505         \t|  0.16258        \t|\n",
      "on_validation_start                \t|  0.022622       \t|61             \t|  1.3799         \t|  0.14469        \t|\n",
      "on_train_epoch_start               \t|  0.0018887      \t|600            \t|  1.1332         \t|  0.11883        \t|\n",
      "on_train_epoch_end                 \t|  0.00092912     \t|600            \t|  0.55747        \t|  0.058455       \t|\n",
      "training_step_end                  \t|  6.4224e-05     \t|6600           \t|  0.42388        \t|  0.044447       \t|\n",
      "on_batch_start                     \t|  5.137e-05      \t|6600           \t|  0.33904        \t|  0.035551       \t|\n",
      "on_after_backward                  \t|  3.7426e-05     \t|6600           \t|  0.24701        \t|  0.025901       \t|\n",
      "evaluation_batch_to_device         \t|  0.003961       \t|61             \t|  0.24162        \t|  0.025335       \t|\n",
      "on_batch_end                       \t|  3.3777e-05     \t|6600           \t|  0.22293        \t|  0.023376       \t|\n",
      "on_before_zero_grad                \t|  3.3544e-05     \t|6600           \t|  0.22139        \t|  0.023215       \t|\n",
      "on_before_backward                 \t|  2.9441e-05     \t|6600           \t|  0.19431        \t|  0.020375       \t|\n",
      "on_before_optimizer_step           \t|  2.9263e-05     \t|6600           \t|  0.19313        \t|  0.020252       \t|\n",
      "get_sanity_check_batch             \t|  0.07021        \t|2              \t|  0.14042        \t|  0.014724       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.070139       \t|2              \t|  0.14028        \t|  0.014709       \t|\n",
      "on_validation_batch_end            \t|  0.0020521      \t|61             \t|  0.12518        \t|  0.013126       \t|\n",
      "on_train_start                     \t|  0.029442       \t|1              \t|  0.029442       \t|  0.0030872      \t|\n",
      "on_sanity_check_start              \t|  0.02291        \t|1              \t|  0.02291        \t|  0.0024023      \t|\n",
      "on_epoch_end                       \t|  3.2959e-05     \t|661            \t|  0.021786       \t|  0.0022844      \t|\n",
      "on_epoch_start                     \t|  3.0364e-05     \t|661            \t|  0.020071       \t|  0.0021046      \t|\n",
      "on_validation_model_eval           \t|  0.00015221     \t|61             \t|  0.0092846      \t|  0.00097356     \t|\n",
      "on_validation_batch_start          \t|  0.00010242     \t|61             \t|  0.0062474      \t|  0.00065509     \t|\n",
      "validation_step_end                \t|  7.4929e-05     \t|61             \t|  0.0045707      \t|  0.00047927     \t|\n",
      "on_pretrain_routine_start          \t|  0.0027715      \t|1              \t|  0.0027715      \t|  0.00029061     \t|\n",
      "on_validation_epoch_end            \t|  3.5576e-05     \t|61             \t|  0.0021701      \t|  0.00022755     \t|\n",
      "on_validation_epoch_start          \t|  2.7707e-05     \t|61             \t|  0.0016901      \t|  0.00017722     \t|\n",
      "on_train_end                       \t|  0.00094256     \t|1              \t|  0.00094256     \t|  9.8834e-05     \t|\n",
      "configure_optimizers               \t|  0.00021349     \t|1              \t|  0.00021349     \t|  2.2386e-05     \t|\n",
      "on_sanity_check_end                \t|  4.6483e-05     \t|1              \t|  4.6483e-05     \t|  4.8741e-06     \t|\n",
      "on_fit_end                         \t|  3.8253e-05     \t|1              \t|  3.8253e-05     \t|  4.0111e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.2845e-05     \t|1              \t|  3.2845e-05     \t|  3.444e-06      \t|\n",
      "on_fit_start                       \t|  3.2329e-05     \t|1              \t|  3.2329e-05     \t|  3.3899e-06     \t|\n",
      "teardown                           \t|  2.9877e-05     \t|1              \t|  2.9877e-05     \t|  3.1328e-06     \t|\n",
      "on_configure_sharded_model         \t|  2.074e-05      \t|1              \t|  2.074e-05      \t|  2.1748e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.547e-05      \t|1              \t|  1.547e-05      \t|  1.6221e-06     \t|\n",
      "configure_callbacks                \t|  1.5356e-05     \t|1              \t|  1.5356e-05     \t|  1.6102e-06     \t|\n",
      "setup                              \t|  1.4717e-05     \t|1              \t|  1.4717e-05     \t|  1.5432e-06     \t|\n",
      "on_train_dataloader                \t|  8.7752e-06     \t|1              \t|  8.7752e-06     \t|  9.2014e-07     \t|\n",
      "on_val_dataloader                  \t|  6.3761e-06     \t|1              \t|  6.3761e-06     \t|  6.6858e-07     \t|\n",
      "configure_sharded_model            \t|  5.645e-06      \t|1              \t|  5.645e-06      \t|  5.9192e-07     \t|\n",
      "prepare_data                       \t|  4.7309e-06     \t|1              \t|  4.7309e-06     \t|  4.9607e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (86902, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc0c220ac6c435d95da4e5b7ffdbdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.2506         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.1943         \t|1              \t|  3.1943         \t|  98.269         \t|\n",
      "evaluation_step_and_end            \t|  0.56505        \t|4              \t|  2.2602         \t|  69.532         \t|\n",
      "test_step                          \t|  0.54931        \t|4              \t|  2.1972         \t|  67.596         \t|\n",
      "get_test_batch                     \t|  0.086204       \t|5              \t|  0.43102        \t|  13.26          \t|\n",
      "fetch_next_test_batch              \t|  0.08615        \t|5              \t|  0.43075        \t|  13.251         \t|\n",
      "evaluation_batch_to_device         \t|  0.020539       \t|4              \t|  0.082156       \t|  2.5274         \t|\n",
      "on_test_batch_end                  \t|  0.018049       \t|4              \t|  0.072196       \t|  2.221          \t|\n",
      "test_step_end                      \t|  0.015566       \t|4              \t|  0.062263       \t|  1.9154         \t|\n",
      "on_test_start                      \t|  0.020188       \t|1              \t|  0.020188       \t|  0.62106        \t|\n",
      "on_test_end                        \t|  0.0020264      \t|1              \t|  0.0020264      \t|  0.062339       \t|\n",
      "on_test_batch_start                \t|  6.8213e-05     \t|4              \t|  0.00027285     \t|  0.0083939      \t|\n",
      "on_test_model_eval                 \t|  0.00010649     \t|1              \t|  0.00010649     \t|  0.003276       \t|\n",
      "on_test_epoch_end                  \t|  6.8659e-05     \t|1              \t|  6.8659e-05     \t|  0.0021122      \t|\n",
      "on_epoch_end                       \t|  3.8907e-05     \t|1              \t|  3.8907e-05     \t|  0.0011969      \t|\n",
      "teardown                           \t|  3.6675e-05     \t|1              \t|  3.6675e-05     \t|  0.0011283      \t|\n",
      "on_epoch_start                     \t|  2.2677e-05     \t|1              \t|  2.2677e-05     \t|  0.00069763     \t|\n",
      "on_configure_sharded_model         \t|  1.9769e-05     \t|1              \t|  1.9769e-05     \t|  0.00060817     \t|\n",
      "on_test_epoch_start                \t|  1.8954e-05     \t|1              \t|  1.8954e-05     \t|  0.00058309     \t|\n",
      "configure_callbacks                \t|  1.5654e-05     \t|1              \t|  1.5654e-05     \t|  0.00048157     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4141e-05     \t|1              \t|  1.4141e-05     \t|  0.00043503     \t|\n",
      "setup                              \t|  1.2662e-05     \t|1              \t|  1.2662e-05     \t|  0.00038953     \t|\n",
      "on_test_dataloader                 \t|  6.5269e-06     \t|1              \t|  6.5269e-06     \t|  0.00020079     \t|\n",
      "configure_sharded_model            \t|  5.1809e-06     \t|1              \t|  5.1809e-06     \t|  0.00015939     \t|\n",
      "prepare_data                       \t|  4.899e-06      \t|1              \t|  4.899e-06      \t|  0.00015071     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.31081610918045044,\n",
      " 'test_loss: mae_response': 0.3787305951118469,\n",
      " 'test_loss: mse': 0.4077070355415344}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ab7a0516e248699b312e70fdab923f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 149: val_loss reached 0.45568 (best 0.45568), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 299: val_loss reached 0.39828 (best 0.39828), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 449: val_loss reached 0.37289 (best 0.37289), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 599: val_loss reached 0.35635 (best 0.35635), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 749: val_loss reached 0.34205 (best 0.34205), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 899: val_loss reached 0.33501 (best 0.33501), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1049: val_loss reached 0.32174 (best 0.32174), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1199: val_loss reached 0.31573 (best 0.31573), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1349: val_loss reached 0.31077 (best 0.31077), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1499: val_loss reached 0.30705 (best 0.30705), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1649: val_loss reached 0.30625 (best 0.30625), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1799: val_loss reached 0.30474 (best 0.30474), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1949: val_loss reached 0.30200 (best 0.30200), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2099: val_loss reached 0.30041 (best 0.30041), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 2249: val_loss reached 0.29905 (best 0.29905), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 2399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 2549: val_loss reached 0.29811 (best 0.29811), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 2699: val_loss reached 0.29709 (best 0.29709), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2999: val_loss reached 0.29544 (best 0.29544), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 3149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 3299: val_loss reached 0.29457 (best 0.29457), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 3449: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 3599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 3749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 3899: val_loss reached 0.29420 (best 0.29420), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 4049: val_loss reached 0.29392 (best 0.29392), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 4199: val_loss reached 0.29366 (best 0.29366), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 4349: val_loss reached 0.29324 (best 0.29324), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 4499: val_loss reached 0.29298 (best 0.29298), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 4649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 4799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 5099: val_loss reached 0.29293 (best 0.29293), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 5249: val_loss reached 0.29245 (best 0.29245), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 5399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 5549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 5699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 5849: val_loss reached 0.29214 (best 0.29214), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 5999: val_loss reached 0.29104 (best 0.29104), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 6149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 6299: val_loss reached 0.29088 (best 0.29088), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 6449: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 6599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 6749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 6899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 7049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 7199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 7349: val_loss reached 0.29076 (best 0.29076), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 7499: val_loss reached 0.28995 (best 0.28995), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 7649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 7799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 7949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 8099: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 8249: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 8399: val_loss reached 0.28994 (best 0.28994), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_20.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 8549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 8699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 8849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 8999: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1180.6         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.9661         \t|600            \t|  1179.7         \t|  99.924         \t|\n",
      "run_training_batch                 \t|  0.081518       \t|9000           \t|  733.66         \t|  62.145         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.047944       \t|9000           \t|  431.5          \t|  36.55          \t|\n",
      "training_step_and_backward         \t|  0.043391       \t|9000           \t|  390.52         \t|  33.079         \t|\n",
      "model_forward                      \t|  0.033164       \t|9000           \t|  298.47         \t|  25.282         \t|\n",
      "training_step                      \t|  0.032912       \t|9000           \t|  296.21         \t|  25.09          \t|\n",
      "get_train_batch                    \t|  0.020603       \t|9600           \t|  197.79         \t|  16.754         \t|\n",
      "fetch_next_train_batch             \t|  0.020571       \t|9600           \t|  197.49         \t|  16.728         \t|\n",
      "backward                           \t|  0.0095697      \t|9000           \t|  86.127         \t|  7.2954         \t|\n",
      "on_train_batch_end                 \t|  0.0027632      \t|9000           \t|  24.868         \t|  2.1065         \t|\n",
      "training_batch_to_device           \t|  0.0027114      \t|9000           \t|  24.403         \t|  2.067          \t|\n",
      "get_validate_batch                 \t|  0.12801        \t|120            \t|  15.361         \t|  1.3012         \t|\n",
      "fetch_next_validate_batch          \t|  0.12794        \t|120            \t|  15.352         \t|  1.3004         \t|\n",
      "on_validation_end                  \t|  0.1365         \t|61             \t|  8.3266         \t|  0.70531        \t|\n",
      "zero_grad                          \t|  0.00062278     \t|9000           \t|  5.605          \t|  0.47477        \t|\n",
      "evaluation_step_and_end            \t|  0.039953       \t|61             \t|  2.4371         \t|  0.20644        \t|\n",
      "validation_step                    \t|  0.039767       \t|61             \t|  2.4258         \t|  0.20548        \t|\n",
      "on_train_batch_start               \t|  0.00022863     \t|9000           \t|  2.0576         \t|  0.17429        \t|\n",
      "on_validation_start                \t|  0.025476       \t|61             \t|  1.554          \t|  0.13164        \t|\n",
      "on_train_epoch_start               \t|  0.0019278      \t|600            \t|  1.1567         \t|  0.097975       \t|\n",
      "training_step_end                  \t|  6.4247e-05     \t|9000           \t|  0.57822        \t|  0.048979       \t|\n",
      "on_train_epoch_end                 \t|  0.00093294     \t|600            \t|  0.55976        \t|  0.047415       \t|\n",
      "on_batch_start                     \t|  4.9369e-05     \t|9000           \t|  0.44432        \t|  0.037637       \t|\n",
      "on_after_backward                  \t|  3.77e-05       \t|9000           \t|  0.3393         \t|  0.028741       \t|\n",
      "on_before_zero_grad                \t|  3.4191e-05     \t|9000           \t|  0.30772        \t|  0.026066       \t|\n",
      "on_batch_end                       \t|  3.4179e-05     \t|9000           \t|  0.30761        \t|  0.026056       \t|\n",
      "get_sanity_check_batch             \t|  0.14376        \t|2              \t|  0.28752        \t|  0.024354       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.14369        \t|2              \t|  0.28738        \t|  0.024343       \t|\n",
      "on_before_backward                 \t|  3.0501e-05     \t|9000           \t|  0.27451        \t|  0.023252       \t|\n",
      "on_before_optimizer_step           \t|  2.9558e-05     \t|9000           \t|  0.26602        \t|  0.022534       \t|\n",
      "evaluation_batch_to_device         \t|  0.00384        \t|61             \t|  0.23424        \t|  0.019841       \t|\n",
      "on_validation_batch_end            \t|  0.0022183      \t|61             \t|  0.13532        \t|  0.011462       \t|\n",
      "on_train_start                     \t|  0.040685       \t|1              \t|  0.040685       \t|  0.0034462      \t|\n",
      "on_sanity_check_start              \t|  0.025931       \t|1              \t|  0.025931       \t|  0.0021965      \t|\n",
      "on_epoch_end                       \t|  3.3714e-05     \t|661            \t|  0.022285       \t|  0.0018877      \t|\n",
      "on_epoch_start                     \t|  3.0887e-05     \t|661            \t|  0.020416       \t|  0.0017294      \t|\n",
      "on_validation_model_eval           \t|  0.00017442     \t|61             \t|  0.010639       \t|  0.00090122     \t|\n",
      "on_validation_batch_start          \t|  9.8081e-05     \t|61             \t|  0.0059829      \t|  0.00050679     \t|\n",
      "validation_step_end                \t|  8.077e-05      \t|61             \t|  0.0049269      \t|  0.00041734     \t|\n",
      "on_pretrain_routine_start          \t|  0.0032085      \t|1              \t|  0.0032085      \t|  0.00027178     \t|\n",
      "on_validation_epoch_end            \t|  4.0207e-05     \t|61             \t|  0.0024526      \t|  0.00020775     \t|\n",
      "on_validation_epoch_start          \t|  2.8762e-05     \t|61             \t|  0.0017545      \t|  0.00014862     \t|\n",
      "on_train_end                       \t|  0.00077234     \t|1              \t|  0.00077234     \t|  6.5421e-05     \t|\n",
      "configure_optimizers               \t|  0.00023595     \t|1              \t|  0.00023595     \t|  1.9987e-05     \t|\n",
      "on_sanity_check_end                \t|  6.3956e-05     \t|1              \t|  6.3956e-05     \t|  5.4174e-06     \t|\n",
      "on_fit_end                         \t|  5.7625e-05     \t|1              \t|  5.7625e-05     \t|  4.8811e-06     \t|\n",
      "on_fit_start                       \t|  3.7886e-05     \t|1              \t|  3.7886e-05     \t|  3.2091e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.6819e-05     \t|1              \t|  3.6819e-05     \t|  3.1188e-06     \t|\n",
      "teardown                           \t|  3.0403e-05     \t|1              \t|  3.0403e-05     \t|  2.5753e-06     \t|\n",
      "configure_callbacks                \t|  2.2574e-05     \t|1              \t|  2.2574e-05     \t|  1.9121e-06     \t|\n",
      "on_configure_sharded_model         \t|  2.2205e-05     \t|1              \t|  2.2205e-05     \t|  1.8809e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.7064e-05     \t|1              \t|  1.7064e-05     \t|  1.4454e-06     \t|\n",
      "setup                              \t|  1.4611e-05     \t|1              \t|  1.4611e-05     \t|  1.2376e-06     \t|\n",
      "on_train_dataloader                \t|  1.1043e-05     \t|1              \t|  1.1043e-05     \t|  9.3542e-07     \t|\n",
      "configure_sharded_model            \t|  6.811e-06      \t|1              \t|  6.811e-06      \t|  5.7693e-07     \t|\n",
      "on_val_dataloader                  \t|  6.6319e-06     \t|1              \t|  6.6319e-06     \t|  5.6176e-07     \t|\n",
      "prepare_data                       \t|  5.1172e-06     \t|1              \t|  5.1172e-06     \t|  4.3345e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa611088c89b470ea0e6c6e36bfb2693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.2781         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.2182         \t|1              \t|  3.2182         \t|  98.173         \t|\n",
      "evaluation_step_and_end            \t|  0.56901        \t|4              \t|  2.2761         \t|  69.432         \t|\n",
      "test_step                          \t|  0.55447        \t|4              \t|  2.2179         \t|  67.657         \t|\n",
      "get_test_batch                     \t|  0.073601       \t|5              \t|  0.368          \t|  11.226         \t|\n",
      "fetch_next_test_batch              \t|  0.073555       \t|5              \t|  0.36778        \t|  11.219         \t|\n",
      "on_test_batch_end                  \t|  0.027448       \t|4              \t|  0.10979        \t|  3.3493         \t|\n",
      "evaluation_batch_to_device         \t|  0.0179         \t|4              \t|  0.071601       \t|  2.1842         \t|\n",
      "test_step_end                      \t|  0.014363       \t|4              \t|  0.057453       \t|  1.7526         \t|\n",
      "on_test_start                      \t|  0.02063        \t|1              \t|  0.02063        \t|  0.62933        \t|\n",
      "on_test_end                        \t|  0.0021799      \t|1              \t|  0.0021799      \t|  0.066499       \t|\n",
      "on_test_batch_start                \t|  6.5022e-05     \t|4              \t|  0.00026009     \t|  0.0079341      \t|\n",
      "on_test_model_eval                 \t|  0.00011069     \t|1              \t|  0.00011069     \t|  0.0033766      \t|\n",
      "on_test_epoch_end                  \t|  9.5297e-05     \t|1              \t|  9.5297e-05     \t|  0.0029071      \t|\n",
      "on_epoch_end                       \t|  5.7822e-05     \t|1              \t|  5.7822e-05     \t|  0.0017639      \t|\n",
      "teardown                           \t|  3.8825e-05     \t|1              \t|  3.8825e-05     \t|  0.0011844      \t|\n",
      "on_epoch_start                     \t|  2.3235e-05     \t|1              \t|  2.3235e-05     \t|  0.00070879     \t|\n",
      "on_configure_sharded_model         \t|  2.0225e-05     \t|1              \t|  2.0225e-05     \t|  0.00061698     \t|\n",
      "on_test_epoch_start                \t|  2.0021e-05     \t|1              \t|  2.0021e-05     \t|  0.00061075     \t|\n",
      "configure_callbacks                \t|  1.6437e-05     \t|1              \t|  1.6437e-05     \t|  0.00050142     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4085e-05     \t|1              \t|  1.4085e-05     \t|  0.00042967     \t|\n",
      "setup                              \t|  1.2235e-05     \t|1              \t|  1.2235e-05     \t|  0.00037324     \t|\n",
      "on_test_dataloader                 \t|  7.3339e-06     \t|1              \t|  7.3339e-06     \t|  0.00022373     \t|\n",
      "configure_sharded_model            \t|  6.052e-06      \t|1              \t|  6.052e-06      \t|  0.00018462     \t|\n",
      "prepare_data                       \t|  5.034e-06      \t|1              \t|  5.034e-06      \t|  0.00015357     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.31761035323143005,\n",
      " 'test_loss: mae_response': 0.38543686270713806,\n",
      " 'test_loss: mse': 0.3876858949661255}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cac953f7e04bc294622d1ea4cd1aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 149: val_loss reached 0.47726 (best 0.47726), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 299: val_loss reached 0.40772 (best 0.40772), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 449: val_loss reached 0.38925 (best 0.38925), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 599: val_loss reached 0.36930 (best 0.36930), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 749: val_loss reached 0.35171 (best 0.35171), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 899: val_loss reached 0.34227 (best 0.34227), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1049: val_loss reached 0.33169 (best 0.33169), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1199: val_loss reached 0.32583 (best 0.32583), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1349: val_loss reached 0.32200 (best 0.32200), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1499: val_loss reached 0.31940 (best 0.31940), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1649: val_loss reached 0.31508 (best 0.31508), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1799: val_loss reached 0.31305 (best 0.31305), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1949: val_loss reached 0.31101 (best 0.31101), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2099: val_loss reached 0.30948 (best 0.30948), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 2249: val_loss reached 0.30808 (best 0.30808), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 2399: val_loss reached 0.30640 (best 0.30640), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 2549: val_loss reached 0.30533 (best 0.30533), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 2699: val_loss reached 0.30492 (best 0.30492), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2849: val_loss reached 0.30483 (best 0.30483), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2999: val_loss reached 0.30385 (best 0.30385), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 3149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 3449: val_loss reached 0.30300 (best 0.30300), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 3599: val_loss reached 0.30224 (best 0.30224), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 3749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 3899: val_loss reached 0.30182 (best 0.30182), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 4049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 4199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 4349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 4499: val_loss reached 0.30144 (best 0.30144), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 4649: val_loss reached 0.30101 (best 0.30101), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 4799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 4949: val_loss reached 0.30092 (best 0.30092), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 5099: val_loss reached 0.30087 (best 0.30087), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 5249: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 5399: val_loss reached 0.30065 (best 0.30065), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 5549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 5699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 5849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 5999: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 6149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 6299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 6449: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 6599: val_loss reached 0.30012 (best 0.30012), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_21.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 6749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 6899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 7049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 7199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 7349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 7499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 7649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 7799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 7949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 8099: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 8249: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 8399: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 8549: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 8699: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 8849: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 8999: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1185.2         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.9737         \t|600            \t|  1184.2         \t|  99.919         \t|\n",
      "run_training_batch                 \t|  0.082171       \t|9000           \t|  739.54         \t|  62.398         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.048151       \t|9000           \t|  433.36         \t|  36.565         \t|\n",
      "training_step_and_backward         \t|  0.043627       \t|9000           \t|  392.65         \t|  33.129         \t|\n",
      "model_forward                      \t|  0.033331       \t|9000           \t|  299.98         \t|  25.31          \t|\n",
      "training_step                      \t|  0.03308        \t|9000           \t|  297.72         \t|  25.12          \t|\n",
      "get_train_batch                    \t|  0.02055        \t|9600           \t|  197.28         \t|  16.645         \t|\n",
      "fetch_next_train_batch             \t|  0.020517       \t|9600           \t|  196.97         \t|  16.619         \t|\n",
      "backward                           \t|  0.0096525      \t|9000           \t|  86.872         \t|  7.3298         \t|\n",
      "on_train_batch_end                 \t|  0.0027968      \t|9000           \t|  25.171         \t|  2.1238         \t|\n",
      "training_batch_to_device           \t|  0.0027095      \t|9000           \t|  24.385         \t|  2.0575         \t|\n",
      "get_validate_batch                 \t|  0.12918        \t|120            \t|  15.502         \t|  1.308          \t|\n",
      "fetch_next_validate_batch          \t|  0.12911        \t|120            \t|  15.493         \t|  1.3072         \t|\n",
      "on_validation_end                  \t|  0.13497        \t|61             \t|  8.2329         \t|  0.69465        \t|\n",
      "zero_grad                          \t|  0.00060962     \t|9000           \t|  5.4865         \t|  0.46293        \t|\n",
      "evaluation_step_and_end            \t|  0.039405       \t|61             \t|  2.4037         \t|  0.20281        \t|\n",
      "validation_step                    \t|  0.039219       \t|61             \t|  2.3924         \t|  0.20186        \t|\n",
      "on_train_batch_start               \t|  0.00022638     \t|9000           \t|  2.0374         \t|  0.1719         \t|\n",
      "on_validation_start                \t|  0.026528       \t|61             \t|  1.6182         \t|  0.13654        \t|\n",
      "on_train_epoch_start               \t|  0.0018874      \t|600            \t|  1.1325         \t|  0.095552       \t|\n",
      "training_step_end                  \t|  6.3554e-05     \t|9000           \t|  0.57198        \t|  0.048261       \t|\n",
      "on_train_epoch_end                 \t|  0.00091188     \t|600            \t|  0.54713        \t|  0.046164       \t|\n",
      "on_batch_start                     \t|  4.9432e-05     \t|9000           \t|  0.44489        \t|  0.037537       \t|\n",
      "on_after_backward                  \t|  3.7057e-05     \t|9000           \t|  0.33351        \t|  0.02814        \t|\n",
      "on_batch_end                       \t|  3.322e-05      \t|9000           \t|  0.29898        \t|  0.025226       \t|\n",
      "on_before_zero_grad                \t|  3.2775e-05     \t|9000           \t|  0.29498        \t|  0.024889       \t|\n",
      "on_before_backward                 \t|  2.9234e-05     \t|9000           \t|  0.26311        \t|  0.022199       \t|\n",
      "on_before_optimizer_step           \t|  2.9058e-05     \t|9000           \t|  0.26152        \t|  0.022066       \t|\n",
      "get_sanity_check_batch             \t|  0.11927        \t|2              \t|  0.23855        \t|  0.020128       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.11921        \t|2              \t|  0.23841        \t|  0.020116       \t|\n",
      "evaluation_batch_to_device         \t|  0.0038476      \t|61             \t|  0.2347         \t|  0.019803       \t|\n",
      "on_validation_batch_end            \t|  0.0022712      \t|61             \t|  0.13854        \t|  0.011689       \t|\n",
      "on_train_start                     \t|  0.039385       \t|1              \t|  0.039385       \t|  0.0033231      \t|\n",
      "on_sanity_check_start              \t|  0.034505       \t|1              \t|  0.034505       \t|  0.0029113      \t|\n",
      "on_epoch_end                       \t|  3.2944e-05     \t|661            \t|  0.021776       \t|  0.0018373      \t|\n",
      "on_epoch_start                     \t|  3.1051e-05     \t|661            \t|  0.020525       \t|  0.0017318      \t|\n",
      "on_validation_model_eval           \t|  0.00018021     \t|61             \t|  0.010993       \t|  0.00092754     \t|\n",
      "on_validation_batch_start          \t|  9.8087e-05     \t|61             \t|  0.0059833      \t|  0.00050484     \t|\n",
      "validation_step_end                \t|  7.8997e-05     \t|61             \t|  0.0048188      \t|  0.00040659     \t|\n",
      "on_pretrain_routine_start          \t|  0.0036874      \t|1              \t|  0.0036874      \t|  0.00031112     \t|\n",
      "on_validation_epoch_end            \t|  4.0529e-05     \t|61             \t|  0.0024723      \t|  0.0002086      \t|\n",
      "on_validation_epoch_start          \t|  2.9992e-05     \t|61             \t|  0.0018295      \t|  0.00015436     \t|\n",
      "on_train_end                       \t|  0.00050029     \t|1              \t|  0.00050029     \t|  4.2212e-05     \t|\n",
      "configure_optimizers               \t|  0.00034009     \t|1              \t|  0.00034009     \t|  2.8695e-05     \t|\n",
      "on_sanity_check_end                \t|  5.9117e-05     \t|1              \t|  5.9117e-05     \t|  4.988e-06      \t|\n",
      "on_fit_start                       \t|  5.0346e-05     \t|1              \t|  5.0346e-05     \t|  4.2479e-06     \t|\n",
      "on_pretrain_routine_end            \t|  4.9206e-05     \t|1              \t|  4.9206e-05     \t|  4.1518e-06     \t|\n",
      "on_fit_end                         \t|  4.7316e-05     \t|1              \t|  4.7316e-05     \t|  3.9923e-06     \t|\n",
      "on_configure_sharded_model         \t|  3.38e-05       \t|1              \t|  3.38e-05       \t|  2.8518e-06     \t|\n",
      "teardown                           \t|  3.122e-05      \t|1              \t|  3.122e-05      \t|  2.6342e-06     \t|\n",
      "configure_callbacks                \t|  2.7057e-05     \t|1              \t|  2.7057e-05     \t|  2.2829e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  2.3532e-05     \t|1              \t|  2.3532e-05     \t|  1.9855e-06     \t|\n",
      "setup                              \t|  2.2893e-05     \t|1              \t|  2.2893e-05     \t|  1.9316e-06     \t|\n",
      "on_train_dataloader                \t|  9.445e-06      \t|1              \t|  9.445e-06      \t|  7.9692e-07     \t|\n",
      "configure_sharded_model            \t|  9.4441e-06     \t|1              \t|  9.4441e-06     \t|  7.9684e-07     \t|\n",
      "on_val_dataloader                  \t|  9.031e-06      \t|1              \t|  9.031e-06      \t|  7.6199e-07     \t|\n",
      "prepare_data                       \t|  8.5821e-06     \t|1              \t|  8.5821e-06     \t|  7.2412e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a1d174b57e43c4aae9055d97ddb2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.2836         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.2216         \t|1              \t|  3.2216         \t|  98.113         \t|\n",
      "evaluation_step_and_end            \t|  0.57185        \t|4              \t|  2.2874         \t|  69.663         \t|\n",
      "test_step                          \t|  0.55608        \t|4              \t|  2.2243         \t|  67.741         \t|\n",
      "get_test_batch                     \t|  0.080811       \t|5              \t|  0.40405        \t|  12.305         \t|\n",
      "fetch_next_test_batch              \t|  0.080763       \t|5              \t|  0.40381        \t|  12.298         \t|\n",
      "on_test_batch_end                  \t|  0.024385       \t|4              \t|  0.097539       \t|  2.9705         \t|\n",
      "evaluation_batch_to_device         \t|  0.016738       \t|4              \t|  0.066951       \t|  2.039          \t|\n",
      "test_step_end                      \t|  0.0156         \t|4              \t|  0.062398       \t|  1.9003         \t|\n",
      "on_test_start                      \t|  0.020426       \t|1              \t|  0.020426       \t|  0.62207        \t|\n",
      "on_test_end                        \t|  0.002338       \t|1              \t|  0.002338       \t|  0.071205       \t|\n",
      "on_test_batch_start                \t|  7.0325e-05     \t|4              \t|  0.0002813      \t|  0.008567       \t|\n",
      "on_test_model_eval                 \t|  0.00011184     \t|1              \t|  0.00011184     \t|  0.0034062      \t|\n",
      "on_test_epoch_end                  \t|  7.2584e-05     \t|1              \t|  7.2584e-05     \t|  0.0022105      \t|\n",
      "on_epoch_end                       \t|  4.5356e-05     \t|1              \t|  4.5356e-05     \t|  0.0013813      \t|\n",
      "on_epoch_start                     \t|  3.9454e-05     \t|1              \t|  3.9454e-05     \t|  0.0012016      \t|\n",
      "teardown                           \t|  3.559e-05      \t|1              \t|  3.559e-05      \t|  0.0010839      \t|\n",
      "on_test_epoch_start                \t|  3.5022e-05     \t|1              \t|  3.5022e-05     \t|  0.0010666      \t|\n",
      "on_configure_sharded_model         \t|  2.708e-05      \t|1              \t|  2.708e-05      \t|  0.00082471     \t|\n",
      "on_before_accelerator_backend_setup\t|  2.3228e-05     \t|1              \t|  2.3228e-05     \t|  0.00070741     \t|\n",
      "setup                              \t|  2.0251e-05     \t|1              \t|  2.0251e-05     \t|  0.00061674     \t|\n",
      "configure_callbacks                \t|  1.9343e-05     \t|1              \t|  1.9343e-05     \t|  0.00058908     \t|\n",
      "prepare_data                       \t|  8.5859e-06     \t|1              \t|  8.5859e-06     \t|  0.00026148     \t|\n",
      "configure_sharded_model            \t|  7.648e-06      \t|1              \t|  7.648e-06      \t|  0.00023292     \t|\n",
      "on_test_dataloader                 \t|  7.642e-06      \t|1              \t|  7.642e-06      \t|  0.00023273     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.32831496000289917,\n",
      " 'test_loss: mae_response': 0.3994031846523285,\n",
      " 'test_loss: mse': 0.4112792909145355}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cd9324ebad4662811b78b10bb0bdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 149: val_loss reached 0.46486 (best 0.46486), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 299: val_loss reached 0.41282 (best 0.41282), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 449: val_loss reached 0.37412 (best 0.37412), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 599: val_loss reached 0.35222 (best 0.35222), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 749: val_loss reached 0.34748 (best 0.34748), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 899: val_loss reached 0.32552 (best 0.32552), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1049: val_loss reached 0.31762 (best 0.31762), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1199: val_loss reached 0.31106 (best 0.31106), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1349: val_loss reached 0.30401 (best 0.30401), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1499: val_loss reached 0.30212 (best 0.30212), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1649: val_loss reached 0.29675 (best 0.29675), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1799: val_loss reached 0.29396 (best 0.29396), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2099: val_loss reached 0.29212 (best 0.29212), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 2249: val_loss reached 0.28926 (best 0.28926), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 2399: val_loss reached 0.28800 (best 0.28800), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 2549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 2699: val_loss reached 0.28571 (best 0.28571), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2849: val_loss reached 0.28486 (best 0.28486), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2999: val_loss reached 0.28435 (best 0.28435), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 3149: val_loss reached 0.28376 (best 0.28376), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 3449: val_loss reached 0.28184 (best 0.28184), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 3599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 3749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 3899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 4049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 4199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 4349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 4499: val_loss reached 0.28099 (best 0.28099), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 4649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 4799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 5099: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 5249: val_loss reached 0.28074 (best 0.28074), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 5399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 5549: val_loss reached 0.27968 (best 0.27968), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 5699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 5849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 5999: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 6149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 6299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 6449: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 6599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 6749: val_loss reached 0.27903 (best 0.27903), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 6899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 7049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 7199: val_loss reached 0.27894 (best 0.27894), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_22.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 7349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 7499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 7649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 7799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 7949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 8099: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 8249: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 8399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 8549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 8699: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 8849: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 8999: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1161.4         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1.9343         \t|600            \t|  1160.6         \t|  99.927         \t|\n",
      "run_training_batch                 \t|  0.080924       \t|9000           \t|  728.32         \t|  62.709         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.04727        \t|9000           \t|  425.43         \t|  36.63          \t|\n",
      "training_step_and_backward         \t|  0.042932       \t|9000           \t|  386.39         \t|  33.269         \t|\n",
      "model_forward                      \t|  0.03256        \t|9000           \t|  293.04         \t|  25.231         \t|\n",
      "training_step                      \t|  0.032327       \t|9000           \t|  290.95         \t|  25.051         \t|\n",
      "get_train_batch                    \t|  0.020045       \t|9600           \t|  192.43         \t|  16.568         \t|\n",
      "fetch_next_train_batch             \t|  0.020014       \t|9600           \t|  192.13         \t|  16.543         \t|\n",
      "backward                           \t|  0.0097691      \t|9000           \t|  87.922         \t|  7.5702         \t|\n",
      "training_batch_to_device           \t|  0.0026456      \t|9000           \t|  23.81          \t|  2.0501         \t|\n",
      "on_train_batch_end                 \t|  0.0025892      \t|9000           \t|  23.303         \t|  2.0064         \t|\n",
      "get_validate_batch                 \t|  0.11984        \t|120            \t|  14.38          \t|  1.2382         \t|\n",
      "fetch_next_validate_batch          \t|  0.11976        \t|120            \t|  14.372         \t|  1.2374         \t|\n",
      "on_validation_end                  \t|  0.11762        \t|61             \t|  7.1747         \t|  0.61775        \t|\n",
      "zero_grad                          \t|  0.00057144     \t|9000           \t|  5.1429         \t|  0.44282        \t|\n",
      "evaluation_step_and_end            \t|  0.038074       \t|61             \t|  2.3225         \t|  0.19997        \t|\n",
      "validation_step                    \t|  0.037895       \t|61             \t|  2.3116         \t|  0.19903        \t|\n",
      "on_train_batch_start               \t|  0.00020808     \t|9000           \t|  1.8727         \t|  0.16124        \t|\n",
      "on_validation_start                \t|  0.023474       \t|61             \t|  1.4319         \t|  0.12329        \t|\n",
      "on_train_epoch_start               \t|  0.0016933      \t|600            \t|  1.016          \t|  0.08748        \t|\n",
      "training_step_end                  \t|  5.9858e-05     \t|9000           \t|  0.53872        \t|  0.046385       \t|\n",
      "on_train_epoch_end                 \t|  0.00085821     \t|600            \t|  0.51493        \t|  0.044336       \t|\n",
      "on_batch_start                     \t|  4.5157e-05     \t|9000           \t|  0.40641        \t|  0.034993       \t|\n",
      "on_after_backward                  \t|  3.4224e-05     \t|9000           \t|  0.30802        \t|  0.026521       \t|\n",
      "on_before_zero_grad                \t|  3.0316e-05     \t|9000           \t|  0.27284        \t|  0.023492       \t|\n",
      "on_batch_end                       \t|  3.0259e-05     \t|9000           \t|  0.27233        \t|  0.023448       \t|\n",
      "evaluation_batch_to_device         \t|  0.0040582      \t|61             \t|  0.24755        \t|  0.021315       \t|\n",
      "on_before_backward                 \t|  2.6848e-05     \t|9000           \t|  0.24163        \t|  0.020805       \t|\n",
      "on_before_optimizer_step           \t|  2.6814e-05     \t|9000           \t|  0.24133        \t|  0.020779       \t|\n",
      "get_sanity_check_batch             \t|  0.092968       \t|2              \t|  0.18594        \t|  0.016009       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.09291        \t|2              \t|  0.18582        \t|  0.015999       \t|\n",
      "on_validation_batch_end            \t|  0.0021219      \t|61             \t|  0.12943        \t|  0.011144       \t|\n",
      "on_train_start                     \t|  0.029232       \t|1              \t|  0.029232       \t|  0.0025169      \t|\n",
      "on_sanity_check_start              \t|  0.021332       \t|1              \t|  0.021332       \t|  0.0018368      \t|\n",
      "on_epoch_end                       \t|  3.0361e-05     \t|661            \t|  0.020069       \t|  0.0017279      \t|\n",
      "on_epoch_start                     \t|  2.774e-05      \t|661            \t|  0.018336       \t|  0.0015788      \t|\n",
      "on_validation_model_eval           \t|  0.00016718     \t|61             \t|  0.010198       \t|  0.00087805     \t|\n",
      "on_validation_batch_start          \t|  0.00010742     \t|61             \t|  0.0065528      \t|  0.00056421     \t|\n",
      "validation_step_end                \t|  7.5128e-05     \t|61             \t|  0.0045828      \t|  0.00039459     \t|\n",
      "on_pretrain_routine_start          \t|  0.0025665      \t|1              \t|  0.0025665      \t|  0.00022098     \t|\n",
      "on_validation_epoch_end            \t|  3.7463e-05     \t|61             \t|  0.0022852      \t|  0.00019676     \t|\n",
      "on_validation_epoch_start          \t|  2.5792e-05     \t|61             \t|  0.0015733      \t|  0.00013547     \t|\n",
      "on_train_end                       \t|  0.0014824      \t|1              \t|  0.0014824      \t|  0.00012764     \t|\n",
      "configure_optimizers               \t|  0.00020712     \t|1              \t|  0.00020712     \t|  1.7833e-05     \t|\n",
      "on_fit_end                         \t|  7.5618e-05     \t|1              \t|  7.5618e-05     \t|  6.5108e-06     \t|\n",
      "teardown                           \t|  5.593e-05      \t|1              \t|  5.593e-05      \t|  4.8157e-06     \t|\n",
      "on_sanity_check_end                \t|  4.6803e-05     \t|1              \t|  4.6803e-05     \t|  4.0298e-06     \t|\n",
      "on_fit_start                       \t|  3.1948e-05     \t|1              \t|  3.1948e-05     \t|  2.7508e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.0442e-05     \t|1              \t|  3.0442e-05     \t|  2.6211e-06     \t|\n",
      "on_configure_sharded_model         \t|  2.162e-05      \t|1              \t|  2.162e-05      \t|  1.8615e-06     \t|\n",
      "configure_callbacks                \t|  1.5385e-05     \t|1              \t|  1.5385e-05     \t|  1.3247e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4668e-05     \t|1              \t|  1.4668e-05     \t|  1.2629e-06     \t|\n",
      "setup                              \t|  1.2902e-05     \t|1              \t|  1.2902e-05     \t|  1.1109e-06     \t|\n",
      "on_train_dataloader                \t|  9.2541e-06     \t|1              \t|  9.2541e-06     \t|  7.9679e-07     \t|\n",
      "configure_sharded_model            \t|  6.4399e-06     \t|1              \t|  6.4399e-06     \t|  5.5448e-07     \t|\n",
      "on_val_dataloader                  \t|  5.6538e-06     \t|1              \t|  5.6538e-06     \t|  4.868e-07      \t|\n",
      "prepare_data                       \t|  4.4971e-06     \t|1              \t|  4.4971e-06     \t|  3.8721e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2106bf64475f4669bab434cb3008c20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.5145         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.4426         \t|1              \t|  3.4426         \t|  97.955         \t|\n",
      "evaluation_step_and_end            \t|  0.58447        \t|4              \t|  2.3379         \t|  66.52          \t|\n",
      "test_step                          \t|  0.56989        \t|4              \t|  2.2796         \t|  64.862         \t|\n",
      "get_test_batch                     \t|  0.090806       \t|5              \t|  0.45403        \t|  12.919         \t|\n",
      "fetch_next_test_batch              \t|  0.090745       \t|5              \t|  0.45372        \t|  12.91          \t|\n",
      "on_test_batch_end                  \t|  0.026457       \t|4              \t|  0.10583        \t|  3.0112         \t|\n",
      "test_step_end                      \t|  0.014336       \t|4              \t|  0.057343       \t|  1.6316         \t|\n",
      "evaluation_batch_to_device         \t|  0.014164       \t|4              \t|  0.056655       \t|  1.612          \t|\n",
      "on_test_start                      \t|  0.035644       \t|1              \t|  0.035644       \t|  1.0142         \t|\n",
      "on_test_end                        \t|  0.0022072      \t|1              \t|  0.0022072      \t|  0.062802       \t|\n",
      "on_test_batch_start                \t|  7.0357e-05     \t|4              \t|  0.00028143     \t|  0.0080076      \t|\n",
      "on_test_model_eval                 \t|  0.00026648     \t|1              \t|  0.00026648     \t|  0.0075824      \t|\n",
      "on_test_epoch_end                  \t|  9.0635e-05     \t|1              \t|  9.0635e-05     \t|  0.0025789      \t|\n",
      "on_epoch_end                       \t|  5.318e-05      \t|1              \t|  5.318e-05      \t|  0.0015132      \t|\n",
      "on_epoch_start                     \t|  4.3557e-05     \t|1              \t|  4.3557e-05     \t|  0.0012393      \t|\n",
      "on_test_epoch_start                \t|  3.6776e-05     \t|1              \t|  3.6776e-05     \t|  0.0010464      \t|\n",
      "teardown                           \t|  3.5819e-05     \t|1              \t|  3.5819e-05     \t|  0.0010192      \t|\n",
      "on_configure_sharded_model         \t|  3.256e-05      \t|1              \t|  3.256e-05      \t|  0.00092645     \t|\n",
      "on_before_accelerator_backend_setup\t|  2.4724e-05     \t|1              \t|  2.4724e-05     \t|  0.00070348     \t|\n",
      "configure_callbacks                \t|  2.1614e-05     \t|1              \t|  2.1614e-05     \t|  0.00061499     \t|\n",
      "setup                              \t|  2.1494e-05     \t|1              \t|  2.1494e-05     \t|  0.00061158     \t|\n",
      "on_test_dataloader                 \t|  1.3101e-05     \t|1              \t|  1.3101e-05     \t|  0.00037277     \t|\n",
      "configure_sharded_model            \t|  8.875e-06      \t|1              \t|  8.875e-06      \t|  0.00025253     \t|\n",
      "prepare_data                       \t|  8.689e-06      \t|1              \t|  8.689e-06      \t|  0.00024723     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.3097085952758789,\n",
      " 'test_loss: mae_response': 0.37777724862098694,\n",
      " 'test_loss: mse': 0.3737935721874237}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916e23313eb64f428e3d05b107130854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 149: val_loss reached 0.46741 (best 0.46741), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 299: val_loss reached 0.44528 (best 0.44528), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 449: val_loss reached 0.41246 (best 0.41246), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 599: val_loss reached 0.37919 (best 0.37919), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 749: val_loss reached 0.36784 (best 0.36784), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 899: val_loss reached 0.36539 (best 0.36539), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1049: val_loss reached 0.34537 (best 0.34537), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1199: val_loss reached 0.33870 (best 0.33870), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1499: val_loss reached 0.33190 (best 0.33190), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1799: val_loss reached 0.32821 (best 0.32821), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1949: val_loss reached 0.32374 (best 0.32374), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2099: val_loss reached 0.32323 (best 0.32323), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 2249: val_loss reached 0.32154 (best 0.32154), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 2399: val_loss reached 0.31932 (best 0.31932), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 2549: val_loss reached 0.31926 (best 0.31926), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 2699: val_loss reached 0.31898 (best 0.31898), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2849: val_loss reached 0.31817 (best 0.31817), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2999: val_loss reached 0.31664 (best 0.31664), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 3149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 3449: val_loss reached 0.31652 (best 0.31652), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 3599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 3749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 3899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 4049: val_loss reached 0.31497 (best 0.31497), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 4199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 4349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 4499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 4649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 4799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 4949: val_loss reached 0.31407 (best 0.31407), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 5099: val_loss reached 0.31403 (best 0.31403), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 5249: val_loss reached 0.31393 (best 0.31393), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 5399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 5549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 5699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 5849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 5999: val_loss reached 0.31353 (best 0.31353), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 6149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 6299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 6449: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 6599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 6749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 6899: val_loss reached 0.31339 (best 0.31339), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 7049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 7199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 7349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 7499: val_loss reached 0.31322 (best 0.31322), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 7649: val_loss reached 0.31315 (best 0.31315), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 7799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 7949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 8099: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 8249: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 8399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 8549: val_loss reached 0.31256 (best 0.31256), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_23.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 8699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 8849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 8999: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1202.1         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.002          \t|600            \t|  1201.2         \t|  99.93          \t|\n",
      "run_training_batch                 \t|  0.082256       \t|9000           \t|  740.3          \t|  61.586         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.049076       \t|9000           \t|  441.69         \t|  36.744         \t|\n",
      "training_step_and_backward         \t|  0.044325       \t|9000           \t|  398.92         \t|  33.186         \t|\n",
      "model_forward                      \t|  0.033831       \t|9000           \t|  304.48         \t|  25.33          \t|\n",
      "training_step                      \t|  0.033566       \t|9000           \t|  302.09         \t|  25.131         \t|\n",
      "get_train_batch                    \t|  0.021077       \t|9600           \t|  202.34         \t|  16.833         \t|\n",
      "fetch_next_train_batch             \t|  0.021044       \t|9600           \t|  202.02         \t|  16.806         \t|\n",
      "backward                           \t|  0.009812       \t|9000           \t|  88.308         \t|  7.3464         \t|\n",
      "on_train_batch_end                 \t|  0.0029213      \t|9000           \t|  26.292         \t|  2.1872         \t|\n",
      "training_batch_to_device           \t|  0.0027937      \t|9000           \t|  25.144         \t|  2.0917         \t|\n",
      "get_validate_batch                 \t|  0.12928        \t|120            \t|  15.513         \t|  1.2906         \t|\n",
      "fetch_next_validate_batch          \t|  0.12921        \t|120            \t|  15.505         \t|  1.2898         \t|\n",
      "on_validation_end                  \t|  0.14212        \t|61             \t|  8.6694         \t|  0.72121        \t|\n",
      "zero_grad                          \t|  0.00064437     \t|9000           \t|  5.7993         \t|  0.48245        \t|\n",
      "evaluation_step_and_end            \t|  0.039843       \t|61             \t|  2.4304         \t|  0.20218        \t|\n",
      "validation_step                    \t|  0.039646       \t|61             \t|  2.4184         \t|  0.20119        \t|\n",
      "on_train_batch_start               \t|  0.00022889     \t|9000           \t|  2.06           \t|  0.17137        \t|\n",
      "on_validation_start                \t|  0.026828       \t|61             \t|  1.6365         \t|  0.13614        \t|\n",
      "on_train_epoch_start               \t|  0.0020089      \t|600            \t|  1.2054         \t|  0.10027        \t|\n",
      "training_step_end                  \t|  6.6894e-05     \t|9000           \t|  0.60205        \t|  0.050084       \t|\n",
      "on_train_epoch_end                 \t|  0.00099728     \t|600            \t|  0.59837        \t|  0.049778       \t|\n",
      "on_batch_start                     \t|  5.2614e-05     \t|9000           \t|  0.47352        \t|  0.039392       \t|\n",
      "on_after_backward                  \t|  4.1915e-05     \t|9000           \t|  0.37723        \t|  0.031382       \t|\n",
      "on_batch_end                       \t|  3.5593e-05     \t|9000           \t|  0.32033        \t|  0.026648       \t|\n",
      "on_before_zero_grad                \t|  3.4717e-05     \t|9000           \t|  0.31246        \t|  0.025993       \t|\n",
      "on_before_backward                 \t|  3.0323e-05     \t|9000           \t|  0.27291        \t|  0.022703       \t|\n",
      "on_before_optimizer_step           \t|  3.0202e-05     \t|9000           \t|  0.27182        \t|  0.022613       \t|\n",
      "evaluation_batch_to_device         \t|  0.0037265      \t|61             \t|  0.22731        \t|  0.01891        \t|\n",
      "get_sanity_check_batch             \t|  0.10233        \t|2              \t|  0.20467        \t|  0.017026       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.10226        \t|2              \t|  0.20451        \t|  0.017013       \t|\n",
      "on_validation_batch_end            \t|  0.0023291      \t|61             \t|  0.14208        \t|  0.011819       \t|\n",
      "on_train_start                     \t|  0.038492       \t|1              \t|  0.038492       \t|  0.0032021      \t|\n",
      "on_epoch_end                       \t|  3.4834e-05     \t|661            \t|  0.023025       \t|  0.0019155      \t|\n",
      "on_epoch_start                     \t|  3.1858e-05     \t|661            \t|  0.021058       \t|  0.0017518      \t|\n",
      "on_sanity_check_start              \t|  0.020342       \t|1              \t|  0.020342       \t|  0.0016923      \t|\n",
      "on_validation_model_eval           \t|  0.00018914     \t|61             \t|  0.011538       \t|  0.00095982     \t|\n",
      "on_validation_batch_start          \t|  0.00010773     \t|61             \t|  0.0065716      \t|  0.00054669     \t|\n",
      "validation_step_end                \t|  8.4183e-05     \t|61             \t|  0.0051352      \t|  0.00042719     \t|\n",
      "on_pretrain_routine_start          \t|  0.0027716      \t|1              \t|  0.0027716      \t|  0.00023057     \t|\n",
      "on_validation_epoch_end            \t|  4.1882e-05     \t|61             \t|  0.0025548      \t|  0.00021253     \t|\n",
      "on_validation_epoch_start          \t|  2.9969e-05     \t|61             \t|  0.0018281      \t|  0.00015208     \t|\n",
      "on_train_end                       \t|  0.00064011     \t|1              \t|  0.00064011     \t|  5.3251e-05     \t|\n",
      "configure_optimizers               \t|  0.00022392     \t|1              \t|  0.00022392     \t|  1.8628e-05     \t|\n",
      "on_sanity_check_end                \t|  6.5698e-05     \t|1              \t|  6.5698e-05     \t|  5.4654e-06     \t|\n",
      "on_fit_end                         \t|  5.4358e-05     \t|1              \t|  5.4358e-05     \t|  4.522e-06      \t|\n",
      "on_fit_start                       \t|  3.6716e-05     \t|1              \t|  3.6716e-05     \t|  3.0544e-06     \t|\n",
      "teardown                           \t|  3.4966e-05     \t|1              \t|  3.4966e-05     \t|  2.9088e-06     \t|\n",
      "on_pretrain_routine_end            \t|  2.9387e-05     \t|1              \t|  2.9387e-05     \t|  2.4447e-06     \t|\n",
      "on_configure_sharded_model         \t|  1.9987e-05     \t|1              \t|  1.9987e-05     \t|  1.6627e-06     \t|\n",
      "configure_callbacks                \t|  1.9149e-05     \t|1              \t|  1.9149e-05     \t|  1.593e-06      \t|\n",
      "setup                              \t|  1.6002e-05     \t|1              \t|  1.6002e-05     \t|  1.3312e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.5685e-05     \t|1              \t|  1.5685e-05     \t|  1.3048e-06     \t|\n",
      "on_train_dataloader                \t|  1.0194e-05     \t|1              \t|  1.0194e-05     \t|  8.4804e-07     \t|\n",
      "on_val_dataloader                  \t|  6.1991e-06     \t|1              \t|  6.1991e-06     \t|  5.157e-07      \t|\n",
      "configure_sharded_model            \t|  5.512e-06      \t|1              \t|  5.512e-06      \t|  4.5855e-07     \t|\n",
      "prepare_data                       \t|  4.4948e-06     \t|1              \t|  4.4948e-06     \t|  3.7392e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2181b5ab3f314acdb0756f9a68c31058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.6691         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.6089         \t|1              \t|  3.6089         \t|  98.359         \t|\n",
      "evaluation_step_and_end            \t|  0.60194        \t|4              \t|  2.4078         \t|  65.623         \t|\n",
      "test_step                          \t|  0.58617        \t|4              \t|  2.3447         \t|  63.903         \t|\n",
      "get_test_batch                     \t|  0.10236        \t|5              \t|  0.51181        \t|  13.949         \t|\n",
      "fetch_next_test_batch              \t|  0.1023         \t|5              \t|  0.51152        \t|  13.941         \t|\n",
      "on_test_batch_end                  \t|  0.020889       \t|4              \t|  0.083558       \t|  2.2773         \t|\n",
      "evaluation_batch_to_device         \t|  0.015648       \t|4              \t|  0.062591       \t|  1.7059         \t|\n",
      "test_step_end                      \t|  0.015601       \t|4              \t|  0.062405       \t|  1.7008         \t|\n",
      "on_test_start                      \t|  0.020095       \t|1              \t|  0.020095       \t|  0.54769        \t|\n",
      "on_test_end                        \t|  0.0019182      \t|1              \t|  0.0019182      \t|  0.052279       \t|\n",
      "on_test_batch_start                \t|  7.1653e-05     \t|4              \t|  0.00028661     \t|  0.0078115      \t|\n",
      "on_test_epoch_end                  \t|  0.0001526      \t|1              \t|  0.0001526      \t|  0.0041591      \t|\n",
      "teardown                           \t|  0.00013802     \t|1              \t|  0.00013802     \t|  0.0037617      \t|\n",
      "on_test_model_eval                 \t|  0.00010243     \t|1              \t|  0.00010243     \t|  0.0027917      \t|\n",
      "on_epoch_end                       \t|  8.8265e-05     \t|1              \t|  8.8265e-05     \t|  0.0024056      \t|\n",
      "on_epoch_start                     \t|  2.1921e-05     \t|1              \t|  2.1921e-05     \t|  0.00059745     \t|\n",
      "on_configure_sharded_model         \t|  2.1678e-05     \t|1              \t|  2.1678e-05     \t|  0.00059083     \t|\n",
      "on_test_epoch_start                \t|  2.019e-05      \t|1              \t|  2.019e-05      \t|  0.00055027     \t|\n",
      "configure_callbacks                \t|  1.7012e-05     \t|1              \t|  1.7012e-05     \t|  0.00046366     \t|\n",
      "setup                              \t|  1.4997e-05     \t|1              \t|  1.4997e-05     \t|  0.00040874     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4132e-05     \t|1              \t|  1.4132e-05     \t|  0.00038517     \t|\n",
      "configure_sharded_model            \t|  6.4399e-06     \t|1              \t|  6.4399e-06     \t|  0.00017552     \t|\n",
      "on_test_dataloader                 \t|  6.285e-06      \t|1              \t|  6.285e-06      \t|  0.0001713      \t|\n",
      "prepare_data                       \t|  4.4769e-06     \t|1              \t|  4.4769e-06     \t|  0.00012202     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2865702509880066,\n",
      " 'test_loss: mae_response': 0.34914833307266235,\n",
      " 'test_loss: mse': 0.34408140182495117}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeb027d43b34794841e2954bfb77edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 149: val_loss reached 0.59571 (best 0.59571), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 299: val_loss reached 0.48928 (best 0.48928), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 449: val_loss reached 0.43938 (best 0.43938), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 599: val_loss reached 0.43400 (best 0.43400), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 749: val_loss reached 0.39878 (best 0.39878), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 899: val_loss reached 0.38444 (best 0.38444), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1049: val_loss reached 0.37657 (best 0.37657), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1199: val_loss reached 0.37041 (best 0.37041), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1349: val_loss reached 0.36360 (best 0.36360), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 1499: val_loss reached 0.35903 (best 0.35903), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 1649: val_loss reached 0.35603 (best 0.35603), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 1799: val_loss reached 0.35222 (best 0.35222), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 1949: val_loss reached 0.34954 (best 0.34954), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2099: val_loss reached 0.34834 (best 0.34834), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 2249: val_loss reached 0.34790 (best 0.34790), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 2399: val_loss reached 0.34463 (best 0.34463), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 2549: val_loss reached 0.34145 (best 0.34145), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 2699: val_loss reached 0.33999 (best 0.33999), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 2849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 2999: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 3149: val_loss reached 0.33921 (best 0.33921), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 3299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 3449: val_loss reached 0.33815 (best 0.33815), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 3599: val_loss reached 0.33760 (best 0.33760), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 3749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 3899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 4049: val_loss reached 0.33708 (best 0.33708), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 4199: val_loss reached 0.33627 (best 0.33627), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 4349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 4499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 4649: val_loss reached 0.33565 (best 0.33565), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 4799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 4949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 5099: val_loss reached 0.33511 (best 0.33511), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 5249: val_loss reached 0.33509 (best 0.33509), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 5399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 5549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 5699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 5849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 5999: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 6149: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 6299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 6449: val_loss reached 0.33464 (best 0.33464), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 6599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 6749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 6899: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 7049: val_loss reached 0.33408 (best 0.33408), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 7199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 7349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 7499: val_loss reached 0.33396 (best 0.33396), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 7649: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 7799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 7949: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 8099: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 8249: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 8399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 8549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 8699: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 8849: val_loss reached 0.33375 (best 0.33375), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Virgin Parenting']__0.001__deepST_CV_24.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 8999: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1201.9         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.0018         \t|600            \t|  1201.1         \t|  99.931         \t|\n",
      "run_training_batch                 \t|  0.082506       \t|9000           \t|  742.55         \t|  61.782         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.048878       \t|9000           \t|  439.9          \t|  36.601         \t|\n",
      "training_step_and_backward         \t|  0.044198       \t|9000           \t|  397.78         \t|  33.096         \t|\n",
      "model_forward                      \t|  0.033801       \t|9000           \t|  304.21         \t|  25.31          \t|\n",
      "training_step                      \t|  0.033538       \t|9000           \t|  301.85         \t|  25.114         \t|\n",
      "get_train_batch                    \t|  0.020947       \t|9600           \t|  201.09         \t|  16.731         \t|\n",
      "fetch_next_train_batch             \t|  0.020914       \t|9600           \t|  200.77         \t|  16.705         \t|\n",
      "backward                           \t|  0.0097269      \t|9000           \t|  87.542         \t|  7.2837         \t|\n",
      "on_train_batch_end                 \t|  0.0029101      \t|9000           \t|  26.191         \t|  2.1791         \t|\n",
      "training_batch_to_device           \t|  0.0027209      \t|9000           \t|  24.488         \t|  2.0375         \t|\n",
      "get_validate_batch                 \t|  0.13062        \t|120            \t|  15.675         \t|  1.3042         \t|\n",
      "fetch_next_validate_batch          \t|  0.13055        \t|120            \t|  15.666         \t|  1.3035         \t|\n",
      "on_validation_end                  \t|  0.14124        \t|61             \t|  8.6156         \t|  0.71683        \t|\n",
      "zero_grad                          \t|  0.00063401     \t|9000           \t|  5.7061         \t|  0.47476        \t|\n",
      "evaluation_step_and_end            \t|  0.041401       \t|61             \t|  2.5254         \t|  0.21012        \t|\n",
      "validation_step                    \t|  0.041209       \t|61             \t|  2.5138         \t|  0.20915        \t|\n",
      "on_train_batch_start               \t|  0.00022936     \t|9000           \t|  2.0642         \t|  0.17175        \t|\n",
      "on_validation_start                \t|  0.026326       \t|61             \t|  1.6059         \t|  0.13362        \t|\n",
      "on_train_epoch_start               \t|  0.0020076      \t|600            \t|  1.2045         \t|  0.10022        \t|\n",
      "training_step_end                  \t|  6.635e-05      \t|9000           \t|  0.59715        \t|  0.049684       \t|\n",
      "on_train_epoch_end                 \t|  0.00099171     \t|600            \t|  0.59502        \t|  0.049507       \t|\n",
      "on_batch_start                     \t|  5.3085e-05     \t|9000           \t|  0.47776        \t|  0.039751       \t|\n",
      "on_after_backward                  \t|  4.044e-05      \t|9000           \t|  0.36396        \t|  0.030283       \t|\n",
      "on_batch_end                       \t|  3.5998e-05     \t|9000           \t|  0.32398        \t|  0.026956       \t|\n",
      "on_before_zero_grad                \t|  3.467e-05      \t|9000           \t|  0.31203        \t|  0.025962       \t|\n",
      "on_before_backward                 \t|  3.1176e-05     \t|9000           \t|  0.28058        \t|  0.023345       \t|\n",
      "on_before_optimizer_step           \t|  3.0075e-05     \t|9000           \t|  0.27068        \t|  0.022521       \t|\n",
      "evaluation_batch_to_device         \t|  0.0039861      \t|61             \t|  0.24315        \t|  0.020231       \t|\n",
      "get_sanity_check_batch             \t|  0.10494        \t|2              \t|  0.20988        \t|  0.017462       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.10488        \t|2              \t|  0.20977        \t|  0.017453       \t|\n",
      "on_validation_batch_end            \t|  0.0022803      \t|61             \t|  0.1391         \t|  0.011574       \t|\n",
      "on_train_start                     \t|  0.024448       \t|1              \t|  0.024448       \t|  0.0020342      \t|\n",
      "on_epoch_end                       \t|  3.4866e-05     \t|661            \t|  0.023046       \t|  0.0019175      \t|\n",
      "on_epoch_start                     \t|  3.1785e-05     \t|661            \t|  0.02101        \t|  0.001748       \t|\n",
      "on_sanity_check_start              \t|  0.020086       \t|1              \t|  0.020086       \t|  0.0016712      \t|\n",
      "on_validation_model_eval           \t|  0.00017047     \t|61             \t|  0.010399       \t|  0.00086519     \t|\n",
      "on_validation_batch_start          \t|  0.00010357     \t|61             \t|  0.0063176      \t|  0.00052564     \t|\n",
      "validation_step_end                \t|  8.2339e-05     \t|61             \t|  0.0050227      \t|  0.0004179      \t|\n",
      "on_pretrain_routine_start          \t|  0.0026142      \t|1              \t|  0.0026142      \t|  0.0002175      \t|\n",
      "on_validation_epoch_end            \t|  4.1455e-05     \t|61             \t|  0.0025288      \t|  0.0002104      \t|\n",
      "on_validation_epoch_start          \t|  2.8585e-05     \t|61             \t|  0.0017437      \t|  0.00014508     \t|\n",
      "on_train_end                       \t|  0.00053284     \t|1              \t|  0.00053284     \t|  4.4334e-05     \t|\n",
      "configure_optimizers               \t|  0.00019787     \t|1              \t|  0.00019787     \t|  1.6463e-05     \t|\n",
      "on_fit_end                         \t|  4.0177e-05     \t|1              \t|  4.0177e-05     \t|  3.3428e-06     \t|\n",
      "on_sanity_check_end                \t|  3.5311e-05     \t|1              \t|  3.5311e-05     \t|  2.938e-06      \t|\n",
      "teardown                           \t|  3.0037e-05     \t|1              \t|  3.0037e-05     \t|  2.4991e-06     \t|\n",
      "on_fit_start                       \t|  2.9864e-05     \t|1              \t|  2.9864e-05     \t|  2.4847e-06     \t|\n",
      "on_pretrain_routine_end            \t|  2.7581e-05     \t|1              \t|  2.7581e-05     \t|  2.2948e-06     \t|\n",
      "on_configure_sharded_model         \t|  1.9718e-05     \t|1              \t|  1.9718e-05     \t|  1.6406e-06     \t|\n",
      "configure_callbacks                \t|  1.625e-05      \t|1              \t|  1.625e-05      \t|  1.352e-06      \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4538e-05     \t|1              \t|  1.4538e-05     \t|  1.2096e-06     \t|\n",
      "setup                              \t|  1.2424e-05     \t|1              \t|  1.2424e-05     \t|  1.0337e-06     \t|\n",
      "on_train_dataloader                \t|  7.2899e-06     \t|1              \t|  7.2899e-06     \t|  6.0654e-07     \t|\n",
      "on_val_dataloader                  \t|  5.926e-06      \t|1              \t|  5.926e-06      \t|  4.9306e-07     \t|\n",
      "configure_sharded_model            \t|  5.431e-06      \t|1              \t|  5.431e-06      \t|  4.5187e-07     \t|\n",
      "prepare_data                       \t|  4.6738e-06     \t|1              \t|  4.6738e-06     \t|  3.8887e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (109105, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8079e5ac972b43d2b4dab3642b603b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.3729         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.3145         \t|1              \t|  3.3145         \t|  98.267         \t|\n",
      "evaluation_step_and_end            \t|  0.59809        \t|4              \t|  2.3923         \t|  70.928         \t|\n",
      "test_step                          \t|  0.58194        \t|4              \t|  2.3278         \t|  69.013         \t|\n",
      "get_test_batch                     \t|  0.087167       \t|5              \t|  0.43584        \t|  12.922         \t|\n",
      "fetch_next_test_batch              \t|  0.087099       \t|5              \t|  0.4355         \t|  12.912         \t|\n",
      "test_step_end                      \t|  0.015754       \t|4              \t|  0.063015       \t|  1.8683         \t|\n",
      "on_test_batch_end                  \t|  0.015537       \t|4              \t|  0.062147       \t|  1.8425         \t|\n",
      "evaluation_batch_to_device         \t|  0.01324        \t|4              \t|  0.052961       \t|  1.5702         \t|\n",
      "on_test_start                      \t|  0.020578       \t|1              \t|  0.020578       \t|  0.61011        \t|\n",
      "on_test_end                        \t|  0.0022455      \t|1              \t|  0.0022455      \t|  0.066574       \t|\n",
      "on_test_batch_start                \t|  8.5066e-05     \t|4              \t|  0.00034027     \t|  0.010088       \t|\n",
      "on_test_model_eval                 \t|  0.00012999     \t|1              \t|  0.00012999     \t|  0.003854       \t|\n",
      "on_test_epoch_end                  \t|  8.798e-05      \t|1              \t|  8.798e-05      \t|  0.0026084      \t|\n",
      "on_epoch_end                       \t|  4.5618e-05     \t|1              \t|  4.5618e-05     \t|  0.0013525      \t|\n",
      "teardown                           \t|  4.2911e-05     \t|1              \t|  4.2911e-05     \t|  0.0012722      \t|\n",
      "on_epoch_start                     \t|  2.4432e-05     \t|1              \t|  2.4432e-05     \t|  0.00072436     \t|\n",
      "on_configure_sharded_model         \t|  2.0678e-05     \t|1              \t|  2.0678e-05     \t|  0.00061306     \t|\n",
      "on_test_epoch_start                \t|  2e-05          \t|1              \t|  2e-05          \t|  0.00059296     \t|\n",
      "configure_callbacks                \t|  1.7217e-05     \t|1              \t|  1.7217e-05     \t|  0.00051045     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.3852e-05     \t|1              \t|  1.3852e-05     \t|  0.00041068     \t|\n",
      "setup                              \t|  1.2539e-05     \t|1              \t|  1.2539e-05     \t|  0.00037176     \t|\n",
      "on_test_dataloader                 \t|  9.944e-06      \t|1              \t|  9.944e-06      \t|  0.00029482     \t|\n",
      "configure_sharded_model            \t|  6.425e-06      \t|1              \t|  6.425e-06      \t|  0.00019049     \t|\n",
      "prepare_data                       \t|  4.6461e-06     \t|1              \t|  4.6461e-06     \t|  0.00013775     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2973720133304596,\n",
      " 'test_loss: mae_response': 0.36154118180274963,\n",
      " 'test_loss: mse': 0.3597952723503113}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61b3baa21846a185ece1a1b92d6485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 209: val_loss reached 0.42902 (best 0.42902), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 419: val_loss reached 0.39119 (best 0.39119), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 629: val_loss reached 0.36328 (best 0.36328), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 839: val_loss reached 0.34065 (best 0.34065), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1049: val_loss reached 0.32762 (best 0.32762), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 1259: val_loss reached 0.31602 (best 0.31602), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1469: val_loss reached 0.30997 (best 0.30997), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1679: val_loss reached 0.30456 (best 0.30456), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1889: val_loss reached 0.30162 (best 0.30162), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 2099: val_loss reached 0.29828 (best 0.29828), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 2309: val_loss reached 0.29686 (best 0.29686), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 2519: val_loss reached 0.29580 (best 0.29580), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 2729: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2939: val_loss reached 0.29410 (best 0.29410), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 3149: val_loss reached 0.29388 (best 0.29388), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 3359: val_loss reached 0.29358 (best 0.29358), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 3569: val_loss reached 0.29227 (best 0.29227), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 3779: val_loss reached 0.29104 (best 0.29104), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 3989: val_loss reached 0.29032 (best 0.29032), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 4199: val_loss reached 0.29001 (best 0.29001), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 4409: val_loss reached 0.28925 (best 0.28925), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 4619: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 4829: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 5039: val_loss reached 0.28868 (best 0.28868), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 5249: val_loss reached 0.28776 (best 0.28776), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 5459: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 5669: val_loss reached 0.28704 (best 0.28704), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 5879: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 6089: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 6299: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 6509: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 6719: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 6929: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 7139: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 7349: val_loss reached 0.28623 (best 0.28623), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 7559: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 7769: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 7979: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 8189: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 8399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 8609: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 8819: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 9029: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 9239: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 9449: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 9659: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 9869: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 10079: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 10289: val_loss reached 0.28613 (best 0.28613), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_1.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 10499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 10709: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 10919: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 11129: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 11339: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 11549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 11759: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 11969: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 12179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 12389: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 12599: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1573.5         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.621          \t|600            \t|  1572.6         \t|  99.944         \t|\n",
      "run_training_batch                 \t|  0.08509        \t|12600          \t|  1072.1         \t|  68.139         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.049664       \t|12600          \t|  625.77         \t|  39.771         \t|\n",
      "training_step_and_backward         \t|  0.045017       \t|12600          \t|  567.22         \t|  36.049         \t|\n",
      "model_forward                      \t|  0.034747       \t|12600          \t|  437.81         \t|  27.825         \t|\n",
      "training_step                      \t|  0.034487       \t|12600          \t|  434.53         \t|  27.617         \t|\n",
      "get_train_batch                    \t|  0.016235       \t|13200          \t|  214.3          \t|  13.619         \t|\n",
      "fetch_next_train_batch             \t|  0.016204       \t|13200          \t|  213.89         \t|  13.594         \t|\n",
      "backward                           \t|  0.0095999      \t|12600          \t|  120.96         \t|  7.6875         \t|\n",
      "on_train_batch_end                 \t|  0.0029154      \t|12600          \t|  36.734         \t|  2.3346         \t|\n",
      "training_batch_to_device           \t|  0.0027548      \t|12600          \t|  34.711         \t|  2.206          \t|\n",
      "get_validate_batch                 \t|  0.097224       \t|180            \t|  17.5           \t|  1.1122         \t|\n",
      "fetch_next_validate_batch          \t|  0.097164       \t|180            \t|  17.49          \t|  1.1115         \t|\n",
      "zero_grad                          \t|  0.0006349      \t|12600          \t|  7.9997         \t|  0.50842        \t|\n",
      "on_validation_end                  \t|  0.11702        \t|61             \t|  7.138          \t|  0.45365        \t|\n",
      "evaluation_step_and_end            \t|  0.044408       \t|122            \t|  5.4177         \t|  0.34432        \t|\n",
      "validation_step                    \t|  0.044214       \t|122            \t|  5.3941         \t|  0.34282        \t|\n",
      "on_train_batch_start               \t|  0.00022217     \t|12600          \t|  2.7994         \t|  0.17791        \t|\n",
      "on_validation_start                \t|  0.0293         \t|61             \t|  1.7873         \t|  0.11359        \t|\n",
      "on_train_epoch_start               \t|  0.0019814      \t|600            \t|  1.1888         \t|  0.075556       \t|\n",
      "training_step_end                  \t|  6.6405e-05     \t|12600          \t|  0.83671        \t|  0.053176       \t|\n",
      "on_batch_start                     \t|  5.0029e-05     \t|12600          \t|  0.63037        \t|  0.040063       \t|\n",
      "on_train_epoch_end                 \t|  0.0009531      \t|600            \t|  0.57186        \t|  0.036344       \t|\n",
      "on_after_backward                  \t|  4.0541e-05     \t|12600          \t|  0.51082        \t|  0.032465       \t|\n",
      "evaluation_batch_to_device         \t|  0.0040947      \t|122            \t|  0.49955        \t|  0.031749       \t|\n",
      "on_before_zero_grad                \t|  3.5201e-05     \t|12600          \t|  0.44353        \t|  0.028189       \t|\n",
      "on_batch_end                       \t|  3.5087e-05     \t|12600          \t|  0.44209        \t|  0.028097       \t|\n",
      "on_before_backward                 \t|  3.0179e-05     \t|12600          \t|  0.38025        \t|  0.024167       \t|\n",
      "on_before_optimizer_step           \t|  3.0175e-05     \t|12600          \t|  0.38021        \t|  0.024164       \t|\n",
      "on_validation_batch_end            \t|  0.0023917      \t|122            \t|  0.29178        \t|  0.018544       \t|\n",
      "get_sanity_check_batch             \t|  0.069147       \t|3              \t|  0.20744        \t|  0.013184       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.069098       \t|3              \t|  0.20729        \t|  0.013175       \t|\n",
      "on_train_start                     \t|  0.036035       \t|1              \t|  0.036035       \t|  0.0022902      \t|\n",
      "on_epoch_end                       \t|  3.4191e-05     \t|661            \t|  0.0226         \t|  0.0014363      \t|\n",
      "on_epoch_start                     \t|  3.1951e-05     \t|661            \t|  0.02112        \t|  0.0013423      \t|\n",
      "on_sanity_check_start              \t|  0.020857       \t|1              \t|  0.020857       \t|  0.0013255      \t|\n",
      "on_validation_batch_start          \t|  9.7872e-05     \t|122            \t|  0.01194        \t|  0.00075886     \t|\n",
      "on_validation_model_eval           \t|  0.00018736     \t|61             \t|  0.011429       \t|  0.00072638     \t|\n",
      "validation_step_end                \t|  8.3382e-05     \t|122            \t|  0.010173       \t|  0.00064651     \t|\n",
      "on_pretrain_routine_start          \t|  0.0029877      \t|1              \t|  0.0029877      \t|  0.00018988     \t|\n",
      "on_validation_epoch_end            \t|  4.2603e-05     \t|61             \t|  0.0025988      \t|  0.00016516     \t|\n",
      "on_validation_epoch_start          \t|  3.2816e-05     \t|61             \t|  0.0020018      \t|  0.00012722     \t|\n",
      "on_train_end                       \t|  0.00054395     \t|1              \t|  0.00054395     \t|  3.457e-05      \t|\n",
      "configure_optimizers               \t|  0.00026054     \t|1              \t|  0.00026054     \t|  1.6558e-05     \t|\n",
      "on_sanity_check_end                \t|  5.1348e-05     \t|1              \t|  5.1348e-05     \t|  3.2634e-06     \t|\n",
      "on_configure_sharded_model         \t|  4.4214e-05     \t|1              \t|  4.4214e-05     \t|  2.81e-06       \t|\n",
      "on_fit_end                         \t|  4.4025e-05     \t|1              \t|  4.4025e-05     \t|  2.798e-06      \t|\n",
      "on_fit_start                       \t|  4.1127e-05     \t|1              \t|  4.1127e-05     \t|  2.6138e-06     \t|\n",
      "teardown                           \t|  3.0232e-05     \t|1              \t|  3.0232e-05     \t|  1.9214e-06     \t|\n",
      "on_pretrain_routine_end            \t|  2.8791e-05     \t|1              \t|  2.8791e-05     \t|  1.8298e-06     \t|\n",
      "configure_callbacks                \t|  1.9476e-05     \t|1              \t|  1.9476e-05     \t|  1.2378e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.8672e-05     \t|1              \t|  1.8672e-05     \t|  1.1867e-06     \t|\n",
      "setup                              \t|  1.3738e-05     \t|1              \t|  1.3738e-05     \t|  8.7312e-07     \t|\n",
      "on_train_dataloader                \t|  9.089e-06      \t|1              \t|  9.089e-06      \t|  5.7765e-07     \t|\n",
      "on_val_dataloader                  \t|  6.8189e-06     \t|1              \t|  6.8189e-06     \t|  4.3337e-07     \t|\n",
      "configure_sharded_model            \t|  5.7679e-06     \t|1              \t|  5.7679e-06     \t|  3.6658e-07     \t|\n",
      "prepare_data                       \t|  4.648e-06      \t|1              \t|  4.648e-06      \t|  2.954e-07      \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920c31cbdc00416588fdb7578c5ce9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  10.925         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  10.863         \t|1              \t|  10.863         \t|  99.433         \t|\n",
      "evaluation_step_and_end            \t|  0.71697        \t|12             \t|  8.6037         \t|  78.753         \t|\n",
      "test_step                          \t|  0.70109        \t|12             \t|  8.4131         \t|  77.008         \t|\n",
      "get_test_batch                     \t|  0.11677        \t|13             \t|  1.518          \t|  13.895         \t|\n",
      "fetch_next_test_batch              \t|  0.11671        \t|13             \t|  1.5173         \t|  13.888         \t|\n",
      "on_test_batch_end                  \t|  0.018274       \t|12             \t|  0.21928        \t|  2.0072         \t|\n",
      "test_step_end                      \t|  0.015643       \t|12             \t|  0.18772        \t|  1.7183         \t|\n",
      "evaluation_batch_to_device         \t|  0.010503       \t|12             \t|  0.12603        \t|  1.1536         \t|\n",
      "on_test_start                      \t|  0.025578       \t|1              \t|  0.025578       \t|  0.23413        \t|\n",
      "on_test_end                        \t|  0.0023062      \t|1              \t|  0.0023062      \t|  0.02111        \t|\n",
      "on_test_batch_start                \t|  6.1747e-05     \t|12             \t|  0.00074097     \t|  0.0067824      \t|\n",
      "on_test_model_eval                 \t|  0.00013265     \t|1              \t|  0.00013265     \t|  0.0012142      \t|\n",
      "on_test_epoch_end                  \t|  0.00011928     \t|1              \t|  0.00011928     \t|  0.0010918      \t|\n",
      "on_epoch_end                       \t|  6.3789e-05     \t|1              \t|  6.3789e-05     \t|  0.00058389     \t|\n",
      "teardown                           \t|  4.275e-05      \t|1              \t|  4.275e-05      \t|  0.00039131     \t|\n",
      "on_epoch_start                     \t|  4.2197e-05     \t|1              \t|  4.2197e-05     \t|  0.00038625     \t|\n",
      "on_test_epoch_start                \t|  3.9331e-05     \t|1              \t|  3.9331e-05     \t|  0.00036001     \t|\n",
      "on_configure_sharded_model         \t|  3.0849e-05     \t|1              \t|  3.0849e-05     \t|  0.00028237     \t|\n",
      "on_before_accelerator_backend_setup\t|  2.5011e-05     \t|1              \t|  2.5011e-05     \t|  0.00022894     \t|\n",
      "configure_callbacks                \t|  2.118e-05      \t|1              \t|  2.118e-05      \t|  0.00019387     \t|\n",
      "setup                              \t|  2.0607e-05     \t|1              \t|  2.0607e-05     \t|  0.00018862     \t|\n",
      "on_test_dataloader                 \t|  1.0255e-05     \t|1              \t|  1.0255e-05     \t|  9.3869e-05     \t|\n",
      "configure_sharded_model            \t|  9.2229e-06     \t|1              \t|  9.2229e-06     \t|  8.4421e-05     \t|\n",
      "prepare_data                       \t|  8.4038e-06     \t|1              \t|  8.4038e-06     \t|  7.6923e-05     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2738986909389496,\n",
      " 'test_loss: mae_response': 0.3353368937969208,\n",
      " 'test_loss: mse': 0.3010720908641815}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d6ea5849c1420b913e9dbcc3ca1f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 209: val_loss reached 0.48965 (best 0.48965), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 419: val_loss reached 0.42326 (best 0.42326), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 629: val_loss reached 0.39167 (best 0.39167), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 839: val_loss reached 0.36908 (best 0.36908), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1049: val_loss reached 0.34825 (best 0.34825), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 1259: val_loss reached 0.33517 (best 0.33517), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1469: val_loss reached 0.32535 (best 0.32535), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 1679: val_loss reached 0.32144 (best 0.32144), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 1889: val_loss reached 0.31032 (best 0.31032), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 2099: val_loss reached 0.30607 (best 0.30607), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 2309: val_loss reached 0.30297 (best 0.30297), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 2519: val_loss reached 0.29904 (best 0.29904), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 2729: val_loss reached 0.29701 (best 0.29701), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 2939: val_loss reached 0.29636 (best 0.29636), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 3149: val_loss reached 0.29497 (best 0.29497), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 3359: val_loss reached 0.29472 (best 0.29472), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 3569: val_loss reached 0.29403 (best 0.29403), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 3779: val_loss reached 0.29329 (best 0.29329), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 3989: val_loss reached 0.29311 (best 0.29311), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 4199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 4409: val_loss reached 0.29230 (best 0.29230), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 4619: val_loss reached 0.29170 (best 0.29170), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 4829: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 5039: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 5249: val_loss reached 0.29114 (best 0.29114), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 5459: val_loss reached 0.29089 (best 0.29089), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 5669: val_loss reached 0.29017 (best 0.29017), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 5879: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 6089: val_loss reached 0.29010 (best 0.29010), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 6299: val_loss reached 0.28987 (best 0.28987), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 6509: val_loss reached 0.28948 (best 0.28948), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 6719: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 6929: val_loss reached 0.28936 (best 0.28936), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 7139: val_loss reached 0.28908 (best 0.28908), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 7349: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 7559: val_loss reached 0.28820 (best 0.28820), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 7769: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 7979: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 8189: val_loss reached 0.28797 (best 0.28797), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 8399: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 8609: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 8819: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 9029: val_loss reached 0.28794 (best 0.28794), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 9239: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 9449: val_loss reached 0.28793 (best 0.28793), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 9659: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 9869: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 10079: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 10289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 10499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 10709: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 10919: val_loss reached 0.28771 (best 0.28771), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_2.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 11129: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 11339: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 11549: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 11759: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 11969: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 12179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 12389: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 12599: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1611.7         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.6846         \t|600            \t|  1610.8         \t|  99.944         \t|\n",
      "run_training_batch                 \t|  0.087734       \t|12600          \t|  1105.5         \t|  68.59          \t|\n",
      "optimizer_step_with_closure_0      \t|  0.050544       \t|12600          \t|  636.86         \t|  39.515         \t|\n",
      "training_step_and_backward         \t|  0.045927       \t|12600          \t|  578.68         \t|  35.905         \t|\n",
      "model_forward                      \t|  0.035607       \t|12600          \t|  448.65         \t|  27.837         \t|\n",
      "training_step                      \t|  0.035351       \t|12600          \t|  445.42         \t|  27.637         \t|\n",
      "get_train_batch                    \t|  0.016407       \t|13200          \t|  216.57         \t|  13.437         \t|\n",
      "fetch_next_train_batch             \t|  0.016375       \t|13200          \t|  216.15         \t|  13.412         \t|\n",
      "backward                           \t|  0.0096623      \t|12600          \t|  121.74         \t|  7.5538         \t|\n",
      "on_train_batch_end                 \t|  0.0029176      \t|12600          \t|  36.762         \t|  2.281          \t|\n",
      "training_batch_to_device           \t|  0.0028192      \t|12600          \t|  35.522         \t|  2.204          \t|\n",
      "get_validate_batch                 \t|  0.1003         \t|180            \t|  18.053         \t|  1.1201         \t|\n",
      "fetch_next_validate_batch          \t|  0.10024        \t|180            \t|  18.043         \t|  1.1195         \t|\n",
      "on_validation_end                  \t|  0.18738        \t|61             \t|  11.43          \t|  0.7092         \t|\n",
      "zero_grad                          \t|  0.00062099     \t|12600          \t|  7.8245         \t|  0.48548        \t|\n",
      "evaluation_step_and_end            \t|  0.043808       \t|122            \t|  5.3445         \t|  0.33161        \t|\n",
      "validation_step                    \t|  0.04362        \t|122            \t|  5.3216         \t|  0.33019        \t|\n",
      "on_train_batch_start               \t|  0.0002179      \t|12600          \t|  2.7456         \t|  0.17035        \t|\n",
      "on_validation_start                \t|  0.027167       \t|61             \t|  1.6572         \t|  0.10282        \t|\n",
      "on_train_epoch_start               \t|  0.0019532      \t|600            \t|  1.1719         \t|  0.072715       \t|\n",
      "training_step_end                  \t|  6.4538e-05     \t|12600          \t|  0.81318        \t|  0.050455       \t|\n",
      "on_batch_start                     \t|  4.8711e-05     \t|12600          \t|  0.61376        \t|  0.038081       \t|\n",
      "on_train_epoch_end                 \t|  0.0009309      \t|600            \t|  0.55854        \t|  0.034656       \t|\n",
      "on_after_backward                  \t|  3.93e-05       \t|12600          \t|  0.49517        \t|  0.030724       \t|\n",
      "evaluation_batch_to_device         \t|  0.0039558      \t|122            \t|  0.48261        \t|  0.029944       \t|\n",
      "on_batch_end                       \t|  3.401e-05      \t|12600          \t|  0.42853        \t|  0.026589       \t|\n",
      "on_before_zero_grad                \t|  3.3239e-05     \t|12600          \t|  0.41881        \t|  0.025986       \t|\n",
      "on_before_optimizer_step           \t|  2.9456e-05     \t|12600          \t|  0.37115        \t|  0.023028       \t|\n",
      "on_before_backward                 \t|  2.9294e-05     \t|12600          \t|  0.3691         \t|  0.022902       \t|\n",
      "on_validation_batch_end            \t|  0.002381       \t|122            \t|  0.29048        \t|  0.018023       \t|\n",
      "get_sanity_check_batch             \t|  0.070922       \t|3              \t|  0.21277        \t|  0.013201       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.070878       \t|3              \t|  0.21263        \t|  0.013193       \t|\n",
      "on_train_start                     \t|  0.033072       \t|1              \t|  0.033072       \t|  0.002052       \t|\n",
      "on_epoch_end                       \t|  3.3895e-05     \t|661            \t|  0.022404       \t|  0.0013901      \t|\n",
      "on_epoch_start                     \t|  3.124e-05      \t|661            \t|  0.02065        \t|  0.0012812      \t|\n",
      "on_sanity_check_start              \t|  0.019851       \t|1              \t|  0.019851       \t|  0.0012317      \t|\n",
      "on_validation_model_eval           \t|  0.00018181     \t|61             \t|  0.011091       \t|  0.00068814     \t|\n",
      "on_validation_batch_start          \t|  8.6545e-05     \t|122            \t|  0.010558       \t|  0.00065511     \t|\n",
      "validation_step_end                \t|  8.2342e-05     \t|122            \t|  0.010046       \t|  0.0006233      \t|\n",
      "on_pretrain_routine_start          \t|  0.0026448      \t|1              \t|  0.0026448      \t|  0.0001641      \t|\n",
      "on_validation_epoch_end            \t|  4.0309e-05     \t|61             \t|  0.0024589      \t|  0.00015256     \t|\n",
      "on_validation_epoch_start          \t|  2.9547e-05     \t|61             \t|  0.0018023      \t|  0.00011183     \t|\n",
      "on_train_end                       \t|  0.00093282     \t|1              \t|  0.00093282     \t|  5.7878e-05     \t|\n",
      "configure_optimizers               \t|  0.00021886     \t|1              \t|  0.00021886     \t|  1.3579e-05     \t|\n",
      "on_fit_end                         \t|  9.2716e-05     \t|1              \t|  9.2716e-05     \t|  5.7527e-06     \t|\n",
      "teardown                           \t|  5.9282e-05     \t|1              \t|  5.9282e-05     \t|  3.6783e-06     \t|\n",
      "on_sanity_check_end                \t|  4.711e-05      \t|1              \t|  4.711e-05      \t|  2.923e-06      \t|\n",
      "on_fit_start                       \t|  3.3128e-05     \t|1              \t|  3.3128e-05     \t|  2.0555e-06     \t|\n",
      "on_pretrain_routine_end            \t|  2.7774e-05     \t|1              \t|  2.7774e-05     \t|  1.7233e-06     \t|\n",
      "on_configure_sharded_model         \t|  1.9547e-05     \t|1              \t|  1.9547e-05     \t|  1.2128e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4222e-05     \t|1              \t|  1.4222e-05     \t|  8.8243e-07     \t|\n",
      "configure_callbacks                \t|  1.3863e-05     \t|1              \t|  1.3863e-05     \t|  8.6015e-07     \t|\n",
      "setup                              \t|  1.2488e-05     \t|1              \t|  1.2488e-05     \t|  7.7483e-07     \t|\n",
      "on_train_dataloader                \t|  8.0019e-06     \t|1              \t|  8.0019e-06     \t|  4.9649e-07     \t|\n",
      "on_val_dataloader                  \t|  6.2699e-06     \t|1              \t|  6.2699e-06     \t|  3.8903e-07     \t|\n",
      "configure_sharded_model            \t|  5.7081e-06     \t|1              \t|  5.7081e-06     \t|  3.5417e-07     \t|\n",
      "prepare_data                       \t|  4.4419e-06     \t|1              \t|  4.4419e-06     \t|  2.7561e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b6dbd15a9a4b8e98e622c1fa3a8a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  10.16          \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  10.104         \t|1              \t|  10.104         \t|  99.45          \t|\n",
      "evaluation_step_and_end            \t|  0.663          \t|12             \t|  7.956          \t|  78.307         \t|\n",
      "test_step                          \t|  0.64715        \t|12             \t|  7.7658         \t|  76.435         \t|\n",
      "get_test_batch                     \t|  0.10725        \t|13             \t|  1.3943         \t|  13.723         \t|\n",
      "fetch_next_test_batch              \t|  0.1072         \t|13             \t|  1.3936         \t|  13.717         \t|\n",
      "on_test_batch_end                  \t|  0.021549       \t|12             \t|  0.25858        \t|  2.5451         \t|\n",
      "test_step_end                      \t|  0.015662       \t|12             \t|  0.18794        \t|  1.8498         \t|\n",
      "evaluation_batch_to_device         \t|  0.0099743      \t|12             \t|  0.11969        \t|  1.1781         \t|\n",
      "on_test_start                      \t|  0.022961       \t|1              \t|  0.022961       \t|  0.226          \t|\n",
      "on_test_end                        \t|  0.0026414      \t|1              \t|  0.0026414      \t|  0.025998       \t|\n",
      "on_test_batch_start                \t|  5.5364e-05     \t|12             \t|  0.00066437     \t|  0.0065391      \t|\n",
      "on_test_model_eval                 \t|  0.00015125     \t|1              \t|  0.00015125     \t|  0.0014887      \t|\n",
      "on_test_epoch_end                  \t|  0.00010625     \t|1              \t|  0.00010625     \t|  0.0010458      \t|\n",
      "on_epoch_end                       \t|  5.7504e-05     \t|1              \t|  5.7504e-05     \t|  0.00056599     \t|\n",
      "teardown                           \t|  4.3652e-05     \t|1              \t|  4.3652e-05     \t|  0.00042964     \t|\n",
      "on_epoch_start                     \t|  2.5272e-05     \t|1              \t|  2.5272e-05     \t|  0.00024874     \t|\n",
      "on_configure_sharded_model         \t|  2.3193e-05     \t|1              \t|  2.3193e-05     \t|  0.00022828     \t|\n",
      "on_test_epoch_start                \t|  2.0152e-05     \t|1              \t|  2.0152e-05     \t|  0.00019835     \t|\n",
      "configure_callbacks                \t|  1.7155e-05     \t|1              \t|  1.7155e-05     \t|  0.00016885     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.5134e-05     \t|1              \t|  1.5134e-05     \t|  0.00014896     \t|\n",
      "setup                              \t|  1.2661e-05     \t|1              \t|  1.2661e-05     \t|  0.00012462     \t|\n",
      "on_test_dataloader                 \t|  9.7021e-06     \t|1              \t|  9.7021e-06     \t|  9.5493e-05     \t|\n",
      "configure_sharded_model            \t|  7.4501e-06     \t|1              \t|  7.4501e-06     \t|  7.3328e-05     \t|\n",
      "prepare_data                       \t|  5.685e-06      \t|1              \t|  5.685e-06      \t|  5.5955e-05     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2683258652687073,\n",
      " 'test_loss: mae_response': 0.3260050117969513,\n",
      " 'test_loss: mse': 0.29068058729171753}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (27) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4143ca8692e40fa908f3cf131330878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 269: val_loss reached 0.38361 (best 0.38361), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 539: val_loss reached 0.32946 (best 0.32946), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 809: val_loss reached 0.31373 (best 0.31373), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 1079: val_loss reached 0.31267 (best 0.31267), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1349: val_loss reached 0.28174 (best 0.28174), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 1619: val_loss reached 0.27338 (best 0.27338), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1889: val_loss reached 0.26943 (best 0.26943), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 2159: val_loss reached 0.26724 (best 0.26724), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 2429: val_loss reached 0.26483 (best 0.26483), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 2699: val_loss reached 0.26357 (best 0.26357), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 2969: val_loss reached 0.26290 (best 0.26290), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 3239: val_loss reached 0.26239 (best 0.26239), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 3509: val_loss reached 0.26177 (best 0.26177), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 3779: val_loss reached 0.26092 (best 0.26092), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 4049: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 4319: val_loss reached 0.26031 (best 0.26031), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 4589: val_loss reached 0.25930 (best 0.25930), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 4859: val_loss reached 0.25904 (best 0.25904), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 5129: val_loss reached 0.25871 (best 0.25871), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 5399: val_loss reached 0.25843 (best 0.25843), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 5669: val_loss reached 0.25770 (best 0.25770), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 5939: val_loss reached 0.25758 (best 0.25758), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 6209: val_loss reached 0.25616 (best 0.25616), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 6479: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 6749: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 7019: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 7289: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 7559: val_loss reached 0.25555 (best 0.25555), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 7829: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 8099: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 8369: val_loss reached 0.25492 (best 0.25492), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 8639: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 8909: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 9179: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 9449: val_loss reached 0.25438 (best 0.25438), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 9719: val_loss reached 0.25406 (best 0.25406), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 9989: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 10259: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 10529: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 10799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 11069: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 11339: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 11609: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 11879: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 12149: val_loss reached 0.25391 (best 0.25391), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 12419: val_loss reached 0.25376 (best 0.25376), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_3.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 12689: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 12959: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 13229: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 13499: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 13769: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 14039: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 14309: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 14579: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 14849: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 15119: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 15389: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 15659: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 15929: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 16199: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1938.1         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  3.2285         \t|600            \t|  1937.1         \t|  99.949         \t|\n",
      "run_training_batch                 \t|  0.08705        \t|16200          \t|  1410.2         \t|  72.763         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.049743       \t|16200          \t|  805.84         \t|  41.579         \t|\n",
      "training_step_and_backward         \t|  0.045364       \t|16200          \t|  734.9          \t|  37.919         \t|\n",
      "model_forward                      \t|  0.034861       \t|16200          \t|  564.75         \t|  29.14          \t|\n",
      "training_step                      \t|  0.034629       \t|16200          \t|  560.98         \t|  28.945         \t|\n",
      "get_train_batch                    \t|  0.013337       \t|16800          \t|  224.07         \t|  11.561         \t|\n",
      "fetch_next_train_batch             \t|  0.013309       \t|16800          \t|  223.59         \t|  11.537         \t|\n",
      "backward                           \t|  0.0098974      \t|16200          \t|  160.34         \t|  8.2729         \t|\n",
      "training_batch_to_device           \t|  0.0026029      \t|16200          \t|  42.167         \t|  2.1757         \t|\n",
      "on_train_batch_end                 \t|  0.0025707      \t|16200          \t|  41.645         \t|  2.1488         \t|\n",
      "get_validate_batch                 \t|  0.093882       \t|180            \t|  16.899         \t|  0.87192        \t|\n",
      "fetch_next_validate_batch          \t|  0.093825       \t|180            \t|  16.888         \t|  0.87139        \t|\n",
      "on_validation_end                  \t|  0.16199        \t|61             \t|  9.8816         \t|  0.50986        \t|\n",
      "zero_grad                          \t|  0.00057468     \t|16200          \t|  9.3098         \t|  0.48036        \t|\n",
      "evaluation_step_and_end            \t|  0.039726       \t|122            \t|  4.8466         \t|  0.25007        \t|\n",
      "validation_step                    \t|  0.039554       \t|122            \t|  4.8256         \t|  0.24899        \t|\n",
      "on_train_batch_start               \t|  0.00019421     \t|16200          \t|  3.1463         \t|  0.16234        \t|\n",
      "on_validation_start                \t|  0.02242        \t|61             \t|  1.3676         \t|  0.070564       \t|\n",
      "on_train_epoch_start               \t|  0.0017546      \t|600            \t|  1.0528         \t|  0.05432        \t|\n",
      "training_step_end                  \t|  5.9273e-05     \t|16200          \t|  0.96023        \t|  0.049545       \t|\n",
      "on_batch_start                     \t|  4.2668e-05     \t|16200          \t|  0.69122        \t|  0.035665       \t|\n",
      "on_after_backward                  \t|  3.5291e-05     \t|16200          \t|  0.57171        \t|  0.029498       \t|\n",
      "on_batch_end                       \t|  3.0011e-05     \t|16200          \t|  0.48617        \t|  0.025085       \t|\n",
      "on_before_zero_grad                \t|  2.974e-05      \t|16200          \t|  0.48179        \t|  0.024859       \t|\n",
      "on_train_epoch_end                 \t|  0.0007827      \t|600            \t|  0.46962        \t|  0.024231       \t|\n",
      "evaluation_batch_to_device         \t|  0.0036716      \t|122            \t|  0.44793        \t|  0.023112       \t|\n",
      "on_before_optimizer_step           \t|  2.6685e-05     \t|16200          \t|  0.4323         \t|  0.022305       \t|\n",
      "on_before_backward                 \t|  2.5964e-05     \t|16200          \t|  0.42061        \t|  0.021702       \t|\n",
      "on_validation_batch_end            \t|  0.0021207      \t|122            \t|  0.25873        \t|  0.013349       \t|\n",
      "get_sanity_check_batch             \t|  0.082876       \t|3              \t|  0.24863        \t|  0.012828       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.082567       \t|3              \t|  0.2477         \t|  0.012781       \t|\n",
      "on_train_start                     \t|  0.046559       \t|1              \t|  0.046559       \t|  0.0024023      \t|\n",
      "on_sanity_check_start              \t|  0.024098       \t|1              \t|  0.024098       \t|  0.0012434      \t|\n",
      "on_epoch_end                       \t|  3.0127e-05     \t|661            \t|  0.019914       \t|  0.0010275      \t|\n",
      "on_epoch_start                     \t|  2.7774e-05     \t|661            \t|  0.018359       \t|  0.00094725     \t|\n",
      "on_validation_model_eval           \t|  0.00017654     \t|61             \t|  0.010769       \t|  0.00055564     \t|\n",
      "on_validation_batch_start          \t|  8.7988e-05     \t|122            \t|  0.010735       \t|  0.00055387     \t|\n",
      "validation_step_end                \t|  7.4336e-05     \t|122            \t|  0.009069       \t|  0.00046793     \t|\n",
      "on_pretrain_routine_start          \t|  0.00285        \t|1              \t|  0.00285        \t|  0.00014705     \t|\n",
      "on_validation_epoch_end            \t|  3.4526e-05     \t|61             \t|  0.0021061      \t|  0.00010867     \t|\n",
      "on_validation_epoch_start          \t|  2.4082e-05     \t|61             \t|  0.001469       \t|  7.5797e-05     \t|\n",
      "on_train_end                       \t|  0.00042209     \t|1              \t|  0.00042209     \t|  2.1778e-05     \t|\n",
      "configure_optimizers               \t|  0.00023723     \t|1              \t|  0.00023723     \t|  1.224e-05      \t|\n",
      "on_sanity_check_end                \t|  6.5681e-05     \t|1              \t|  6.5681e-05     \t|  3.3889e-06     \t|\n",
      "on_fit_start                       \t|  4.05e-05       \t|1              \t|  4.05e-05       \t|  2.0897e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.3125e-05     \t|1              \t|  3.3125e-05     \t|  1.7091e-06     \t|\n",
      "teardown                           \t|  2.7804e-05     \t|1              \t|  2.7804e-05     \t|  1.4346e-06     \t|\n",
      "on_fit_end                         \t|  2.7224e-05     \t|1              \t|  2.7224e-05     \t|  1.4047e-06     \t|\n",
      "setup                              \t|  2.3392e-05     \t|1              \t|  2.3392e-05     \t|  1.207e-06      \t|\n",
      "on_configure_sharded_model         \t|  2.1818e-05     \t|1              \t|  2.1818e-05     \t|  1.1257e-06     \t|\n",
      "configure_callbacks                \t|  1.9103e-05     \t|1              \t|  1.9103e-05     \t|  9.8566e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.6746e-05     \t|1              \t|  1.6746e-05     \t|  8.6403e-07     \t|\n",
      "on_train_dataloader                \t|  1.149e-05      \t|1              \t|  1.149e-05      \t|  5.9285e-07     \t|\n",
      "on_val_dataloader                  \t|  8.0941e-06     \t|1              \t|  8.0941e-06     \t|  4.1763e-07     \t|\n",
      "configure_sharded_model            \t|  5.5691e-06     \t|1              \t|  5.5691e-06     \t|  2.8735e-07     \t|\n",
      "prepare_data                       \t|  4.4301e-06     \t|1              \t|  4.4301e-06     \t|  2.2858e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9cc729cf1341ca8cfa9b54086119c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  5.2986         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  5.2414         \t|1              \t|  5.2414         \t|  98.92          \t|\n",
      "evaluation_step_and_end            \t|  0.68731        \t|6              \t|  4.1239         \t|  77.829         \t|\n",
      "test_step                          \t|  0.67224        \t|6              \t|  4.0334         \t|  76.122         \t|\n",
      "get_test_batch                     \t|  0.070578       \t|7              \t|  0.49405        \t|  9.3241         \t|\n",
      "fetch_next_test_batch              \t|  0.070517       \t|7              \t|  0.49362        \t|  9.316          \t|\n",
      "on_test_batch_end                  \t|  0.018598       \t|6              \t|  0.11159        \t|  2.1059         \t|\n",
      "evaluation_batch_to_device         \t|  0.016154       \t|6              \t|  0.096923       \t|  1.8292         \t|\n",
      "test_step_end                      \t|  0.014846       \t|6              \t|  0.089076       \t|  1.6811         \t|\n",
      "on_test_start                      \t|  0.018012       \t|1              \t|  0.018012       \t|  0.33993        \t|\n",
      "on_test_end                        \t|  0.0017675      \t|1              \t|  0.0017675      \t|  0.033358       \t|\n",
      "on_test_batch_start                \t|  6.7037e-05     \t|6              \t|  0.00040222     \t|  0.0075911      \t|\n",
      "on_test_model_eval                 \t|  0.00012452     \t|1              \t|  0.00012452     \t|  0.0023501      \t|\n",
      "on_test_epoch_end                  \t|  0.00011285     \t|1              \t|  0.00011285     \t|  0.0021298      \t|\n",
      "on_epoch_end                       \t|  5.3727e-05     \t|1              \t|  5.3727e-05     \t|  0.001014       \t|\n",
      "teardown                           \t|  5.1977e-05     \t|1              \t|  5.1977e-05     \t|  0.00098095     \t|\n",
      "on_configure_sharded_model         \t|  2.1995e-05     \t|1              \t|  2.1995e-05     \t|  0.00041511     \t|\n",
      "on_epoch_start                     \t|  2.1878e-05     \t|1              \t|  2.1878e-05     \t|  0.0004129      \t|\n",
      "on_test_epoch_start                \t|  1.7776e-05     \t|1              \t|  1.7776e-05     \t|  0.00033549     \t|\n",
      "configure_callbacks                \t|  1.6105e-05     \t|1              \t|  1.6105e-05     \t|  0.00030395     \t|\n",
      "setup                              \t|  1.4653e-05     \t|1              \t|  1.4653e-05     \t|  0.00027655     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.4314e-05     \t|1              \t|  1.4314e-05     \t|  0.00027015     \t|\n",
      "on_test_dataloader                 \t|  8.5891e-06     \t|1              \t|  8.5891e-06     \t|  0.0001621      \t|\n",
      "configure_sharded_model            \t|  7.2981e-06     \t|1              \t|  7.2981e-06     \t|  0.00013774     \t|\n",
      "prepare_data                       \t|  5.4259e-06     \t|1              \t|  5.4259e-06     \t|  0.0001024      \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2561831772327423,\n",
      " 'test_loss: mae_response': 0.3131941556930542,\n",
      " 'test_loss: mse': 0.2730114161968231}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'predict/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'training/default': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'model/MonetAutoencoder2D': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'datasets/FilteredMerfishDataset': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'optimizer/sgd': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | encoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "1 | decoder_network | DenseReluGMMConvNetwork | 2.8 M \n",
      "------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.048    Total estimated model params size (MB)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264b4f88baef4ec2be5d3f10a09263bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 279: val_loss reached 0.38880 (best 0.38880), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 559: val_loss reached 0.33520 (best 0.33520), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 839: val_loss reached 0.31456 (best 0.31456), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 1119: val_loss reached 0.30257 (best 0.30257), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49, global step 1399: val_loss reached 0.29669 (best 0.29669), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59, global step 1679: val_loss reached 0.28459 (best 0.28459), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69, global step 1959: val_loss reached 0.28255 (best 0.28255), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79, global step 2239: val_loss reached 0.27846 (best 0.27846), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89, global step 2519: val_loss reached 0.27688 (best 0.27688), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99, global step 2799: val_loss reached 0.27557 (best 0.27557), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109, global step 3079: val_loss reached 0.27444 (best 0.27444), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119, global step 3359: val_loss reached 0.27432 (best 0.27432), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129, global step 3639: val_loss reached 0.27333 (best 0.27333), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139, global step 3919: val_loss reached 0.27312 (best 0.27312), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149, global step 4199: val_loss reached 0.27247 (best 0.27247), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 159, global step 4479: val_loss reached 0.27202 (best 0.27202), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169, global step 4759: val_loss reached 0.27137 (best 0.27137), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 179, global step 5039: val_loss reached 0.27116 (best 0.27116), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 189, global step 5319: val_loss reached 0.27110 (best 0.27110), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199, global step 5599: val_loss reached 0.27016 (best 0.27016), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 209, global step 5879: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 219, global step 6159: val_loss reached 0.27010 (best 0.27010), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 229, global step 6439: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 239, global step 6719: val_loss reached 0.26979 (best 0.26979), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 249, global step 6999: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 259, global step 7279: val_loss reached 0.26952 (best 0.26952), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269, global step 7559: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 279, global step 7839: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 289, global step 8119: val_loss reached 0.26918 (best 0.26918), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, global step 8399: val_loss reached 0.26863 (best 0.26863), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 309, global step 8679: val_loss reached 0.26811 (best 0.26811), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 319, global step 8959: val_loss reached 0.26749 (best 0.26749), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 329, global step 9239: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 339, global step 9519: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 349, global step 9799: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 359, global step 10079: val_loss reached 0.26675 (best 0.26675), saving model to \"/home/roko/spatial/output/lightning_logs/checkpoints/MonetAutoencoder2D/MonetAutoencoder2D__155__[200, 200]__155__3__['Female']__['Naive']__0.001__deepST_CV_4.ckpt\" as top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 369, global step 10359: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 379, global step 10639: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 389, global step 10919: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399, global step 11199: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 409, global step 11479: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 419, global step 11759: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 429, global step 12039: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 439, global step 12319: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 449, global step 12599: val_loss was not in top True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 459, global step 12879: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 469, global step 13159: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 479, global step 13439: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 489, global step 13719: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499, global step 13999: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 509, global step 14279: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 519, global step 14559: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 529, global step 14839: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 539, global step 15119: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 549, global step 15399: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 559, global step 15679: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 569, global step 15959: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 579, global step 16239: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 589, global step 16519: val_loss was not in top True\n",
      "Trainer was signaled to stop but required minimum epochs (600) or minimum steps (None) has not been met. Training will continue...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599, global step 16799: val_loss was not in top True\n",
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  1948.0         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  3.2451         \t|600            \t|  1947.1         \t|  99.954         \t|\n",
      "run_training_batch                 \t|  0.084852       \t|16800          \t|  1425.5         \t|  73.179         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.047836       \t|16800          \t|  803.65         \t|  41.255         \t|\n",
      "training_step_and_backward         \t|  0.043656       \t|16800          \t|  733.41         \t|  37.65          \t|\n",
      "model_forward                      \t|  0.033185       \t|16800          \t|  557.51         \t|  28.62          \t|\n",
      "training_step                      \t|  0.03299        \t|16800          \t|  554.23         \t|  28.452         \t|\n",
      "get_train_batch                    \t|  0.01281        \t|17400          \t|  222.89         \t|  11.442         \t|\n",
      "fetch_next_train_batch             \t|  0.012785       \t|17400          \t|  222.47         \t|  11.42          \t|\n",
      "backward                           \t|  0.0099186      \t|16800          \t|  166.63         \t|  8.5541         \t|\n",
      "training_batch_to_device           \t|  0.0021749      \t|16800          \t|  36.539         \t|  1.8757         \t|\n",
      "on_train_batch_end                 \t|  0.0020777      \t|16800          \t|  34.906         \t|  1.7919         \t|\n",
      "get_validate_batch                 \t|  0.099059       \t|180            \t|  17.831         \t|  0.91534        \t|\n",
      "fetch_next_validate_batch          \t|  0.099005       \t|180            \t|  17.821         \t|  0.91484        \t|\n",
      "zero_grad                          \t|  0.00052663     \t|16800          \t|  8.8474         \t|  0.45418        \t|\n",
      "on_validation_end                  \t|  0.10267        \t|61             \t|  6.263          \t|  0.32151        \t|\n",
      "evaluation_step_and_end            \t|  0.039813       \t|122            \t|  4.8572         \t|  0.24935        \t|\n",
      "validation_step                    \t|  0.039658       \t|122            \t|  4.8383         \t|  0.24837        \t|\n",
      "on_train_batch_start               \t|  0.00016497     \t|16800          \t|  2.7715         \t|  0.14228        \t|\n",
      "on_validation_start                \t|  0.018587       \t|61             \t|  1.1338         \t|  0.058204       \t|\n",
      "on_train_epoch_start               \t|  0.0014396      \t|600            \t|  0.86377        \t|  0.044342       \t|\n",
      "training_step_end                  \t|  5.1129e-05     \t|16800          \t|  0.85897        \t|  0.044095       \t|\n",
      "on_batch_start                     \t|  3.5327e-05     \t|16800          \t|  0.5935         \t|  0.030467       \t|\n",
      "on_after_backward                  \t|  2.8563e-05     \t|16800          \t|  0.47985        \t|  0.024633       \t|\n",
      "evaluation_batch_to_device         \t|  0.0034816      \t|122            \t|  0.42476        \t|  0.021805       \t|\n",
      "on_batch_end                       \t|  2.4874e-05     \t|16800          \t|  0.41788        \t|  0.021452       \t|\n",
      "on_before_zero_grad                \t|  2.4309e-05     \t|16800          \t|  0.4084         \t|  0.020965       \t|\n",
      "on_before_optimizer_step           \t|  2.2882e-05     \t|16800          \t|  0.38441        \t|  0.019734       \t|\n",
      "on_before_backward                 \t|  2.2e-05        \t|16800          \t|  0.3696         \t|  0.018974       \t|\n",
      "on_train_epoch_end                 \t|  0.00051118     \t|600            \t|  0.30671        \t|  0.015745       \t|\n",
      "on_validation_batch_end            \t|  0.0023544      \t|122            \t|  0.28724        \t|  0.014745       \t|\n",
      "get_sanity_check_batch             \t|  0.072576       \t|3              \t|  0.21773        \t|  0.011177       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.072521       \t|3              \t|  0.21756        \t|  0.011169       \t|\n",
      "on_train_start                     \t|  0.033033       \t|1              \t|  0.033033       \t|  0.0016957      \t|\n",
      "on_sanity_check_start              \t|  0.025522       \t|1              \t|  0.025522       \t|  0.0013102      \t|\n",
      "on_epoch_end                       \t|  2.495e-05      \t|661            \t|  0.016492       \t|  0.00084663     \t|\n",
      "on_epoch_start                     \t|  2.2956e-05     \t|661            \t|  0.015174       \t|  0.00077894     \t|\n",
      "on_validation_batch_start          \t|  8.7317e-05     \t|122            \t|  0.010653       \t|  0.00054686     \t|\n",
      "validation_step_end                \t|  6.7491e-05     \t|122            \t|  0.008234       \t|  0.00042269     \t|\n",
      "on_validation_model_eval           \t|  0.00012761     \t|61             \t|  0.007784       \t|  0.0003996      \t|\n",
      "on_pretrain_routine_start          \t|  0.0031133      \t|1              \t|  0.0031133      \t|  0.00015982     \t|\n",
      "on_validation_epoch_end            \t|  3.0946e-05     \t|61             \t|  0.0018877      \t|  9.6906e-05     \t|\n",
      "on_validation_epoch_start          \t|  2.1244e-05     \t|61             \t|  0.0012959      \t|  6.6524e-05     \t|\n",
      "on_train_end                       \t|  0.00042857     \t|1              \t|  0.00042857     \t|  2.2001e-05     \t|\n",
      "configure_optimizers               \t|  0.00026178     \t|1              \t|  0.00026178     \t|  1.3439e-05     \t|\n",
      "on_sanity_check_end                \t|  5.8722e-05     \t|1              \t|  5.8722e-05     \t|  3.0145e-06     \t|\n",
      "on_pretrain_routine_end            \t|  3.9692e-05     \t|1              \t|  3.9692e-05     \t|  2.0376e-06     \t|\n",
      "on_fit_start                       \t|  3.8404e-05     \t|1              \t|  3.8404e-05     \t|  1.9715e-06     \t|\n",
      "on_fit_end                         \t|  2.9138e-05     \t|1              \t|  2.9138e-05     \t|  1.4958e-06     \t|\n",
      "teardown                           \t|  2.8546e-05     \t|1              \t|  2.8546e-05     \t|  1.4654e-06     \t|\n",
      "on_configure_sharded_model         \t|  2.7367e-05     \t|1              \t|  2.7367e-05     \t|  1.4049e-06     \t|\n",
      "configure_callbacks                \t|  2.49e-05       \t|1              \t|  2.49e-05       \t|  1.2782e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.8743e-05     \t|1              \t|  1.8743e-05     \t|  9.6218e-07     \t|\n",
      "setup                              \t|  1.4153e-05     \t|1              \t|  1.4153e-05     \t|  7.2655e-07     \t|\n",
      "on_train_dataloader                \t|  8.9789e-06     \t|1              \t|  8.9789e-06     \t|  4.6093e-07     \t|\n",
      "configure_sharded_model            \t|  7.2399e-06     \t|1              \t|  7.2399e-06     \t|  3.7166e-07     \t|\n",
      "on_val_dataloader                  \t|  6.6808e-06     \t|1              \t|  6.6808e-06     \t|  3.4296e-07     \t|\n",
      "prepare_data                       \t|  5.2911e-06     \t|1              \t|  5.2911e-06     \t|  2.7162e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (1027848, 170)\n",
      "Filtered Data (205348, 170)\n",
      "/home/roko/spatial/data/raw/merfish_messi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:286: LightningDeprecationWarning: Passing `Trainer(accelerator='dp')` has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy='dp')` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9410aa536484b018ff71a7988482a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/spatial-G_n0JvVf-py3.8/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py:97: UserWarning: Could not determine on which device the inputs are. When using DataParallel (strategy='dp'), be aware that in case you are using self.device in your code, it will reference only the root device.\n",
      "  rank_zero_warn(\n",
      "TEST Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  3.8589         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_test_evaluation                \t|  3.8098         \t|1              \t|  3.8098         \t|  98.728         \t|\n",
      "evaluation_step_and_end            \t|  0.55976        \t|5              \t|  2.7988         \t|  72.528         \t|\n",
      "test_step                          \t|  0.54403        \t|5              \t|  2.7201         \t|  70.49          \t|\n",
      "get_test_batch                     \t|  0.06582        \t|6              \t|  0.39492        \t|  10.234         \t|\n",
      "fetch_next_test_batch              \t|  0.065774       \t|6              \t|  0.39464        \t|  10.227         \t|\n",
      "on_test_batch_end                  \t|  0.022225       \t|5              \t|  0.11113        \t|  2.8797         \t|\n",
      "evaluation_batch_to_device         \t|  0.021211       \t|5              \t|  0.10605        \t|  2.7483         \t|\n",
      "test_step_end                      \t|  0.015562       \t|5              \t|  0.077812       \t|  2.0164         \t|\n",
      "on_test_start                      \t|  0.016898       \t|1              \t|  0.016898       \t|  0.4379         \t|\n",
      "on_test_end                        \t|  0.0020262      \t|1              \t|  0.0020262      \t|  0.052508       \t|\n",
      "on_test_batch_start                \t|  7.0735e-05     \t|5              \t|  0.00035368     \t|  0.0091652      \t|\n",
      "on_test_epoch_end                  \t|  0.00010279     \t|1              \t|  0.00010279     \t|  0.0026638      \t|\n",
      "on_test_model_eval                 \t|  8.1673e-05     \t|1              \t|  8.1673e-05     \t|  0.0021165      \t|\n",
      "on_epoch_end                       \t|  5.2014e-05     \t|1              \t|  5.2014e-05     \t|  0.0013479      \t|\n",
      "teardown                           \t|  3.7537e-05     \t|1              \t|  3.7537e-05     \t|  0.00097274     \t|\n",
      "on_epoch_start                     \t|  1.8908e-05     \t|1              \t|  1.8908e-05     \t|  0.00048998     \t|\n",
      "on_configure_sharded_model         \t|  1.7698e-05     \t|1              \t|  1.7698e-05     \t|  0.00045863     \t|\n",
      "on_test_epoch_start                \t|  1.5978e-05     \t|1              \t|  1.5978e-05     \t|  0.00041406     \t|\n",
      "configure_callbacks                \t|  1.3975e-05     \t|1              \t|  1.3975e-05     \t|  0.00036215     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.2191e-05     \t|1              \t|  1.2191e-05     \t|  0.00031592     \t|\n",
      "setup                              \t|  1.0296e-05     \t|1              \t|  1.0296e-05     \t|  0.00026681     \t|\n",
      "on_test_dataloader                 \t|  5.4911e-06     \t|1              \t|  5.4911e-06     \t|  0.0001423      \t|\n",
      "configure_sharded_model            \t|  5.1241e-06     \t|1              \t|  5.1241e-06     \t|  0.00013279     \t|\n",
      "prepare_data                       \t|  3.793e-06      \t|1              \t|  3.793e-06      \t|  9.8293e-05     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.27796030044555664,\n",
      " 'test_loss: mae_response': 0.33865559101104736,\n",
      " 'test_loss: mse': 0.314207524061203}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_dict = {}\n",
    "time_dict = {}\n",
    "loss_excitatory_dict = {}\n",
    "loss_inhibitory_dict = {}\n",
    "\n",
    "for behavior in behaviors:\n",
    "    for sex in sexes:\n",
    "        try:\n",
    "            animal_list = animals[behavior][sex]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        behavior = [behavior]\n",
    "        sex = [sex]\n",
    "        # print(behavior, sex, animal_list)\n",
    "        for animal in animal_list:\n",
    "            start = time.time()\n",
    "            with initialize(config_path=\"../config\"):\n",
    "                cfg_from_terminal = compose(config_name=\"config\")\n",
    "                # update the behavior to get the model of interest\n",
    "                OmegaConf.update(cfg_from_terminal, \"datasets.dataset.non_response_genes_file\", \"/home/roko/spatial/spatial/ligands_only.txt\")\n",
    "                OmegaConf.update(cfg_from_terminal, \"datasets.dataset.behaviors\", behavior)\n",
    "                OmegaConf.update(cfg_from_terminal, \"datasets.dataset.sexes\", sex)\n",
    "                OmegaConf.update(cfg_from_terminal, \"datasets.dataset.test_animal\", animal)\n",
    "                model = train(cfg_from_terminal)\n",
    "                output = test(cfg_from_terminal)\n",
    "                trainer, l1_losses, inputs, gene_expressions, celltypes, test_results = output\n",
    "                MAE = test_results[0]['test_loss: mae_response']\n",
    "                excitatory_cells = (celltypes == 6).nonzero(as_tuple=True)[0]\n",
    "                MAE = test_results[0]['test_loss: mae_response']\n",
    "                excitatory_cells = (celltypes == 6).nonzero(as_tuple=True)[0]\n",
    "                MAE_excitatory = torch.abs(torch.index_select((gene_expressions-inputs)[excitatory_cells], 1, torch.tensor(response_indeces))).mean().item()\n",
    "                inhibitory_cells = (celltypes == 7).nonzero(as_tuple=True)[0]\n",
    "                MAE_inhibitory = torch.abs(torch.index_select((gene_expressions-inputs)[inhibitory_cells], 1, torch.tensor(response_indeces))).mean().item()\n",
    "            end = time.time()\n",
    "            time_dict[f\"{sex}_{behavior}_{animal}\"] = end-start\n",
    "            loss_dict[f\"{sex}_{behavior}_{animal}\"] = MAE\n",
    "            loss_excitatory_dict[f\"{sex}_{behavior}_{animal}\"] = MAE_excitatory\n",
    "            loss_inhibitory_dict[f\"{sex}_{behavior}_{animal}\"] = MAE_inhibitory\n",
    "            \n",
    "            with open(\"deepST_MAE_ligandsOnly.json\", \"w\") as outfile:\n",
    "                json.dump(loss_dict, outfile, indent=4)\n",
    "\n",
    "            with open(\"deepST_time_ligandsOnly.json\", \"w\") as outfile:\n",
    "                json.dump(time_dict, outfile, indent=4)\n",
    "                \n",
    "            with open(\"deepST_MAE_excitatory_ligandsOnly.json\", \"w\") as outfile:\n",
    "                json.dump(loss_excitatory_dict, outfile, indent=4)\n",
    "                \n",
    "            with open(\"deepST_MAE_inhibitory_ligandsOnly.json\", \"w\") as outfile:\n",
    "                json.dump(loss_inhibitory_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5f7b2",
   "metadata": {},
   "source": [
    "## Graph Organized by Animal ID Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c8b02",
   "metadata": {},
   "source": [
    "In order for a specific animal to be held out for testing, we need to understand how exactly the slices get stored before graph construction. We can accomplish this by putting a break point in unique_slices, and observing what happens and assuring it's not random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aec9f7",
   "metadata": {},
   "source": [
    "    cell_types = [\n",
    "        \"Ambiguous\",\n",
    "        \"Astrocyte\",\n",
    "        \"Endothelial 1\",\n",
    "        \"Endothelial 2\",\n",
    "        \"Endothelial 3\",\n",
    "        \"Ependymal\",\n",
    "        \"Excitatory\",\n",
    "        \"Inhibitory\",\n",
    "        \"Microglia\",\n",
    "        \"OD Immature 1\",\n",
    "        \"OD Immature 2\",\n",
    "        \"OD Mature 1\",\n",
    "        \"OD Mature 2\",\n",
    "        \"OD Mature 3\",\n",
    "        \"OD Mature 4\",\n",
    "        \"Pericytes\",\n",
    "    ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
